{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ee18ecb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, Model\n",
    "from tensorflow.keras.initializers import HeNormal, RandomNormal\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a1634e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class L2Pool2D(layers.Layer):\n",
    "    \"\"\"L2 Pooling layer as used in FaceNet NN2\"\"\"\n",
    "    def __init__(self, pool_size=3, strides=1, padding='same', **kwargs):\n",
    "        super(L2Pool2D, self).__init__(**kwargs)\n",
    "        self.pool_size = pool_size\n",
    "        self.strides = strides\n",
    "        self.padding = padding.upper()\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        # L2 pooling: sqrt(avg(x^2))\n",
    "        x_squared = tf.square(inputs)\n",
    "        pooled = tf.nn.avg_pool2d(x_squared, \n",
    "                                 ksize=self.pool_size, \n",
    "                                 strides=self.strides, \n",
    "                                 padding=self.padding)\n",
    "        return tf.sqrt(pooled + 1e-8)  # Add small epsilon for numerical stability\n",
    "    \n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\n",
    "            'pool_size': self.pool_size,\n",
    "            'strides': self.strides,\n",
    "            'padding': self.padding\n",
    "        })\n",
    "        return config\n",
    "\n",
    "class InceptionModule(layers.Layer):\n",
    "    \"\"\"Inception module exactly as described in Table 2\"\"\"\n",
    "    def __init__(self, n1x1, n3x3_reduce, n3x3, n5x5_reduce, n5x5, pool_proj, pool_type='max', **kwargs):\n",
    "        super(InceptionModule, self).__init__(**kwargs)\n",
    "        \n",
    "        self.n1x1 = n1x1\n",
    "        self.n3x3_reduce = n3x3_reduce\n",
    "        self.n3x3 = n3x3\n",
    "        self.n5x5_reduce = n5x5_reduce\n",
    "        self.n5x5 = n5x5\n",
    "        self.pool_proj = pool_proj\n",
    "        self.pool_type = pool_type\n",
    "        \n",
    "        # Branch 1: 1x1 convolution\n",
    "        if n1x1 > 0:\n",
    "            self.branch1_conv = layers.Conv2D(n1x1, 1, activation='relu', \n",
    "                                            kernel_initializer=HeNormal())\n",
    "        \n",
    "        # Branch 2: 1x1 -> 3x3 convolution\n",
    "        if n3x3_reduce > 0 and n3x3 > 0:\n",
    "            self.branch2_conv1 = layers.Conv2D(n3x3_reduce, 1, activation='relu',\n",
    "                                              kernel_initializer=HeNormal())\n",
    "            self.branch2_conv2 = layers.Conv2D(n3x3, 3, padding='same', activation='relu',\n",
    "                                              kernel_initializer=HeNormal())\n",
    "        \n",
    "        # Branch 3: 1x1 -> 5x5 convolution\n",
    "        if n5x5_reduce > 0 and n5x5 > 0:\n",
    "            self.branch3_conv1 = layers.Conv2D(n5x5_reduce, 1, activation='relu',\n",
    "                                              kernel_initializer=HeNormal())\n",
    "            self.branch3_conv2 = layers.Conv2D(n5x5, 5, padding='same', activation='relu',\n",
    "                                              kernel_initializer=HeNormal())\n",
    "        \n",
    "        # Branch 4: Pooling -> 1x1 convolution\n",
    "        if pool_type == 'max':\n",
    "            self.pool = layers.MaxPooling2D(3, strides=1, padding='same')\n",
    "        elif pool_type == 'L2':\n",
    "            self.pool = L2Pool2D(pool_size=3, strides=1, padding='same')\n",
    "        else:\n",
    "            self.pool = layers.AveragePooling2D(3, strides=1, padding='same')\n",
    "        \n",
    "        if pool_proj > 0:\n",
    "            self.branch4_conv = layers.Conv2D(pool_proj, 1, activation='relu',\n",
    "                                            kernel_initializer=HeNormal())\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        outputs = []\n",
    "        \n",
    "        # Branch 1: 1x1 conv\n",
    "        if self.n1x1 > 0:\n",
    "            branch1_out = self.branch1_conv(inputs)\n",
    "            outputs.append(branch1_out)\n",
    "        \n",
    "        # Branch 2: 1x1 -> 3x3 conv\n",
    "        if self.n3x3_reduce > 0 and self.n3x3 > 0:\n",
    "            branch2_out = self.branch2_conv1(inputs)\n",
    "            branch2_out = self.branch2_conv2(branch2_out)\n",
    "            outputs.append(branch2_out)\n",
    "        \n",
    "        # Branch 3: 1x1 -> 5x5 conv\n",
    "        if self.n5x5_reduce > 0 and self.n5x5 > 0:\n",
    "            branch3_out = self.branch3_conv1(inputs)\n",
    "            branch3_out = self.branch3_conv2(branch3_out)\n",
    "            outputs.append(branch3_out)\n",
    "        \n",
    "        # Branch 4: pool -> 1x1 conv\n",
    "        if self.pool_proj > 0:\n",
    "            branch4_out = self.pool(inputs)\n",
    "            branch4_out = self.branch4_conv(branch4_out)\n",
    "            outputs.append(branch4_out)\n",
    "        \n",
    "        return layers.Concatenate(axis=-1)(outputs)\n",
    "    \n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\n",
    "            'n1x1': self.n1x1,\n",
    "            'n3x3_reduce': self.n3x3_reduce,\n",
    "            'n3x3': self.n3x3,\n",
    "            'n5x5_reduce': self.n5x5_reduce,\n",
    "            'n5x5': self.n5x5,\n",
    "            'pool_proj': self.pool_proj,\n",
    "            'pool_type': self.pool_type\n",
    "        })\n",
    "        return config\n",
    "\n",
    "class InceptionWithStride(layers.Layer):\n",
    "    \"\"\"Inception module with stride for downsampling (3c and 4e)\"\"\"\n",
    "    def __init__(self, n3x3_reduce, n3x3, n5x5_reduce, n5x5, **kwargs):\n",
    "        super(InceptionWithStride, self).__init__(**kwargs)\n",
    "        \n",
    "        self.n3x3_reduce = n3x3_reduce\n",
    "        self.n3x3 = n3x3\n",
    "        self.n5x5_reduce = n5x5_reduce\n",
    "        self.n5x5 = n5x5\n",
    "        \n",
    "        # Branch 1: 1x1 -> 3x3 convolution with stride 2\n",
    "        self.branch1_conv1 = layers.Conv2D(n3x3_reduce, 1, activation='relu',\n",
    "                                          kernel_initializer=HeNormal())\n",
    "        self.branch1_conv2 = layers.Conv2D(n3x3, 3, strides=2, padding='same', \n",
    "                                          activation='relu', kernel_initializer=HeNormal())\n",
    "        \n",
    "        # Branch 2: 1x1 -> 5x5 convolution with stride 2\n",
    "        self.branch2_conv1 = layers.Conv2D(n5x5_reduce, 1, activation='relu',\n",
    "                                          kernel_initializer=HeNormal())\n",
    "        self.branch2_conv2 = layers.Conv2D(n5x5, 5, strides=2, padding='same', \n",
    "                                          activation='relu', kernel_initializer=HeNormal())\n",
    "        \n",
    "        # Branch 3: Max pooling with stride 2\n",
    "        self.branch3_pool = layers.MaxPooling2D(3, strides=2, padding='same')\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        # Branch 1: 1x1 -> 3x3 with stride 2\n",
    "        branch1_out = self.branch1_conv1(inputs)\n",
    "        branch1_out = self.branch1_conv2(branch1_out)\n",
    "        \n",
    "        # Branch 2: 1x1 -> 5x5 with stride 2\n",
    "        branch2_out = self.branch2_conv1(inputs)\n",
    "        branch2_out = self.branch2_conv2(branch2_out)\n",
    "        \n",
    "        # Branch 3: Max pooling with stride 2\n",
    "        branch3_out = self.branch3_pool(inputs)\n",
    "        \n",
    "        return layers.Concatenate(axis=-1)([branch1_out, branch2_out, branch3_out])\n",
    "    \n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\n",
    "            'n3x3_reduce': self.n3x3_reduce,\n",
    "            'n3x3': self.n3x3,\n",
    "            'n5x5_reduce': self.n5x5_reduce,\n",
    "            'n5x5': self.n5x5\n",
    "        })\n",
    "        return config\n",
    "\n",
    "def create_facenet_nn2(input_shape=(224, 224, 3), embedding_dim=128, num_classes=None, dropout=0.5):\n",
    "    \"\"\"\n",
    "    Create FaceNet NN2 model using Keras Functional API\n",
    "    \n",
    "    Args:\n",
    "        input_shape: Input image shape (default: (224, 224, 3))\n",
    "        embedding_dim: Dimension of face embeddings (default: 128)\n",
    "        num_classes: Number of identities for classification (optional)\n",
    "        dropout: Dropout rate before final FC layer (default: 0.5)\n",
    "    \n",
    "    Returns:\n",
    "        Keras Model\n",
    "    \"\"\"\n",
    "    \n",
    "    inputs = layers.Input(shape=input_shape, name='input_image')\n",
    "    \n",
    "    # Layer 1: Initial convolution (7x7, stride 2)\n",
    "    x = layers.Conv2D(64, 7, strides=2, padding='same', activation='relu',\n",
    "                     kernel_initializer=HeNormal(), name='conv1')(inputs)\n",
    "    \n",
    "    # Layer 2: Max pooling + normalization\n",
    "    x = layers.MaxPooling2D(3, strides=2, padding='same', name='maxpool1')(x)\n",
    "    x = tf.nn.local_response_normalization(x, depth_radius=2, bias=1.0, \n",
    "                                          alpha=0.0001, beta=0.75, name='norm1')\n",
    "    \n",
    "    # Layer 3: Inception (2) - 56x56x64 -> 56x56x192\n",
    "    x = layers.Conv2D(64, 1, activation='relu', kernel_initializer=HeNormal(),\n",
    "                     name='inception2_1x1')(x)\n",
    "    x = layers.Conv2D(192, 3, padding='same', activation='relu', \n",
    "                     kernel_initializer=HeNormal(), name='inception2_3x3')(x)\n",
    "    \n",
    "    # Layer 4: Normalization + max pooling\n",
    "    x = tf.nn.local_response_normalization(x, depth_radius=2, bias=1.0,\n",
    "                                          alpha=0.0001, beta=0.75, name='norm2')\n",
    "    x = layers.MaxPooling2D(3, strides=2, padding='same', name='maxpool2')(x)\n",
    "    \n",
    "    # Layer 5: Inception (3a) - 28x28x192 -> 28x28x256\n",
    "    x = InceptionModule(n1x1=64, n3x3_reduce=96, n3x3=128,\n",
    "                       n5x5_reduce=16, n5x5=32, pool_proj=32, \n",
    "                       pool_type='max', name='inception3a')(x)\n",
    "    \n",
    "    # Layer 6: Inception (3b) - 28x28x256 -> 28x28x320\n",
    "    x = InceptionModule(n1x1=64, n3x3_reduce=96, n3x3=128,\n",
    "                       n5x5_reduce=32, n5x5=64, pool_proj=64,\n",
    "                       pool_type='L2', name='inception3b')(x)\n",
    "    \n",
    "    # Layer 7: Inception (3c) - 28x28x320 -> 14x14x640\n",
    "    x = InceptionWithStride(n3x3_reduce=128, n3x3=256,\n",
    "                           n5x5_reduce=32, n5x5=64, name='inception3c')(x)\n",
    "    \n",
    "    # Layer 8: Inception (4a) - 14x14x640 -> 14x14x640\n",
    "    x = InceptionModule(n1x1=256, n3x3_reduce=96, n3x3=192,\n",
    "                       n5x5_reduce=32, n5x5=64, pool_proj=128,\n",
    "                       pool_type='L2', name='inception4a')(x)\n",
    "    \n",
    "    # Layer 9: Inception (4b) - 14x14x640 -> 14x14x640\n",
    "    x = InceptionModule(n1x1=224, n3x3_reduce=112, n3x3=224,\n",
    "                       n5x5_reduce=32, n5x5=64, pool_proj=128,\n",
    "                       pool_type='L2', name='inception4b')(x)\n",
    "    \n",
    "    # Layer 10: Inception (4c) - 14x14x640 -> 14x14x640\n",
    "    x = InceptionModule(n1x1=192, n3x3_reduce=128, n3x3=256,\n",
    "                       n5x5_reduce=32, n5x5=64, pool_proj=128,\n",
    "                       pool_type='L2', name='inception4c')(x)\n",
    "    \n",
    "    # Layer 11: Inception (4d) - 14x14x640 -> 14x14x640\n",
    "    x = InceptionModule(n1x1=160, n3x3_reduce=144, n3x3=288,\n",
    "                       n5x5_reduce=32, n5x5=64, pool_proj=128,\n",
    "                       pool_type='L2', name='inception4d')(x)\n",
    "    \n",
    "    # Layer 12: Inception (4e) - 14x14x640 -> 7x7x1024\n",
    "    x = InceptionWithStride(n3x3_reduce=160, n3x3=256,\n",
    "                           n5x5_reduce=64, n5x5=128, name='inception4e')(x)\n",
    "    \n",
    "    # Layer 13: Inception (5a) - 7x7x1024 -> 7x7x1024\n",
    "    x = InceptionModule(n1x1=384, n3x3_reduce=192, n3x3=384,\n",
    "                       n5x5_reduce=48, n5x5=128, pool_proj=128,\n",
    "                       pool_type='L2', name='inception5a')(x)\n",
    "    \n",
    "    # Layer 14: Inception (5b) - 7x7x1024 -> 7x7x1024\n",
    "    x = InceptionModule(n1x1=384, n3x3_reduce=192, n3x3=384,\n",
    "                       n5x5_reduce=48, n5x5=128, pool_proj=128,\n",
    "                       pool_type='max', name='inception5b')(x)\n",
    "    \n",
    "    # Layer 15: Average pooling\n",
    "    x = layers.GlobalAveragePooling2D(name='avgpool')(x)\n",
    "    \n",
    "    # Layer 16: Fully connected layer\n",
    "    if dropout > 0:\n",
    "        x = layers.Dropout(dropout, name='dropout')(x)\n",
    "    \n",
    "    embeddings = layers.Dense(embedding_dim, kernel_initializer=RandomNormal(stddev=0.01),\n",
    "                             name='embeddings')(x)\n",
    "    \n",
    "    # Layer 17: L2 normalization\n",
    "    embeddings = tf.nn.l2_normalize(embeddings, axis=1, name='l2_normalization')\n",
    "\n",
    "\n",
    "    # Optional classification layer for training\n",
    "    if num_classes is not None:\n",
    "        logits = layers.Dense(num_classes, kernel_initializer=RandomNormal(stddev=0.01),\n",
    "                             name='logits')(embeddings)\n",
    "        model = Model(inputs=inputs, outputs=[embeddings, logits], name='FaceNet_NN2')\n",
    "    else:\n",
    "        model = Model(inputs=inputs, outputs=embeddings, name='FaceNet_NN2')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "37e6cf01",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1c4d0d8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.9.2\n",
      "2.10.0\n"
     ]
    }
   ],
   "source": [
    "print(matplotlib.__version__)\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "88b5c5af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image_paths_by_class(dataset_path):\n",
    "    \n",
    "    #สร้าง dictionary \n",
    "    class_image_paths = {}\n",
    "\n",
    "    for class_name in os.listdir(dataset_path): #os.listdir ดึงรายชื่อไฟล์/โฟเดอร์ใน paht\n",
    "        class_dir = os.path.join(dataset_path, class_name)#os.path.join = images\\photo.jpg\n",
    "        #print(class_dir)\n",
    "        if os.path.isdir(class_dir):#ตรวจสอบclass_dir เป็นโฟลเดอร์ถ้าเป็นโฟลเดอร์ จะเข้าไปทำงานต่อ\n",
    "            image_files = [ \n",
    "                os.path.join(class_dir, img) #\n",
    "                for img in os.listdir(class_dir) # ดึงรายชื่อ\n",
    "                if img.lower().endswith(('.jpg', '.jpeg', '.png')) #\n",
    "            ]\n",
    "            if len(image_files) >= 12:  # ขั้นต่ำ 3 ภาพผป\n",
    "                class_image_paths[class_name] = image_files # สร้าง dictionary\n",
    "\n",
    "    return class_image_paths\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "df934d51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14032\n"
     ]
    }
   ],
   "source": [
    "dataset_path = r'C:\\InceptionNet\\mediamdata' \n",
    "dataset_path3 = r\"C:\\InceptionNet\\GLint360K\\glint360k_3\"\n",
    "dic = load_image_paths_by_class(dataset_path3)\n",
    "print(len(dic))\n",
    "#print(dictm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e1668f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = list(dic.keys())\n",
    "#print(classes)\n",
    "#print(len(classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "167006af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "จำนวนคลาสสำหรับ Training: 11225\n",
      "จำนวนคลาสสำหรับ Validation: 2807\n"
     ]
    }
   ],
   "source": [
    "train_classes, val_classes = train_test_split(classes, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"จำนวนคลาสสำหรับ Training: {len(train_classes)}\")\n",
    "print(f\"จำนวนคลาสสำหรับ Validation: {len(val_classes)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b2971923",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ขนาดของ Dictionary สำหรับ Training: 11225\n",
      "ขนาดของ Dictionary สำหรับ Validation: 2807\n"
     ]
    }
   ],
   "source": [
    "train_image_dict1 = {\n",
    "    class_name: dic[class_name]\n",
    "    for class_name in train_classes\n",
    "}\n",
    "\n",
    "# สร้าง dictionary สำหรับ Validation\n",
    "val_image_dict1 = {\n",
    "    class_name: dic[class_name]\n",
    "    for class_name in val_classes\n",
    "}\n",
    "print(f\"ขนาดของ Dictionary สำหรับ Training: {len(train_image_dict1)}\")\n",
    "print(f\"ขนาดของ Dictionary สำหรับ Validation: {len(val_image_dict1)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d9b9826d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- รายชื่อคลาสสำหรับ Validation ---\n",
      "264427\n",
      "325435\n",
      "170797\n",
      "107026\n",
      "192910\n",
      "267447\n",
      "275211\n",
      "291875\n",
      "2299\n",
      "38893\n",
      "254775\n",
      "257934\n",
      "298845\n",
      "190328\n",
      "68713\n",
      "38295\n",
      "283094\n",
      "176427\n",
      "6511\n",
      "233570\n",
      "269177\n",
      "162807\n",
      "171064\n",
      "20137\n",
      "302913\n",
      "165467\n",
      "174469\n",
      "222770\n",
      "358956\n",
      "149532\n",
      "104860\n",
      "18399\n",
      "346805\n",
      "43783\n",
      "192658\n",
      "315225\n",
      "259712\n",
      "41120\n",
      "52053\n",
      "206048\n",
      "312885\n",
      "209426\n",
      "144345\n",
      "326979\n",
      "304320\n",
      "264490\n",
      "64413\n",
      "88187\n",
      "253434\n",
      "36735\n",
      "139025\n",
      "240142\n",
      "275942\n",
      "113325\n",
      "156648\n",
      "232220\n",
      "121324\n",
      "173586\n",
      "141331\n",
      "156270\n",
      "222925\n",
      "236203\n",
      "308003\n",
      "74526\n",
      "60177\n",
      "88447\n",
      "334234\n",
      "283994\n",
      "317656\n",
      "179217\n",
      "38350\n",
      "166236\n",
      "317606\n",
      "291314\n",
      "305888\n",
      "313289\n",
      "216339\n",
      "252153\n",
      "278997\n",
      "193538\n",
      "311686\n",
      "158496\n",
      "67789\n",
      "259305\n",
      "37273\n",
      "167243\n",
      "232522\n",
      "122471\n",
      "240077\n",
      "168774\n",
      "211264\n",
      "143428\n",
      "180315\n",
      "227541\n",
      "259134\n",
      "208533\n",
      "333068\n",
      "129305\n",
      "275125\n",
      "333903\n",
      "78360\n",
      "195166\n",
      "33602\n",
      "198954\n",
      "1244\n",
      "221761\n",
      "232257\n",
      "328833\n",
      "107650\n",
      "151845\n",
      "112970\n",
      "51363\n",
      "295792\n",
      "233066\n",
      "331256\n",
      "176331\n",
      "46401\n",
      "290345\n",
      "214706\n",
      "177052\n",
      "88773\n",
      "301279\n",
      "271749\n",
      "117671\n",
      "88073\n",
      "304655\n",
      "37119\n",
      "10849\n",
      "126113\n",
      "77863\n",
      "191435\n",
      "211060\n",
      "96432\n",
      "128853\n",
      "115722\n",
      "14713\n",
      "358533\n",
      "143789\n",
      "103654\n",
      "46351\n",
      "137868\n",
      "140211\n",
      "329321\n",
      "13123\n",
      "100307\n",
      "302418\n",
      "323036\n",
      "27602\n",
      "110401\n",
      "19101\n",
      "212359\n",
      "60604\n",
      "16851\n",
      "128722\n",
      "224958\n",
      "21761\n",
      "281026\n",
      "65946\n",
      "301183\n",
      "344636\n",
      "154740\n",
      "320310\n",
      "273870\n",
      "103651\n",
      "197774\n",
      "158050\n",
      "230012\n",
      "182170\n",
      "22202\n",
      "224501\n",
      "292517\n",
      "68539\n",
      "259181\n",
      "222512\n",
      "247649\n",
      "213676\n",
      "271063\n",
      "181638\n",
      "239940\n",
      "239338\n",
      "195945\n",
      "323388\n",
      "306996\n",
      "116839\n",
      "185808\n",
      "171667\n",
      "228616\n",
      "234425\n",
      "25600\n",
      "59803\n",
      "305168\n",
      "65725\n",
      "191667\n",
      "264522\n",
      "18327\n",
      "121778\n",
      "142653\n",
      "329731\n",
      "260069\n",
      "162013\n",
      "136697\n",
      "55142\n",
      "38179\n",
      "316294\n",
      "269705\n",
      "289725\n",
      "248580\n",
      "266645\n",
      "169659\n",
      "296531\n",
      "18555\n",
      "289582\n",
      "189472\n",
      "246234\n",
      "347990\n",
      "199111\n",
      "263832\n",
      "132821\n",
      "273349\n",
      "338466\n",
      "192072\n",
      "338679\n",
      "337820\n",
      "323020\n",
      "282692\n",
      "231040\n",
      "290498\n",
      "152659\n",
      "74010\n",
      "135519\n",
      "115686\n",
      "302752\n",
      "56025\n",
      "309336\n",
      "92999\n",
      "330096\n",
      "34735\n",
      "39411\n",
      "49725\n",
      "106359\n",
      "74167\n",
      "155359\n",
      "342567\n",
      "293640\n",
      "276714\n",
      "106464\n",
      "354525\n",
      "332202\n",
      "233311\n",
      "330639\n",
      "205787\n",
      "240103\n",
      "96386\n",
      "56765\n",
      "127637\n",
      "222551\n",
      "103713\n",
      "242866\n",
      "154886\n",
      "121084\n",
      "268768\n",
      "82776\n",
      "358365\n",
      "102301\n",
      "69911\n",
      "258263\n",
      "234449\n",
      "261840\n",
      "342484\n",
      "189085\n",
      "74981\n",
      "135120\n",
      "301157\n",
      "52465\n",
      "300635\n",
      "177196\n",
      "63303\n",
      "9908\n",
      "53780\n",
      "22889\n",
      "343735\n",
      "17743\n",
      "224226\n",
      "313822\n",
      "328203\n",
      "259428\n",
      "76236\n",
      "132059\n",
      "229477\n",
      "137989\n",
      "226242\n",
      "4591\n",
      "312507\n",
      "248625\n",
      "107327\n",
      "109791\n",
      "217633\n",
      "90673\n",
      "324134\n",
      "190577\n",
      "160264\n",
      "21968\n",
      "172429\n",
      "310190\n",
      "333457\n",
      "254805\n",
      "224446\n",
      "29480\n",
      "309233\n",
      "38397\n",
      "193456\n",
      "110023\n",
      "293674\n",
      "302005\n",
      "42610\n",
      "168653\n",
      "96748\n",
      "155841\n",
      "124516\n",
      "215138\n",
      "348923\n",
      "191854\n",
      "100809\n",
      "37944\n",
      "230251\n",
      "128552\n",
      "82738\n",
      "226555\n",
      "6434\n",
      "203035\n",
      "151160\n",
      "349758\n",
      "177347\n",
      "85827\n",
      "324160\n",
      "180428\n",
      "29917\n",
      "10234\n",
      "176575\n",
      "75022\n",
      "293654\n",
      "266956\n",
      "295143\n",
      "194605\n",
      "226878\n",
      "305280\n",
      "274476\n",
      "86422\n",
      "51078\n",
      "117077\n",
      "329189\n",
      "54268\n",
      "305250\n",
      "52588\n",
      "37256\n",
      "146054\n",
      "84925\n",
      "336834\n",
      "315776\n",
      "155286\n",
      "126364\n",
      "280329\n",
      "346966\n",
      "300118\n",
      "297125\n",
      "231599\n",
      "135985\n",
      "198990\n",
      "295646\n",
      "167227\n",
      "58881\n",
      "18644\n",
      "243194\n",
      "323501\n",
      "146271\n",
      "210000\n",
      "27764\n",
      "300245\n",
      "107798\n",
      "162277\n",
      "67713\n",
      "103972\n",
      "80629\n",
      "297041\n",
      "283022\n",
      "134591\n",
      "189110\n",
      "126417\n",
      "317065\n",
      "12943\n",
      "344910\n",
      "263910\n",
      "189485\n",
      "344277\n",
      "35871\n",
      "251408\n",
      "230186\n",
      "235101\n",
      "20848\n",
      "19004\n",
      "239994\n",
      "18122\n",
      "148194\n",
      "203440\n",
      "134196\n",
      "315307\n",
      "126679\n",
      "322302\n",
      "334948\n",
      "200394\n",
      "44961\n",
      "294065\n",
      "23851\n",
      "92424\n",
      "75452\n",
      "286255\n",
      "286973\n",
      "302028\n",
      "2750\n",
      "315146\n",
      "163477\n",
      "229921\n",
      "62667\n",
      "14638\n",
      "174883\n",
      "47401\n",
      "239499\n",
      "250640\n",
      "99039\n",
      "291673\n",
      "106179\n",
      "93948\n",
      "192232\n",
      "44268\n",
      "85012\n",
      "64621\n",
      "280794\n",
      "347724\n",
      "309889\n",
      "255694\n",
      "351867\n",
      "81076\n",
      "3394\n",
      "332091\n",
      "14598\n",
      "17586\n",
      "63718\n",
      "169592\n",
      "136174\n",
      "28799\n",
      "190718\n",
      "299317\n",
      "136107\n",
      "64408\n",
      "272753\n",
      "60751\n",
      "108758\n",
      "347942\n",
      "97753\n",
      "137867\n",
      "324676\n",
      "282935\n",
      "2908\n",
      "136574\n",
      "343643\n",
      "12088\n",
      "217954\n",
      "158945\n",
      "33528\n",
      "58888\n",
      "301399\n",
      "304426\n",
      "183728\n",
      "187961\n",
      "200498\n",
      "188382\n",
      "209433\n",
      "151899\n",
      "160550\n",
      "235085\n",
      "2115\n",
      "345314\n",
      "56881\n",
      "236873\n",
      "144150\n",
      "60448\n",
      "16982\n",
      "62692\n",
      "285875\n",
      "137333\n",
      "96086\n",
      "190732\n",
      "88211\n",
      "132349\n",
      "252394\n",
      "500\n",
      "6388\n",
      "90043\n",
      "233300\n",
      "212313\n",
      "281792\n",
      "59297\n",
      "260434\n",
      "97309\n",
      "246079\n",
      "123781\n",
      "311305\n",
      "239080\n",
      "172659\n",
      "272092\n",
      "268283\n",
      "115290\n",
      "181139\n",
      "205710\n",
      "16244\n",
      "145402\n",
      "58916\n",
      "2434\n",
      "51193\n",
      "201499\n",
      "76114\n",
      "217411\n",
      "175151\n",
      "188087\n",
      "130697\n",
      "33244\n",
      "292855\n",
      "183849\n",
      "281701\n",
      "304791\n",
      "325086\n",
      "109710\n",
      "167843\n",
      "75365\n",
      "168647\n",
      "135219\n",
      "23856\n",
      "48542\n",
      "279459\n",
      "234790\n",
      "334462\n",
      "33535\n",
      "148537\n",
      "114868\n",
      "294632\n",
      "325695\n",
      "77673\n",
      "86970\n",
      "4062\n",
      "346753\n",
      "66251\n",
      "186884\n",
      "252366\n",
      "259573\n",
      "103820\n",
      "346678\n",
      "9501\n",
      "115348\n",
      "109793\n",
      "183780\n",
      "44321\n",
      "148932\n",
      "95974\n",
      "101509\n",
      "258596\n",
      "154838\n",
      "351303\n",
      "308316\n",
      "15555\n",
      "88269\n",
      "77762\n",
      "30911\n",
      "26325\n",
      "224143\n",
      "124373\n",
      "108153\n",
      "151451\n",
      "12880\n",
      "51996\n",
      "74761\n",
      "298668\n",
      "305435\n",
      "295976\n",
      "223318\n",
      "247566\n",
      "49152\n",
      "150609\n",
      "42530\n",
      "245296\n",
      "135887\n",
      "5952\n",
      "29875\n",
      "46159\n",
      "236231\n",
      "100164\n",
      "226732\n",
      "158589\n",
      "254872\n",
      "296998\n",
      "315439\n",
      "71146\n",
      "319151\n",
      "250342\n",
      "219593\n",
      "166457\n",
      "336737\n",
      "249344\n",
      "17895\n",
      "127274\n",
      "301774\n",
      "291964\n",
      "19839\n",
      "87974\n",
      "344882\n",
      "306337\n",
      "197689\n",
      "271745\n",
      "225147\n",
      "135052\n",
      "261886\n",
      "253303\n",
      "197890\n",
      "258911\n",
      "80925\n",
      "186956\n",
      "192133\n",
      "341446\n",
      "147815\n",
      "187223\n",
      "54711\n",
      "98589\n",
      "123326\n",
      "353456\n",
      "175663\n",
      "7769\n",
      "89912\n",
      "94465\n",
      "282624\n",
      "244958\n",
      "176307\n",
      "238127\n",
      "27910\n",
      "224966\n",
      "183349\n",
      "236988\n",
      "75739\n",
      "243451\n",
      "312279\n",
      "302195\n",
      "199845\n",
      "320334\n",
      "50567\n",
      "70359\n",
      "24265\n",
      "211\n",
      "330564\n",
      "317823\n",
      "278628\n",
      "184191\n",
      "227625\n",
      "129734\n",
      "316439\n",
      "339994\n",
      "141197\n",
      "262461\n",
      "85271\n",
      "330914\n",
      "278541\n",
      "171212\n",
      "42365\n",
      "115371\n",
      "76361\n",
      "299586\n",
      "170686\n",
      "39662\n",
      "225148\n",
      "340547\n",
      "285153\n",
      "358414\n",
      "261441\n",
      "112591\n",
      "4010\n",
      "187968\n",
      "240027\n",
      "124292\n",
      "281783\n",
      "48634\n",
      "266794\n",
      "175175\n",
      "19296\n",
      "189212\n",
      "138386\n",
      "270701\n",
      "36352\n",
      "319310\n",
      "312183\n",
      "80095\n",
      "309183\n",
      "351806\n",
      "7420\n",
      "325577\n",
      "125059\n",
      "34671\n",
      "305139\n",
      "323407\n",
      "358730\n",
      "71904\n",
      "273882\n",
      "65369\n",
      "254345\n",
      "278166\n",
      "351397\n",
      "310096\n",
      "231591\n",
      "101180\n",
      "71623\n",
      "58400\n",
      "305406\n",
      "189536\n",
      "222885\n",
      "156080\n",
      "262312\n",
      "65469\n",
      "305537\n",
      "40924\n",
      "92114\n",
      "193403\n",
      "346696\n",
      "86810\n",
      "76850\n",
      "252553\n",
      "278705\n",
      "168586\n",
      "108174\n",
      "78017\n",
      "251480\n",
      "221601\n",
      "262927\n",
      "129737\n",
      "227514\n",
      "172943\n",
      "134835\n",
      "330279\n",
      "11630\n",
      "210266\n",
      "42145\n",
      "15898\n",
      "164782\n",
      "244458\n",
      "170943\n",
      "279984\n",
      "33898\n",
      "169609\n",
      "63762\n",
      "24846\n",
      "224092\n",
      "310997\n",
      "89383\n",
      "19969\n",
      "38463\n",
      "146663\n",
      "36049\n",
      "194831\n",
      "119256\n",
      "261351\n",
      "233291\n",
      "194331\n",
      "231152\n",
      "344774\n",
      "343137\n",
      "7679\n",
      "111473\n",
      "149743\n",
      "59820\n",
      "239129\n",
      "286432\n",
      "98554\n",
      "97958\n",
      "28486\n",
      "156801\n",
      "216662\n",
      "197521\n",
      "152145\n",
      "158624\n",
      "239539\n",
      "294786\n",
      "203971\n",
      "75722\n",
      "13723\n",
      "259286\n",
      "111609\n",
      "277787\n",
      "185806\n",
      "55507\n",
      "266273\n",
      "235704\n",
      "177240\n",
      "30749\n",
      "278081\n",
      "272201\n",
      "325740\n",
      "191552\n",
      "121863\n",
      "233761\n",
      "87979\n",
      "295653\n",
      "1274\n",
      "29162\n",
      "257827\n",
      "137287\n",
      "59880\n",
      "79424\n",
      "61098\n",
      "56436\n",
      "312328\n",
      "196855\n",
      "77533\n",
      "21382\n",
      "344394\n",
      "90969\n",
      "33207\n",
      "283251\n",
      "95500\n",
      "28560\n",
      "216885\n",
      "3974\n",
      "349609\n",
      "153931\n",
      "15458\n",
      "22658\n",
      "196593\n",
      "240850\n",
      "129276\n",
      "137242\n",
      "192827\n",
      "266651\n",
      "97782\n",
      "341819\n",
      "10825\n",
      "244371\n",
      "278852\n",
      "50894\n",
      "198685\n",
      "189949\n",
      "188585\n",
      "46070\n",
      "252097\n",
      "28758\n",
      "106696\n",
      "134036\n",
      "251670\n",
      "106784\n",
      "309416\n",
      "279869\n",
      "297121\n",
      "269457\n",
      "107735\n",
      "112930\n",
      "123604\n",
      "49184\n",
      "265926\n",
      "292289\n",
      "110203\n",
      "155201\n",
      "137692\n",
      "154971\n",
      "177540\n",
      "168009\n",
      "24389\n",
      "214410\n",
      "227314\n",
      "9861\n",
      "225358\n",
      "83463\n",
      "81211\n",
      "48999\n",
      "87302\n",
      "277041\n",
      "315907\n",
      "68318\n",
      "73992\n",
      "233504\n",
      "118827\n",
      "89419\n",
      "60013\n",
      "331439\n",
      "74192\n",
      "69559\n",
      "296227\n",
      "235988\n",
      "19106\n",
      "329369\n",
      "58431\n",
      "105611\n",
      "173638\n",
      "295936\n",
      "275\n",
      "315537\n",
      "114643\n",
      "79655\n",
      "118311\n",
      "29012\n",
      "133505\n",
      "158164\n",
      "293670\n",
      "21599\n",
      "284638\n",
      "186806\n",
      "122960\n",
      "16670\n",
      "180198\n",
      "111098\n",
      "101595\n",
      "356609\n",
      "346583\n",
      "293279\n",
      "331730\n",
      "82561\n",
      "148286\n",
      "122149\n",
      "323179\n",
      "30486\n",
      "77709\n",
      "9274\n",
      "142925\n",
      "212969\n",
      "221613\n",
      "292707\n",
      "187915\n",
      "354537\n",
      "176804\n",
      "309827\n",
      "17873\n",
      "49876\n",
      "101074\n",
      "138470\n",
      "21600\n",
      "32124\n",
      "247519\n",
      "19950\n",
      "120068\n",
      "312363\n",
      "228231\n",
      "56906\n",
      "136571\n",
      "755\n",
      "232962\n",
      "50450\n",
      "302425\n",
      "314384\n",
      "78916\n",
      "36990\n",
      "179161\n",
      "179351\n",
      "299992\n",
      "220709\n",
      "34020\n",
      "256458\n",
      "186955\n",
      "172443\n",
      "174993\n",
      "286928\n",
      "94802\n",
      "130445\n",
      "3288\n",
      "27826\n",
      "203492\n",
      "236915\n",
      "71049\n",
      "137702\n",
      "349416\n",
      "269737\n",
      "52647\n",
      "271136\n",
      "299410\n",
      "226647\n",
      "272169\n",
      "235040\n",
      "181607\n",
      "129696\n",
      "319827\n",
      "130014\n",
      "297664\n",
      "323070\n",
      "214904\n",
      "274244\n",
      "320677\n",
      "104848\n",
      "89188\n",
      "334067\n",
      "458\n",
      "334694\n",
      "246911\n",
      "288640\n",
      "17505\n",
      "9291\n",
      "159009\n",
      "301334\n",
      "187289\n",
      "213747\n",
      "68798\n",
      "273335\n",
      "166332\n",
      "331489\n",
      "30766\n",
      "119199\n",
      "31332\n",
      "104096\n",
      "146842\n",
      "106337\n",
      "9397\n",
      "163390\n",
      "23882\n",
      "329055\n",
      "185017\n",
      "272332\n",
      "265398\n",
      "326855\n",
      "205318\n",
      "306268\n",
      "289724\n",
      "122560\n",
      "246292\n",
      "16315\n",
      "196333\n",
      "112751\n",
      "84012\n",
      "193316\n",
      "111532\n",
      "40055\n",
      "156897\n",
      "29194\n",
      "290012\n",
      "216916\n",
      "354285\n",
      "182974\n",
      "32826\n",
      "48375\n",
      "131626\n",
      "293606\n",
      "269976\n",
      "16337\n",
      "83184\n",
      "144676\n",
      "216555\n",
      "238788\n",
      "152559\n",
      "198068\n",
      "244484\n",
      "351425\n",
      "73770\n",
      "153254\n",
      "50713\n",
      "181823\n",
      "20914\n",
      "246357\n",
      "232723\n",
      "232288\n",
      "159948\n",
      "109989\n",
      "144271\n",
      "10263\n",
      "307491\n",
      "146998\n",
      "7233\n",
      "246263\n",
      "260135\n",
      "100834\n",
      "64401\n",
      "2707\n",
      "287299\n",
      "224459\n",
      "18620\n",
      "66997\n",
      "272087\n",
      "57898\n",
      "118453\n",
      "290517\n",
      "139377\n",
      "341618\n",
      "63225\n",
      "354790\n",
      "277251\n",
      "172019\n",
      "266866\n",
      "326551\n",
      "165157\n",
      "146946\n",
      "273120\n",
      "208916\n",
      "31672\n",
      "252956\n",
      "47010\n",
      "302312\n",
      "13120\n",
      "229480\n",
      "213576\n",
      "318007\n",
      "22790\n",
      "247135\n",
      "132932\n",
      "238059\n",
      "51546\n",
      "5175\n",
      "195291\n",
      "258182\n",
      "150558\n",
      "227222\n",
      "38216\n",
      "98986\n",
      "19018\n",
      "339930\n",
      "268429\n",
      "137538\n",
      "64522\n",
      "249698\n",
      "95574\n",
      "144292\n",
      "17847\n",
      "144263\n",
      "272320\n",
      "250643\n",
      "122316\n",
      "153376\n",
      "161804\n",
      "311717\n",
      "267243\n",
      "285379\n",
      "133369\n",
      "172655\n",
      "303053\n",
      "121635\n",
      "299368\n",
      "237711\n",
      "251537\n",
      "268097\n",
      "25643\n",
      "294830\n",
      "350497\n",
      "295677\n",
      "143519\n",
      "281039\n",
      "103645\n",
      "274694\n",
      "302017\n",
      "198807\n",
      "193104\n",
      "298083\n",
      "350220\n",
      "355937\n",
      "50160\n",
      "181515\n",
      "73868\n",
      "355430\n",
      "258407\n",
      "44422\n",
      "193635\n",
      "154876\n",
      "56751\n",
      "75217\n",
      "201077\n",
      "351239\n",
      "292916\n",
      "258523\n",
      "192954\n",
      "152389\n",
      "163949\n",
      "35955\n",
      "81619\n",
      "105598\n",
      "207471\n",
      "41774\n",
      "56969\n",
      "245835\n",
      "358394\n",
      "110961\n",
      "204241\n",
      "280226\n",
      "328595\n",
      "81551\n",
      "291991\n",
      "224698\n",
      "332858\n",
      "67615\n",
      "68016\n",
      "92268\n",
      "288807\n",
      "295089\n",
      "287655\n",
      "36032\n",
      "103005\n",
      "109291\n",
      "206291\n",
      "306068\n",
      "191787\n",
      "68469\n",
      "41174\n",
      "283253\n",
      "152717\n",
      "35181\n",
      "44277\n",
      "300813\n",
      "219937\n",
      "71966\n",
      "316207\n",
      "216911\n",
      "94249\n",
      "355879\n",
      "315329\n",
      "132498\n",
      "32866\n",
      "282455\n",
      "197031\n",
      "340895\n",
      "206773\n",
      "85445\n",
      "96547\n",
      "234072\n",
      "160809\n",
      "138687\n",
      "348468\n",
      "183325\n",
      "281095\n",
      "63619\n",
      "14345\n",
      "97322\n",
      "120342\n",
      "93407\n",
      "117456\n",
      "200016\n",
      "174766\n",
      "118560\n",
      "217484\n",
      "89287\n",
      "354568\n",
      "125675\n",
      "89960\n",
      "49225\n",
      "21077\n",
      "89077\n",
      "336272\n",
      "264704\n",
      "123676\n",
      "172649\n",
      "7299\n",
      "134332\n",
      "108769\n",
      "126084\n",
      "130256\n",
      "23348\n",
      "279377\n",
      "252344\n",
      "132429\n",
      "264813\n",
      "249804\n",
      "115084\n",
      "256631\n",
      "82705\n",
      "129300\n",
      "190321\n",
      "1476\n",
      "185068\n",
      "275011\n",
      "184412\n",
      "158604\n",
      "248110\n",
      "277919\n",
      "106624\n",
      "288995\n",
      "346684\n",
      "180788\n",
      "69934\n",
      "34185\n",
      "25891\n",
      "30280\n",
      "96518\n",
      "62027\n",
      "152320\n",
      "201859\n",
      "150580\n",
      "239462\n",
      "64536\n",
      "240187\n",
      "68524\n",
      "356975\n",
      "125985\n",
      "291021\n",
      "241083\n",
      "102724\n",
      "326328\n",
      "250868\n",
      "306817\n",
      "262179\n",
      "320961\n",
      "358300\n",
      "258039\n",
      "344115\n",
      "8186\n",
      "185718\n",
      "113911\n",
      "293333\n",
      "296381\n",
      "98838\n",
      "99566\n",
      "96641\n",
      "272076\n",
      "211634\n",
      "263504\n",
      "162585\n",
      "18392\n",
      "114753\n",
      "340763\n",
      "323575\n",
      "295654\n",
      "83492\n",
      "264586\n",
      "103267\n",
      "274655\n",
      "154643\n",
      "248181\n",
      "83959\n",
      "18347\n",
      "247499\n",
      "49761\n",
      "221527\n",
      "310266\n",
      "165971\n",
      "7709\n",
      "265650\n",
      "28031\n",
      "6366\n",
      "134254\n",
      "22723\n",
      "54676\n",
      "48779\n",
      "258559\n",
      "285398\n",
      "359057\n",
      "169124\n",
      "281961\n",
      "297156\n",
      "148362\n",
      "16827\n",
      "352596\n",
      "195586\n",
      "145080\n",
      "81805\n",
      "6307\n",
      "86349\n",
      "155538\n",
      "312203\n",
      "53318\n",
      "100824\n",
      "134833\n",
      "330002\n",
      "38504\n",
      "299736\n",
      "158307\n",
      "207620\n",
      "331653\n",
      "205594\n",
      "143081\n",
      "120030\n",
      "143070\n",
      "350573\n",
      "119539\n",
      "305293\n",
      "248226\n",
      "268653\n",
      "336237\n",
      "303013\n",
      "67711\n",
      "305203\n",
      "335132\n",
      "30077\n",
      "142894\n",
      "200913\n",
      "256420\n",
      "313209\n",
      "116055\n",
      "227395\n",
      "189339\n",
      "123765\n",
      "77292\n",
      "328045\n",
      "207157\n",
      "297398\n",
      "9384\n",
      "121091\n",
      "233536\n",
      "159498\n",
      "201175\n",
      "101205\n",
      "311078\n",
      "146100\n",
      "355229\n",
      "91028\n",
      "74861\n",
      "287326\n",
      "303317\n",
      "13529\n",
      "250884\n",
      "300473\n",
      "315837\n",
      "153735\n",
      "269625\n",
      "147459\n",
      "223129\n",
      "62576\n",
      "98860\n",
      "175555\n",
      "50278\n",
      "302670\n",
      "222584\n",
      "240723\n",
      "59894\n",
      "39698\n",
      "237347\n",
      "325629\n",
      "108402\n",
      "24397\n",
      "17991\n",
      "197461\n",
      "172257\n",
      "186232\n",
      "99651\n",
      "42785\n",
      "66014\n",
      "261734\n",
      "120183\n",
      "301366\n",
      "15285\n",
      "117242\n",
      "109315\n",
      "195913\n",
      "12249\n",
      "47288\n",
      "88218\n",
      "246239\n",
      "104530\n",
      "347186\n",
      "94333\n",
      "56875\n",
      "344135\n",
      "209272\n",
      "105630\n",
      "113045\n",
      "274948\n",
      "198697\n",
      "317779\n",
      "240960\n",
      "218950\n",
      "20293\n",
      "340281\n",
      "132348\n",
      "355607\n",
      "103244\n",
      "177624\n",
      "90244\n",
      "3721\n",
      "262869\n",
      "154843\n",
      "274407\n",
      "26246\n",
      "354545\n",
      "130523\n",
      "234026\n",
      "11605\n",
      "202530\n",
      "15133\n",
      "201476\n",
      "176516\n",
      "198635\n",
      "49517\n",
      "20773\n",
      "256436\n",
      "217694\n",
      "41334\n",
      "333589\n",
      "26704\n",
      "311443\n",
      "147453\n",
      "48133\n",
      "9997\n",
      "179807\n",
      "207835\n",
      "101904\n",
      "86725\n",
      "240205\n",
      "13694\n",
      "71287\n",
      "248812\n",
      "262795\n",
      "175400\n",
      "297787\n",
      "179289\n",
      "109274\n",
      "167178\n",
      "149814\n",
      "214041\n",
      "212632\n",
      "4428\n",
      "216706\n",
      "308459\n",
      "355202\n",
      "358011\n",
      "303731\n",
      "6991\n",
      "327788\n",
      "106538\n",
      "18669\n",
      "172603\n",
      "177332\n",
      "309961\n",
      "328198\n",
      "113542\n",
      "181181\n",
      "113858\n",
      "264347\n",
      "163709\n",
      "350107\n",
      "258170\n",
      "223333\n",
      "168891\n",
      "208835\n",
      "133481\n",
      "301408\n",
      "39756\n",
      "319364\n",
      "267051\n",
      "236436\n",
      "110286\n",
      "84494\n",
      "329879\n",
      "324113\n",
      "102363\n",
      "314252\n",
      "125397\n",
      "137995\n",
      "234446\n",
      "129993\n",
      "81328\n",
      "292945\n",
      "181537\n",
      "155572\n",
      "326156\n",
      "113752\n",
      "205166\n",
      "85590\n",
      "260126\n",
      "131726\n",
      "330577\n",
      "25244\n",
      "28781\n",
      "80405\n",
      "192883\n",
      "220217\n",
      "6692\n",
      "305360\n",
      "220206\n",
      "63017\n",
      "144576\n",
      "111621\n",
      "34857\n",
      "134428\n",
      "65142\n",
      "152178\n",
      "358726\n",
      "321504\n",
      "283599\n",
      "268209\n",
      "142146\n",
      "219718\n",
      "5271\n",
      "332066\n",
      "294453\n",
      "115560\n",
      "345804\n",
      "218914\n",
      "10032\n",
      "167103\n",
      "62982\n",
      "303824\n",
      "326235\n",
      "36366\n",
      "52914\n",
      "260228\n",
      "235987\n",
      "177173\n",
      "303503\n",
      "314078\n",
      "114973\n",
      "151901\n",
      "81373\n",
      "209002\n",
      "213724\n",
      "206287\n",
      "172990\n",
      "143921\n",
      "190984\n",
      "332853\n",
      "358334\n",
      "99261\n",
      "54142\n",
      "328944\n",
      "117799\n",
      "158691\n",
      "96898\n",
      "138467\n",
      "213330\n",
      "191829\n",
      "323087\n",
      "95138\n",
      "137345\n",
      "355361\n",
      "278584\n",
      "115641\n",
      "342495\n",
      "56695\n",
      "120207\n",
      "125118\n",
      "213952\n",
      "271806\n",
      "348260\n",
      "143049\n",
      "45340\n",
      "211773\n",
      "206401\n",
      "81826\n",
      "74755\n",
      "168640\n",
      "67965\n",
      "45206\n",
      "358968\n",
      "4983\n",
      "111393\n",
      "262746\n",
      "193441\n",
      "158560\n",
      "262097\n",
      "284682\n",
      "84220\n",
      "356207\n",
      "69198\n",
      "211677\n",
      "29279\n",
      "199284\n",
      "63342\n",
      "211659\n",
      "331581\n",
      "50596\n",
      "28000\n",
      "155383\n",
      "39949\n",
      "128196\n",
      "245330\n",
      "183756\n",
      "255577\n",
      "26967\n",
      "315468\n",
      "316518\n",
      "119105\n",
      "964\n",
      "166044\n",
      "49033\n",
      "93839\n",
      "117374\n",
      "2634\n",
      "223102\n",
      "126705\n",
      "66117\n",
      "187422\n",
      "26952\n",
      "16993\n",
      "310312\n",
      "313507\n",
      "16988\n",
      "111483\n",
      "256934\n",
      "230813\n",
      "188392\n",
      "174624\n",
      "353995\n",
      "212162\n",
      "300009\n",
      "54835\n",
      "179613\n",
      "139080\n",
      "27977\n",
      "358091\n",
      "125782\n",
      "342994\n",
      "31583\n",
      "216624\n",
      "30470\n",
      "205569\n",
      "338878\n",
      "98461\n",
      "256636\n",
      "200218\n",
      "122665\n",
      "149267\n",
      "153574\n",
      "281311\n",
      "108057\n",
      "83402\n",
      "209202\n",
      "182640\n",
      "357206\n",
      "8558\n",
      "146906\n",
      "265402\n",
      "231781\n",
      "240428\n",
      "156418\n",
      "63946\n",
      "132471\n",
      "345446\n",
      "4015\n",
      "142534\n",
      "286409\n",
      "276642\n",
      "21274\n",
      "153657\n",
      "60237\n",
      "168888\n",
      "243407\n",
      "271689\n",
      "73451\n",
      "10411\n",
      "96417\n",
      "286443\n",
      "56\n",
      "332836\n",
      "293425\n",
      "93703\n",
      "215674\n",
      "301639\n",
      "338424\n",
      "225668\n",
      "206119\n",
      "220931\n",
      "277658\n",
      "191448\n",
      "157270\n",
      "273202\n",
      "132018\n",
      "198360\n",
      "321298\n",
      "318952\n",
      "356129\n",
      "30444\n",
      "346075\n",
      "57336\n",
      "252405\n",
      "171533\n",
      "282587\n",
      "22797\n",
      "239749\n",
      "82033\n",
      "276228\n",
      "328608\n",
      "335453\n",
      "63598\n",
      "246566\n",
      "126930\n",
      "219088\n",
      "248222\n",
      "305033\n",
      "218482\n",
      "253362\n",
      "11429\n",
      "200342\n",
      "238234\n",
      "339485\n",
      "6181\n",
      "119936\n",
      "319421\n",
      "1259\n",
      "95299\n",
      "183741\n",
      "176515\n",
      "10497\n",
      "111822\n",
      "128846\n",
      "14212\n",
      "329202\n",
      "322685\n",
      "156681\n",
      "321755\n",
      "283784\n",
      "94642\n",
      "199218\n",
      "330987\n",
      "3779\n",
      "327569\n",
      "107206\n",
      "239256\n",
      "54838\n",
      "5245\n",
      "50169\n",
      "233250\n",
      "7351\n",
      "71636\n",
      "36768\n",
      "85225\n",
      "54379\n",
      "349858\n",
      "89321\n",
      "6591\n",
      "350223\n",
      "312602\n",
      "38589\n",
      "136244\n",
      "272090\n",
      "346980\n",
      "170176\n",
      "212925\n",
      "279648\n",
      "283256\n",
      "298631\n",
      "115141\n",
      "318406\n",
      "206220\n",
      "47728\n",
      "263\n",
      "31957\n",
      "289563\n",
      "36894\n",
      "354939\n",
      "50903\n",
      "222088\n",
      "10948\n",
      "160800\n",
      "138989\n",
      "154017\n",
      "53286\n",
      "322749\n",
      "358348\n",
      "87919\n",
      "314475\n",
      "42207\n",
      "21029\n",
      "247885\n",
      "330729\n",
      "120516\n",
      "96434\n",
      "81315\n",
      "133803\n",
      "114398\n",
      "238096\n",
      "349018\n",
      "214813\n",
      "118627\n",
      "179357\n",
      "252263\n",
      "340651\n",
      "352714\n",
      "128652\n",
      "16828\n",
      "169006\n",
      "244877\n",
      "53037\n",
      "47537\n",
      "289439\n",
      "45147\n",
      "1197\n",
      "39481\n",
      "175965\n",
      "45133\n",
      "69865\n",
      "297135\n",
      "327147\n",
      "92616\n",
      "6330\n",
      "28412\n",
      "221685\n",
      "223278\n",
      "279883\n",
      "47340\n",
      "155171\n",
      "226556\n",
      "228580\n",
      "135331\n",
      "201084\n",
      "39685\n",
      "206479\n",
      "126933\n",
      "235381\n",
      "316462\n",
      "102336\n",
      "207018\n",
      "135268\n",
      "97315\n",
      "168369\n",
      "319457\n",
      "177982\n",
      "246732\n",
      "129381\n",
      "121095\n",
      "19335\n",
      "186585\n",
      "268657\n",
      "90756\n",
      "203361\n",
      "132394\n",
      "82855\n",
      "86641\n",
      "341401\n",
      "122113\n",
      "125350\n",
      "119519\n",
      "271930\n",
      "209218\n",
      "137079\n",
      "128755\n",
      "284984\n",
      "231341\n",
      "304818\n",
      "319865\n",
      "238177\n",
      "190280\n",
      "234780\n",
      "68018\n",
      "331315\n",
      "285142\n",
      "257853\n",
      "4623\n",
      "29923\n",
      "244071\n",
      "350521\n",
      "322340\n",
      "239472\n",
      "166694\n",
      "171270\n",
      "100359\n",
      "245494\n",
      "132760\n",
      "7451\n",
      "323715\n",
      "214573\n",
      "193567\n",
      "224020\n",
      "300515\n",
      "41558\n",
      "245883\n",
      "195173\n",
      "134917\n",
      "106943\n",
      "75753\n",
      "6622\n",
      "66060\n",
      "337196\n",
      "168310\n",
      "25673\n",
      "175033\n",
      "96680\n",
      "18509\n",
      "61047\n",
      "222521\n",
      "159873\n",
      "205175\n",
      "137042\n",
      "262393\n",
      "37458\n",
      "105881\n",
      "166609\n",
      "201301\n",
      "9865\n",
      "231183\n",
      "90292\n",
      "54900\n",
      "79408\n",
      "168286\n",
      "286062\n",
      "159903\n",
      "273976\n",
      "110110\n",
      "341924\n",
      "334779\n",
      "155965\n",
      "183485\n",
      "240110\n",
      "187388\n",
      "45493\n",
      "92176\n",
      "245057\n",
      "70103\n",
      "354606\n",
      "296308\n",
      "251672\n",
      "169545\n",
      "130927\n",
      "206783\n",
      "253080\n",
      "304940\n",
      "281620\n",
      "356986\n",
      "200299\n",
      "265449\n",
      "72152\n",
      "242957\n",
      "354292\n",
      "258597\n",
      "201237\n",
      "336798\n",
      "317167\n",
      "67600\n",
      "127107\n",
      "257035\n",
      "33119\n",
      "229887\n",
      "341453\n",
      "180208\n",
      "88058\n",
      "147347\n",
      "1530\n",
      "41534\n",
      "117959\n",
      "252612\n",
      "97719\n",
      "23506\n",
      "154675\n",
      "29695\n",
      "303769\n",
      "96924\n",
      "152288\n",
      "5115\n",
      "205618\n",
      "146810\n",
      "36619\n",
      "272432\n",
      "17854\n",
      "120857\n",
      "20800\n",
      "142668\n",
      "309172\n",
      "55681\n",
      "282697\n",
      "102093\n",
      "348665\n",
      "148019\n",
      "358107\n",
      "98186\n",
      "52586\n",
      "196986\n",
      "78098\n",
      "104872\n",
      "273644\n",
      "101326\n",
      "190429\n",
      "338204\n",
      "229341\n",
      "63538\n",
      "10990\n",
      "44570\n",
      "233039\n",
      "215446\n",
      "225831\n",
      "153873\n",
      "358336\n",
      "319541\n",
      "308443\n",
      "10843\n",
      "75277\n",
      "209240\n",
      "297957\n",
      "198621\n",
      "145488\n",
      "222303\n",
      "324799\n",
      "47970\n",
      "215932\n",
      "178631\n",
      "249650\n",
      "107150\n",
      "138726\n",
      "117091\n",
      "143349\n",
      "169642\n",
      "113074\n",
      "127952\n",
      "28440\n",
      "282482\n",
      "156929\n",
      "290007\n",
      "183477\n",
      "264273\n",
      "207229\n",
      "184047\n",
      "319842\n",
      "234189\n",
      "43375\n",
      "324950\n",
      "75468\n",
      "321170\n",
      "144377\n",
      "291681\n",
      "87238\n",
      "267667\n",
      "335758\n",
      "159966\n",
      "94713\n",
      "184885\n",
      "89817\n",
      "247854\n",
      "322514\n",
      "296288\n",
      "170399\n",
      "260157\n",
      "270975\n",
      "183660\n",
      "306314\n",
      "15827\n",
      "273689\n",
      "269816\n",
      "13754\n",
      "294855\n",
      "65268\n",
      "48689\n",
      "125517\n",
      "89006\n",
      "239753\n",
      "195604\n",
      "327316\n",
      "168220\n",
      "82575\n",
      "142637\n",
      "98317\n",
      "300171\n",
      "338529\n",
      "129283\n",
      "151356\n",
      "177314\n",
      "353790\n",
      "126259\n",
      "210560\n",
      "109186\n",
      "111785\n",
      "142900\n",
      "295164\n",
      "37251\n",
      "347136\n",
      "325456\n",
      "357300\n",
      "53168\n",
      "56073\n",
      "289193\n",
      "59367\n",
      "150327\n",
      "209739\n",
      "158074\n",
      "310666\n",
      "112214\n",
      "299824\n",
      "223379\n",
      "179051\n",
      "79613\n",
      "4532\n",
      "183572\n",
      "277744\n",
      "101586\n",
      "265980\n",
      "189266\n",
      "91613\n",
      "196495\n",
      "212978\n",
      "134669\n",
      "217535\n",
      "249828\n",
      "351170\n",
      "219780\n",
      "323406\n",
      "105543\n",
      "283259\n",
      "46343\n",
      "163677\n",
      "346039\n",
      "165537\n",
      "69600\n",
      "114266\n",
      "65873\n",
      "20703\n",
      "341232\n",
      "237488\n",
      "185069\n",
      "36860\n",
      "67144\n",
      "165005\n",
      "197840\n",
      "45824\n",
      "286459\n",
      "214242\n",
      "3935\n",
      "144585\n",
      "36479\n",
      "78866\n",
      "63421\n",
      "230993\n",
      "131160\n",
      "240888\n",
      "21662\n",
      "34183\n",
      "70021\n",
      "130829\n",
      "102645\n",
      "278753\n",
      "206005\n",
      "105161\n",
      "259176\n",
      "188015\n",
      "203304\n",
      "13306\n",
      "46911\n",
      "104834\n",
      "309045\n",
      "60261\n",
      "275987\n",
      "5136\n",
      "268379\n",
      "14827\n",
      "45271\n",
      "16833\n",
      "67364\n",
      "356051\n",
      "78444\n",
      "16579\n",
      "198380\n",
      "58300\n",
      "26653\n",
      "17224\n",
      "54101\n",
      "95567\n",
      "191218\n",
      "132618\n",
      "238118\n",
      "306290\n",
      "38003\n",
      "168485\n",
      "41792\n",
      "187344\n",
      "145099\n",
      "350304\n",
      "145174\n",
      "317257\n",
      "279103\n",
      "18071\n",
      "304569\n",
      "242327\n",
      "51375\n",
      "110380\n",
      "262761\n",
      "254603\n",
      "200364\n",
      "37372\n",
      "301492\n",
      "177013\n",
      "273783\n",
      "194732\n",
      "79361\n",
      "94521\n",
      "30981\n",
      "24715\n",
      "42949\n",
      "237486\n",
      "69913\n",
      "22758\n",
      "8121\n",
      "211292\n",
      "355961\n",
      "186592\n",
      "130850\n",
      "110747\n",
      "114201\n",
      "276182\n",
      "41877\n",
      "90996\n",
      "207454\n",
      "106688\n",
      "8291\n",
      "137050\n",
      "309390\n",
      "20433\n",
      "98985\n",
      "276421\n",
      "296394\n",
      "352866\n",
      "33043\n",
      "217973\n",
      "304974\n",
      "172819\n",
      "195926\n",
      "214913\n",
      "73382\n",
      "232551\n",
      "285826\n",
      "163699\n",
      "159355\n",
      "177631\n",
      "123416\n",
      "39495\n",
      "353469\n",
      "314266\n",
      "111758\n",
      "165026\n",
      "56742\n",
      "213635\n",
      "178663\n",
      "235197\n",
      "182547\n",
      "5935\n",
      "58694\n",
      "5962\n",
      "167289\n",
      "75284\n",
      "259618\n",
      "109058\n",
      "231107\n",
      "205159\n",
      "196597\n",
      "132534\n",
      "122765\n",
      "354103\n",
      "288362\n",
      "118162\n",
      "313437\n",
      "169877\n",
      "61037\n",
      "179627\n",
      "316056\n",
      "202613\n",
      "211274\n",
      "25566\n",
      "338468\n",
      "195100\n",
      "117288\n",
      "135758\n",
      "28939\n",
      "24493\n",
      "102517\n",
      "107882\n",
      "90540\n",
      "186144\n",
      "57391\n",
      "9888\n",
      "162617\n",
      "298948\n",
      "188230\n",
      "67991\n",
      "88505\n",
      "279787\n",
      "43161\n",
      "35179\n",
      "11096\n",
      "114722\n",
      "297339\n",
      "343357\n",
      "172725\n",
      "12782\n",
      "32005\n",
      "315127\n",
      "10090\n",
      "192510\n",
      "21027\n",
      "339733\n",
      "327184\n",
      "178703\n",
      "309979\n",
      "185749\n",
      "128336\n",
      "169814\n",
      "286822\n",
      "107522\n",
      "68998\n",
      "337348\n",
      "110149\n",
      "209334\n",
      "86392\n",
      "71639\n",
      "240107\n",
      "61205\n",
      "289178\n",
      "85173\n",
      "282080\n",
      "198478\n",
      "315886\n",
      "248306\n",
      "22557\n",
      "120958\n",
      "234592\n",
      "218379\n",
      "307586\n",
      "83062\n",
      "222251\n",
      "316411\n",
      "23632\n",
      "126140\n",
      "258560\n",
      "330128\n",
      "100837\n",
      "220290\n",
      "352911\n",
      "235539\n",
      "314405\n",
      "306643\n",
      "256498\n",
      "298026\n",
      "214200\n",
      "19143\n",
      "43118\n",
      "128095\n",
      "63007\n",
      "153540\n",
      "89766\n",
      "345906\n",
      "197907\n",
      "137900\n",
      "350815\n",
      "184874\n",
      "338691\n",
      "5543\n",
      "288871\n",
      "350729\n",
      "51873\n",
      "202623\n",
      "8710\n",
      "104709\n",
      "142779\n",
      "182526\n",
      "113847\n",
      "149055\n",
      "130400\n",
      "327401\n",
      "217899\n",
      "321893\n",
      "136416\n",
      "151863\n",
      "194914\n",
      "175045\n",
      "21716\n",
      "88837\n",
      "332612\n",
      "281177\n",
      "351226\n",
      "321560\n",
      "110388\n",
      "272579\n",
      "119177\n",
      "13757\n",
      "254705\n",
      "212383\n",
      "41002\n",
      "359013\n",
      "301412\n",
      "127177\n",
      "263763\n",
      "154376\n",
      "51199\n",
      "98265\n",
      "274760\n",
      "208521\n",
      "238655\n",
      "151181\n",
      "228278\n",
      "112514\n",
      "193630\n",
      "115069\n",
      "96262\n",
      "326856\n",
      "116025\n",
      "160523\n",
      "1409\n",
      "49644\n",
      "97518\n",
      "161904\n",
      "115381\n",
      "193164\n",
      "317427\n",
      "55704\n",
      "251711\n",
      "302456\n",
      "336973\n",
      "171415\n",
      "9330\n",
      "264573\n",
      "115730\n",
      "58896\n",
      "79232\n",
      "242330\n",
      "140014\n",
      "207247\n",
      "12775\n",
      "222056\n",
      "5025\n",
      "264959\n",
      "165171\n",
      "209554\n",
      "1768\n",
      "15050\n",
      "213306\n",
      "195243\n",
      "224215\n",
      "71812\n",
      "249972\n",
      "129700\n",
      "115492\n",
      "39340\n",
      "46075\n",
      "125960\n",
      "67284\n",
      "258451\n",
      "134140\n",
      "304258\n",
      "170955\n",
      "146995\n",
      "319672\n",
      "20054\n",
      "240677\n",
      "143388\n",
      "200333\n",
      "6790\n",
      "279704\n",
      "7142\n",
      "145150\n",
      "193611\n",
      "74020\n",
      "290708\n",
      "35587\n",
      "74901\n",
      "215174\n",
      "163343\n",
      "85049\n",
      "56507\n",
      "33425\n",
      "219341\n",
      "214684\n",
      "68336\n",
      "215663\n",
      "263006\n",
      "167579\n",
      "11190\n",
      "317865\n",
      "40901\n",
      "113587\n",
      "136404\n",
      "66033\n",
      "15366\n",
      "49414\n",
      "55245\n",
      "280298\n",
      "219408\n",
      "344655\n",
      "316608\n",
      "40255\n",
      "250101\n",
      "334725\n",
      "237792\n",
      "72303\n",
      "158825\n",
      "103929\n",
      "176361\n",
      "85920\n",
      "149343\n",
      "212204\n",
      "142911\n",
      "123063\n",
      "195331\n",
      "74193\n",
      "130451\n",
      "317718\n",
      "211145\n",
      "329962\n",
      "224997\n",
      "268307\n",
      "316194\n",
      "305366\n",
      "357569\n",
      "12633\n",
      "178837\n",
      "174658\n",
      "149889\n",
      "273010\n",
      "334851\n",
      "302215\n",
      "274570\n",
      "204465\n",
      "286087\n",
      "320716\n",
      "53007\n",
      "283263\n",
      "183288\n",
      "232904\n",
      "230480\n",
      "131231\n",
      "99648\n",
      "102048\n",
      "275132\n",
      "306432\n",
      "26786\n",
      "340381\n",
      "351724\n",
      "64389\n",
      "224383\n",
      "160427\n",
      "250485\n",
      "83032\n",
      "245569\n",
      "333043\n",
      "337621\n",
      "71256\n",
      "259561\n",
      "307868\n",
      "123707\n",
      "10927\n",
      "340633\n",
      "77992\n",
      "234575\n",
      "62119\n",
      "243745\n",
      "231097\n",
      "273179\n",
      "108692\n",
      "252119\n",
      "135082\n",
      "39221\n",
      "269273\n",
      "210639\n",
      "327271\n",
      "278225\n",
      "299470\n",
      "311858\n",
      "75706\n",
      "120619\n",
      "373\n",
      "159108\n",
      "295709\n",
      "29426\n",
      "292849\n",
      "240144\n",
      "231280\n",
      "25711\n",
      "242682\n",
      "259675\n",
      "19163\n",
      "206710\n",
      "13100\n",
      "40161\n",
      "325233\n",
      "117286\n",
      "286106\n",
      "353761\n",
      "159527\n",
      "93237\n",
      "344906\n",
      "219540\n",
      "279174\n",
      "49606\n",
      "128045\n",
      "334683\n",
      "204456\n",
      "335152\n",
      "219024\n",
      "123959\n",
      "31865\n",
      "101685\n",
      "240715\n",
      "177092\n",
      "345093\n",
      "234795\n",
      "202338\n",
      "106482\n",
      "221600\n",
      "69159\n",
      "350706\n",
      "214274\n",
      "146131\n",
      "202661\n",
      "139119\n",
      "73841\n",
      "322583\n",
      "51162\n",
      "340758\n",
      "106868\n",
      "176896\n",
      "45845\n",
      "7034\n",
      "314527\n",
      "139784\n",
      "48582\n",
      "316640\n",
      "103195\n",
      "295191\n",
      "43838\n",
      "331841\n",
      "17060\n",
      "199489\n",
      "327470\n",
      "358154\n",
      "268985\n",
      "139880\n",
      "307194\n",
      "101938\n",
      "308199\n",
      "126502\n",
      "310332\n",
      "325264\n",
      "180453\n",
      "253746\n",
      "176300\n",
      "232812\n",
      "198119\n",
      "11276\n",
      "192143\n",
      "162045\n",
      "302958\n",
      "52402\n",
      "284352\n",
      "90403\n",
      "80014\n",
      "219338\n",
      "101403\n",
      "258738\n",
      "53030\n",
      "38213\n",
      "351511\n",
      "37725\n",
      "35980\n",
      "45838\n",
      "352826\n",
      "247074\n",
      "97722\n",
      "287528\n",
      "231218\n",
      "170089\n",
      "120692\n",
      "187029\n",
      "132846\n",
      "150979\n",
      "194852\n",
      "46619\n",
      "132222\n",
      "37381\n",
      "28021\n",
      "342956\n",
      "204771\n",
      "296996\n",
      "330138\n",
      "16499\n",
      "324725\n",
      "347500\n",
      "37710\n",
      "301694\n",
      "271638\n",
      "320194\n",
      "81244\n",
      "338798\n",
      "29745\n",
      "270330\n",
      "102857\n",
      "28468\n",
      "200197\n",
      "170655\n",
      "57097\n",
      "253952\n",
      "19441\n",
      "49314\n",
      "262074\n",
      "259805\n",
      "31638\n",
      "174459\n",
      "106120\n",
      "307894\n",
      "329263\n",
      "127708\n",
      "178154\n",
      "198222\n",
      "253060\n",
      "261733\n",
      "141580\n",
      "67526\n",
      "213889\n",
      "353462\n",
      "275162\n",
      "94403\n",
      "52697\n",
      "200943\n",
      "3119\n",
      "114992\n",
      "330131\n",
      "204879\n",
      "124450\n",
      "2348\n",
      "163508\n",
      "351754\n",
      "222345\n",
      "151765\n",
      "278620\n",
      "308213\n",
      "197315\n",
      "25694\n",
      "35615\n",
      "177895\n",
      "352298\n",
      "207335\n",
      "212139\n",
      "25523\n",
      "259461\n"
     ]
    }
   ],
   "source": [
    "# ปริ้นชื่อคลาสสำหรับ Training\n",
    "#print(\"\\n--- รายชื่อคลาสสำหรับ Training ---\")\n",
    "#for class_name in train_classes:\n",
    "    #print(class_name)\n",
    "\n",
    "# ---\n",
    "# ปริ้นชื่อคลาสสำหรับ Validation\n",
    "print(\"\\n--- รายชื่อคลาสสำหรับ Validation ---\")\n",
    "for class_name in val_classes:\n",
    "    print(class_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a463475",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadimage(image_path):\n",
    "    try:\n",
    "        img = tf.io.read_file(image_path)\n",
    "        img = tf.image.decode_jpeg(img, channels=3)\n",
    "        img = tf.image.resize(img, (224, 224))\n",
    "        img = tf.cast(img, tf.float32)\n",
    "        img = img / 255.0  # Normalization\n",
    "        img = tf.clip_by_value(img, 0.0, 1.0)#img = tf.where(tf.math.is_finite(img), img, tf.zeros_like(img)) # แทนที่ค่า NaN หรือ Inf ด้วย 0\n",
    "        img.set_shape((224, 224, 3))\n",
    "        return img\n",
    "    except:\n",
    "        print(f\"Error loading image {image_path}. Returning a zero tensor.\")\n",
    "        return tf.zeros((224, 224, 3), dtype=tf.float32)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e53ea715",
   "metadata": {},
   "source": [
    "##Online Triplet Mining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4aa8f866",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "def triplet_generator(image_dict, num_triplets_per_epoch):\n",
    "    # image_dict คือ dictionary ของคุณที่ได้จากขั้นตอนที่ 1\n",
    "    # num_triplets_per_epoch คือจำนวน triplet ที่ต้องการใน 1 รอบ (epoch)\n",
    "    classes = list(image_dict.keys()) # ดึงชื่อคลาสทั้งหมด\n",
    "    for _ in range(num_triplets_per_epoch):\n",
    "        # 1. สุ่ม anchor และ positive จากคลาสเดียวกัน\n",
    "        anchor_class = random.choice(classes)\n",
    "        # ตรวจสอบว่าคลาสนั้นมีรูปภาพอย่างน้อย 2 รูป\n",
    "        if len(image_dict[anchor_class]) < 2:\n",
    "            continue\n",
    "\n",
    "        a, p = random.sample(image_dict[anchor_class], 2)\n",
    "        \n",
    "        # 2. สุ่ม negative จากคลาสอื่น\n",
    "        neg_classes = [c for c in classes if c != anchor_class]\n",
    "        if not neg_classes:\n",
    "            continue\n",
    "            \n",
    "        negative_class = random.choice(neg_classes)\n",
    "        n = random.choice(image_dict[negative_class])\n",
    "        \n",
    "        # คืนค่า (yield) Path ของรูปภาพ\n",
    "        yield (a, p, n)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "797e39ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def builddataset1(image_dict, num_triplets, batch_size):\n",
    "    dataset = tf.data.Dataset.from_generator(\n",
    "        lambda: triplet_generator(image_dict, num_triplets),\n",
    "        output_signature=(\n",
    "            tf.TensorSpec(shape=(), dtype=tf.string),\n",
    "            tf.TensorSpec(shape=(), dtype=tf.string),\n",
    "            tf.TensorSpec(shape=(), dtype=tf.string)\n",
    "        )\n",
    "    )\n",
    "    dataset = dataset.map(\n",
    "        lambda a, p, n: (loadimage(a), loadimage(p), loadimage(n)),\n",
    "        num_parallel_calls=tf.data.AUTOTUNE\n",
    "    )\n",
    "    dataset = dataset.batch(batch_size).prefetch(tf.data.AUTOTUNE) #เพิ่มมิติ btach\n",
    "    return dataset\n",
    "\n",
    "triple = 65000\n",
    "BATCH_SIZE = 4\n",
    "\n",
    "train_dataset = builddataset1(train_image_dict1, triple, BATCH_SIZE)\n",
    "val_dataset = builddataset1(val_image_dict1, int(triple*0.1), BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4b40cafd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anchor batch shape: (4, 224, 224, 3)\n",
      "Positive batch shape: (4, 224, 224, 3)\n",
      "Negative batch shape: (4, 224, 224, 3)\n",
      "ลูปที่: tf.Tensor(\n",
      "[[[[1.09803922e-01 1.33333340e-01 7.84313753e-02]\n",
      "   [1.09803922e-01 1.33333340e-01 7.84313753e-02]\n",
      "   [1.09803922e-01 1.33333340e-01 7.84313753e-02]\n",
      "   ...\n",
      "   [5.86274505e-01 5.10784328e-01 4.11764711e-01]\n",
      "   [5.74509799e-01 5.04901946e-01 4.03921574e-01]\n",
      "   [5.68627477e-01 5.01960814e-01 4.00000006e-01]]\n",
      "\n",
      "  [[1.14705883e-01 1.38235301e-01 8.33333358e-02]\n",
      "   [1.14460781e-01 1.37990192e-01 8.35784301e-02]\n",
      "   [1.13970585e-01 1.37500003e-01 8.40686262e-02]\n",
      "   ...\n",
      "   [5.91421545e-01 5.15931368e-01 4.16911751e-01]\n",
      "   [5.80147088e-01 5.10539234e-01 4.09558833e-01]\n",
      "   [5.74509799e-01 5.07843137e-01 4.05882359e-01]]\n",
      "\n",
      "  [[1.24509804e-01 1.48039222e-01 9.31372568e-02]\n",
      "   [1.23774506e-01 1.47303924e-01 9.38725471e-02]\n",
      "   [1.22303918e-01 1.45833328e-01 9.53431353e-02]\n",
      "   ...\n",
      "   [6.01715684e-01 5.26225507e-01 4.27205890e-01]\n",
      "   [5.91421545e-01 5.21813750e-01 4.20833319e-01]\n",
      "   [5.86274505e-01 5.19607842e-01 4.17647064e-01]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[6.01960778e-01 6.89215660e-01 4.06862736e-01]\n",
      "   [5.97058833e-01 6.85784340e-01 4.02941167e-01]\n",
      "   [5.87254882e-01 6.78921580e-01 3.95098031e-01]\n",
      "   ...\n",
      "   [1.40686274e-01 1.30392164e-01 2.62009799e-01]\n",
      "   [1.31862745e-01 1.26470596e-01 2.60539204e-01]\n",
      "   [1.27450988e-01 1.24509804e-01 2.59803921e-01]]\n",
      "\n",
      "  [[5.90196073e-01 6.79411769e-01 3.97058815e-01]\n",
      "   [5.83333313e-01 6.75000012e-01 3.91176462e-01]\n",
      "   [5.69607854e-01 6.66176498e-01 3.79411757e-01]\n",
      "   ...\n",
      "   [1.39705881e-01 1.34313732e-01 2.68382341e-01]\n",
      "   [1.28921568e-01 1.26470596e-01 2.63970584e-01]\n",
      "   [1.23529412e-01 1.22549020e-01 2.61764705e-01]]\n",
      "\n",
      "  [[5.84313750e-01 6.74509823e-01 3.92156869e-01]\n",
      "   [5.76470613e-01 6.69607818e-01 3.85294110e-01]\n",
      "   [5.60784340e-01 6.59803927e-01 3.71568620e-01]\n",
      "   ...\n",
      "   [1.39215693e-01 1.36274517e-01 2.71568626e-01]\n",
      "   [1.27450988e-01 1.26470596e-01 2.65686274e-01]\n",
      "   [1.21568628e-01 1.21568628e-01 2.62745112e-01]]]\n",
      "\n",
      "\n",
      " [[[5.92156887e-01 7.49019623e-01 8.50980401e-01]\n",
      "   [6.10784292e-01 7.68627465e-01 8.74509811e-01]\n",
      "   [6.48039222e-01 8.07843149e-01 9.21568632e-01]\n",
      "   ...\n",
      "   [1.17647061e-02 0.00000000e+00 7.84313772e-03]\n",
      "   [1.17647061e-02 0.00000000e+00 7.84313772e-03]\n",
      "   [1.17647061e-02 0.00000000e+00 7.84313772e-03]]\n",
      "\n",
      "  [[5.77450991e-01 7.31372535e-01 8.33333313e-01]\n",
      "   [5.91421545e-01 7.46568620e-01 8.52205873e-01]\n",
      "   [6.19362772e-01 7.76960790e-01 8.89950991e-01]\n",
      "   ...\n",
      "   [9.80392192e-03 0.00000000e+00 7.35294120e-03]\n",
      "   [9.80392192e-03 0.00000000e+00 6.37254911e-03]\n",
      "   [9.80392192e-03 0.00000000e+00 5.88235306e-03]]\n",
      "\n",
      "  [[5.48039198e-01 6.96078420e-01 7.98039198e-01]\n",
      "   [5.52696049e-01 7.02450991e-01 8.07598054e-01]\n",
      "   [5.62009811e-01 7.15196073e-01 8.26715708e-01]\n",
      "   ...\n",
      "   [5.88235306e-03 0.00000000e+00 6.37254911e-03]\n",
      "   [5.88235306e-03 0.00000000e+00 3.43137258e-03]\n",
      "   [5.88235306e-03 0.00000000e+00 1.96078443e-03]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[1.00000001e-01 6.47058859e-02 3.72549035e-02]\n",
      "   [1.15931369e-01 8.06372538e-02 5.46568632e-02]\n",
      "   [1.47794113e-01 1.12499997e-01 8.94607827e-02]\n",
      "   ...\n",
      "   [1.55392155e-01 2.70833343e-01 3.22794110e-01]\n",
      "   [1.36764705e-01 2.57598042e-01 3.07598025e-01]\n",
      "   [1.27450988e-01 2.50980407e-01 3.00000012e-01]]\n",
      "\n",
      "  [[1.27450988e-01 9.21568647e-02 6.47058859e-02]\n",
      "   [1.41911760e-01 1.06617644e-01 7.96568617e-02]\n",
      "   [1.70833334e-01 1.35539219e-01 1.09558821e-01]\n",
      "   ...\n",
      "   [1.83823526e-01 2.96813726e-01 3.44852954e-01]\n",
      "   [1.59313723e-01 2.76715696e-01 3.22794110e-01]\n",
      "   [1.47058830e-01 2.66666681e-01 3.11764717e-01]]\n",
      "\n",
      "  [[1.41176477e-01 1.05882354e-01 7.84313753e-02]\n",
      "   [1.54901966e-01 1.19607843e-01 9.21568647e-02]\n",
      "   [1.82352945e-01 1.47058830e-01 1.19607843e-01]\n",
      "   ...\n",
      "   [1.98039219e-01 3.09803933e-01 3.55882347e-01]\n",
      "   [1.70588240e-01 2.86274523e-01 3.30392152e-01]\n",
      "   [1.56862751e-01 2.74509817e-01 3.17647070e-01]]]\n",
      "\n",
      "\n",
      " [[[8.11764717e-01 2.90196091e-01 2.54901975e-01]\n",
      "   [8.05882335e-01 2.83333331e-01 2.46078432e-01]\n",
      "   [7.94117630e-01 2.69607842e-01 2.28431374e-01]\n",
      "   ...\n",
      "   [2.82352954e-01 2.82352954e-01 2.43137255e-01]\n",
      "   [2.82352954e-01 2.82352954e-01 2.43137255e-01]\n",
      "   [2.82352954e-01 2.82352954e-01 2.43137255e-01]]\n",
      "\n",
      "  [[8.27450991e-01 3.25490206e-01 2.91176468e-01]\n",
      "   [8.20343137e-01 3.17401975e-01 2.81127453e-01]\n",
      "   [8.06127429e-01 3.01225483e-01 2.61029422e-01]\n",
      "   ...\n",
      "   [2.81862736e-01 2.82352954e-01 2.42892161e-01]\n",
      "   [2.80882359e-01 2.82352954e-01 2.42401958e-01]\n",
      "   [2.80392170e-01 2.82352954e-01 2.42156863e-01]]\n",
      "\n",
      "  [[8.58823538e-01 3.96078438e-01 3.63725483e-01]\n",
      "   [8.49264681e-01 3.85539204e-01 3.51225495e-01]\n",
      "   [8.30147088e-01 3.64460796e-01 3.26225489e-01]\n",
      "   ...\n",
      "   [2.80882359e-01 2.82352954e-01 2.42401958e-01]\n",
      "   [2.77941167e-01 2.82352954e-01 2.40931377e-01]\n",
      "   [2.76470602e-01 2.82352954e-01 2.40196079e-01]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[8.25490177e-01 8.45098019e-01 8.60784292e-01]\n",
      "   [8.25735271e-01 8.45343113e-01 8.61029387e-01]\n",
      "   [8.26225519e-01 8.45833361e-01 8.61519635e-01]\n",
      "   ...\n",
      "   [1.68872550e-01 1.72794119e-01 1.49264708e-01]\n",
      "   [1.67401955e-01 1.71323523e-01 1.47794113e-01]\n",
      "   [1.66666672e-01 1.70588240e-01 1.47058830e-01]]\n",
      "\n",
      "  [[8.29411745e-01 8.49019587e-01 8.64705861e-01]\n",
      "   [8.28186274e-01 8.47794116e-01 8.63480389e-01]\n",
      "   [8.25735271e-01 8.45343113e-01 8.61029387e-01]\n",
      "   ...\n",
      "   [1.71323523e-01 1.75245091e-01 1.51715681e-01]\n",
      "   [1.70833334e-01 1.74754903e-01 1.51225492e-01]\n",
      "   [1.70588240e-01 1.74509808e-01 1.50980398e-01]]\n",
      "\n",
      "  [[8.31372559e-01 8.50980401e-01 8.66666675e-01]\n",
      "   [8.29411745e-01 8.49019587e-01 8.64705861e-01]\n",
      "   [8.25490177e-01 8.45098019e-01 8.60784292e-01]\n",
      "   ...\n",
      "   [1.72549024e-01 1.76470593e-01 1.52941182e-01]\n",
      "   [1.72549024e-01 1.76470593e-01 1.52941182e-01]\n",
      "   [1.72549024e-01 1.76470593e-01 1.52941182e-01]]]\n",
      "\n",
      "\n",
      " [[[5.64705908e-01 5.41176498e-01 4.94117647e-01]\n",
      "   [5.63725471e-01 5.40196061e-01 4.93137240e-01]\n",
      "   [5.61764717e-01 5.38235307e-01 4.91176456e-01]\n",
      "   ...\n",
      "   [1.67647064e-01 1.87254906e-01 2.10784316e-01]\n",
      "   [1.57843143e-01 1.77450985e-01 2.00980395e-01]\n",
      "   [1.52941182e-01 1.72549024e-01 1.96078435e-01]]\n",
      "\n",
      "  [[5.59803903e-01 5.36274493e-01 4.89215672e-01]\n",
      "   [5.59803903e-01 5.36274493e-01 4.89215672e-01]\n",
      "   [5.59803903e-01 5.36274493e-01 4.89215672e-01]\n",
      "   ...\n",
      "   [1.65196076e-01 1.84803918e-01 2.08333328e-01]\n",
      "   [1.56372547e-01 1.75980389e-01 1.99509799e-01]\n",
      "   [1.51960790e-01 1.71568632e-01 1.95098042e-01]]\n",
      "\n",
      "  [[5.50000012e-01 5.26470602e-01 4.79411751e-01]\n",
      "   [5.51960766e-01 5.28431356e-01 4.81372535e-01]\n",
      "   [5.55882335e-01 5.32352924e-01 4.85294104e-01]\n",
      "   ...\n",
      "   [1.60294116e-01 1.79901958e-01 2.03431368e-01]\n",
      "   [1.53431371e-01 1.73039213e-01 1.96568623e-01]\n",
      "   [1.50000006e-01 1.69607848e-01 1.93137258e-01]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[2.94117653e-03 0.00000000e+00 7.84313772e-03]\n",
      "   [2.20588245e-03 0.00000000e+00 7.84313772e-03]\n",
      "   [7.35294132e-04 0.00000000e+00 7.84313772e-03]\n",
      "   ...\n",
      "   [2.85294116e-01 3.16666663e-01 2.73529410e-01]\n",
      "   [2.95098037e-01 3.26470584e-01 2.83333331e-01]\n",
      "   [3.00000012e-01 3.31372559e-01 2.88235307e-01]]\n",
      "\n",
      "  [[9.80392215e-04 0.00000000e+00 7.84313772e-03]\n",
      "   [7.35294132e-04 0.00000000e+00 7.84313772e-03]\n",
      "   [2.45098054e-04 0.00000000e+00 7.84313772e-03]\n",
      "   ...\n",
      "   [2.91176468e-01 3.22549015e-01 2.79411763e-01]\n",
      "   [3.04901958e-01 3.36274505e-01 2.93137252e-01]\n",
      "   [3.11764717e-01 3.43137264e-01 3.00000012e-01]]\n",
      "\n",
      "  [[0.00000000e+00 0.00000000e+00 7.84313772e-03]\n",
      "   [0.00000000e+00 0.00000000e+00 7.84313772e-03]\n",
      "   [0.00000000e+00 0.00000000e+00 7.84313772e-03]\n",
      "   ...\n",
      "   [2.94117659e-01 3.25490206e-01 2.82352954e-01]\n",
      "   [3.09803933e-01 3.41176480e-01 2.98039228e-01]\n",
      "   [3.17647070e-01 3.49019617e-01 3.05882365e-01]]]], shape=(4, 224, 224, 3), dtype=float32)\n",
      "ลูปที่: 0\n",
      "Anchor batch shape: (4, 224, 224, 3)\n",
      "Positive batch shape: (4, 224, 224, 3)\n",
      "Negative batch shape: (4, 224, 224, 3)\n",
      "ลูปที่: tf.Tensor(\n",
      "[[[[6.6666670e-02 6.6666670e-02 1.9607844e-02]\n",
      "   [6.6666670e-02 6.6666670e-02 1.9607844e-02]\n",
      "   [6.6666670e-02 6.6666670e-02 1.9607844e-02]\n",
      "   ...\n",
      "   [7.3529415e-02 8.5294120e-02 5.0000001e-02]\n",
      "   [7.9411767e-02 9.1176473e-02 5.5882353e-02]\n",
      "   [8.2352944e-02 9.4117649e-02 5.8823530e-02]]\n",
      "\n",
      "  [[6.6666670e-02 6.6666670e-02 1.9607844e-02]\n",
      "   [6.6911764e-02 6.7156866e-02 1.9607844e-02]\n",
      "   [6.7401960e-02 6.8137258e-02 1.9607844e-02]\n",
      "   ...\n",
      "   [7.2794117e-02 8.4558822e-02 4.9264707e-02]\n",
      "   [7.9166666e-02 9.0931371e-02 5.5637255e-02]\n",
      "   [8.2352944e-02 9.4117649e-02 5.8823530e-02]]\n",
      "\n",
      "  [[6.6666670e-02 6.6666670e-02 1.9607844e-02]\n",
      "   [6.7401960e-02 6.8137258e-02 1.9607844e-02]\n",
      "   [6.8872549e-02 7.1078435e-02 1.9607844e-02]\n",
      "   ...\n",
      "   [7.1323529e-02 8.3088234e-02 4.7794119e-02]\n",
      "   [7.8676470e-02 9.0441175e-02 5.5147059e-02]\n",
      "   [8.2352944e-02 9.4117649e-02 5.8823530e-02]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[8.4705883e-01 2.9019609e-01 2.1862745e-01]\n",
      "   [8.4436274e-01 2.8995097e-01 2.1740197e-01]\n",
      "   [8.3897060e-01 2.8946078e-01 2.1495098e-01]\n",
      "   ...\n",
      "   [4.6813726e-01 6.4215690e-02 2.8921569e-02]\n",
      "   [4.6911764e-01 6.5196082e-02 2.9901961e-02]\n",
      "   [4.6960783e-01 6.5686278e-02 3.0392157e-02]]\n",
      "\n",
      "  [[8.5490197e-01 2.9019609e-01 2.1666667e-01]\n",
      "   [8.5073531e-01 2.8946078e-01 2.1495098e-01]\n",
      "   [8.4240198e-01 2.8799018e-01 2.1151961e-01]\n",
      "   ...\n",
      "   [4.8480392e-01 8.0882356e-02 4.5588236e-02]\n",
      "   [4.8382354e-01 7.9901963e-02 4.4607844e-02]\n",
      "   [4.8333332e-01 7.9411767e-02 4.4117648e-02]]\n",
      "\n",
      "  [[8.5882354e-01 2.9019609e-01 2.1568628e-01]\n",
      "   [8.5392159e-01 2.8921568e-01 2.1372549e-01]\n",
      "   [8.4411764e-01 2.8725490e-01 2.0980392e-01]\n",
      "   ...\n",
      "   [4.9313724e-01 8.9215688e-02 5.3921569e-02]\n",
      "   [4.9117646e-01 8.7254904e-02 5.1960785e-02]\n",
      "   [4.9019608e-01 8.6274512e-02 5.0980393e-02]]]\n",
      "\n",
      "\n",
      " [[[2.5882354e-01 4.0784314e-01 3.0980393e-01]\n",
      "   [2.5784314e-01 4.0686274e-01 3.0882353e-01]\n",
      "   [2.5588235e-01 4.0490195e-01 3.0686274e-01]\n",
      "   ...\n",
      "   [2.1568628e-01 1.6470589e-01 1.3333334e-01]\n",
      "   [2.4705882e-01 1.9607843e-01 1.6470589e-01]\n",
      "   [2.6274511e-01 2.1176471e-01 1.8039216e-01]]\n",
      "\n",
      "  [[2.5588235e-01 4.0196079e-01 3.0490196e-01]\n",
      "   [2.5441176e-01 4.0122548e-01 3.0392158e-01]\n",
      "   [2.5147060e-01 3.9975491e-01 3.0196080e-01]\n",
      "   ...\n",
      "   [2.3357843e-01 1.8259804e-01 1.5122549e-01]\n",
      "   [2.5563726e-01 2.0465687e-01 1.7328431e-01]\n",
      "   [2.6666668e-01 2.1568628e-01 1.8431373e-01]]\n",
      "\n",
      "  [[2.5000000e-01 3.9019608e-01 2.9509804e-01]\n",
      "   [2.4754901e-01 3.8995099e-01 2.9411766e-01]\n",
      "   [2.4264705e-01 3.8946077e-01 2.9215688e-01]\n",
      "   ...\n",
      "   [2.6936275e-01 2.1838236e-01 1.8700980e-01]\n",
      "   [2.7279413e-01 2.2181372e-01 1.9044118e-01]\n",
      "   [2.7450982e-01 2.2352941e-01 1.9215687e-01]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[5.1960785e-02 0.0000000e+00 0.0000000e+00]\n",
      "   [8.4558822e-02 2.3529412e-02 9.0686278e-03]\n",
      "   [1.4975490e-01 7.0588239e-02 2.7205883e-02]\n",
      "   ...\n",
      "   [5.3259802e-01 3.6789215e-01 2.1102941e-01]\n",
      "   [5.3897059e-01 3.7426472e-01 2.1740197e-01]\n",
      "   [5.4215688e-01 3.7745097e-01 2.2058824e-01]]\n",
      "\n",
      "  [[4.6078432e-02 0.0000000e+00 0.0000000e+00]\n",
      "   [7.5245097e-02 1.9607844e-02 3.6764706e-03]\n",
      "   [1.3357843e-01 5.8823530e-02 1.1029412e-02]\n",
      "   ...\n",
      "   [5.4877448e-01 3.8406864e-01 2.2720589e-01]\n",
      "   [5.5612743e-01 3.9142156e-01 2.3455882e-01]\n",
      "   [5.5980390e-01 3.9509803e-01 2.3823529e-01]]\n",
      "\n",
      "  [[4.3137256e-02 0.0000000e+00 0.0000000e+00]\n",
      "   [7.0588239e-02 1.7647060e-02 9.8039221e-04]\n",
      "   [1.2549020e-01 5.2941177e-02 2.9411765e-03]\n",
      "   ...\n",
      "   [5.5686277e-01 3.9215687e-01 2.3529412e-01]\n",
      "   [5.6470591e-01 4.0000001e-01 2.4313726e-01]\n",
      "   [5.6862748e-01 4.0392157e-01 2.4705882e-01]]]\n",
      "\n",
      "\n",
      " [[[1.0000000e+00 1.0000000e+00 9.6470588e-01]\n",
      "   [1.0000000e+00 9.9901962e-01 9.6372551e-01]\n",
      "   [1.0000000e+00 9.9705881e-01 9.6176469e-01]\n",
      "   ...\n",
      "   [3.3627450e-01 3.1666666e-01 2.9313725e-01]\n",
      "   [6.5588236e-01 6.3627452e-01 6.1274511e-01]\n",
      "   [8.1568629e-01 7.9607844e-01 7.7254903e-01]]\n",
      "\n",
      "  [[1.0000000e+00 1.0000000e+00 9.6470588e-01]\n",
      "   [1.0000000e+00 9.9926472e-01 9.6397060e-01]\n",
      "   [1.0000000e+00 9.9779409e-01 9.6249998e-01]\n",
      "   ...\n",
      "   [3.0416667e-01 2.8455883e-01 2.6102942e-01]\n",
      "   [5.9877449e-01 5.7916665e-01 5.5563724e-01]\n",
      "   [7.4607843e-01 7.2647059e-01 7.0294118e-01]]\n",
      "\n",
      "  [[1.0000000e+00 1.0000000e+00 9.6470588e-01]\n",
      "   [1.0000000e+00 9.9975491e-01 9.6446079e-01]\n",
      "   [1.0000000e+00 9.9926472e-01 9.6397060e-01]\n",
      "   ...\n",
      "   [2.3995098e-01 2.2034314e-01 1.9681373e-01]\n",
      "   [4.8455882e-01 4.6495098e-01 4.4142157e-01]\n",
      "   [6.0686272e-01 5.8725488e-01 5.6372547e-01]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[5.5294120e-01 5.0196081e-01 4.3529412e-01]\n",
      "   [5.5367649e-01 5.0269610e-01 4.3602940e-01]\n",
      "   [5.5514705e-01 5.0416666e-01 4.3750000e-01]\n",
      "   ...\n",
      "   [9.9313724e-01 9.8725492e-01 9.9019605e-01]\n",
      "   [9.8921567e-01 9.8725492e-01 9.8823529e-01]\n",
      "   [9.8725492e-01 9.8725492e-01 9.8725492e-01]]\n",
      "\n",
      "  [[5.5294120e-01 5.0196081e-01 4.3529412e-01]\n",
      "   [5.5318630e-01 5.0220591e-01 4.3553922e-01]\n",
      "   [5.5367649e-01 5.0269610e-01 4.3602940e-01]\n",
      "   ...\n",
      "   [9.9117649e-01 9.8529410e-01 9.8823529e-01]\n",
      "   [9.8725492e-01 9.8529410e-01 9.8627448e-01]\n",
      "   [9.8529410e-01 9.8529410e-01 9.8529410e-01]]\n",
      "\n",
      "  [[5.5294120e-01 5.0196081e-01 4.3529412e-01]\n",
      "   [5.5294120e-01 5.0196081e-01 4.3529412e-01]\n",
      "   [5.5294120e-01 5.0196081e-01 4.3529412e-01]\n",
      "   ...\n",
      "   [9.9019605e-01 9.8431373e-01 9.8725492e-01]\n",
      "   [9.8627448e-01 9.8431373e-01 9.8529410e-01]\n",
      "   [9.8431373e-01 9.8431373e-01 9.8431373e-01]]]\n",
      "\n",
      "\n",
      " [[[0.0000000e+00 3.9215689e-03 0.0000000e+00]\n",
      "   [0.0000000e+00 3.9215689e-03 0.0000000e+00]\n",
      "   [0.0000000e+00 3.9215689e-03 0.0000000e+00]\n",
      "   ...\n",
      "   [0.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      "   [0.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      "   [0.0000000e+00 0.0000000e+00 0.0000000e+00]]\n",
      "\n",
      "  [[0.0000000e+00 3.9215689e-03 0.0000000e+00]\n",
      "   [0.0000000e+00 4.1666669e-03 2.4509805e-04]\n",
      "   [0.0000000e+00 4.6568629e-03 7.3529413e-04]\n",
      "   ...\n",
      "   [0.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      "   [0.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      "   [0.0000000e+00 0.0000000e+00 0.0000000e+00]]\n",
      "\n",
      "  [[0.0000000e+00 3.9215689e-03 0.0000000e+00]\n",
      "   [0.0000000e+00 4.6568629e-03 7.3529413e-04]\n",
      "   [0.0000000e+00 6.1274511e-03 2.2058825e-03]\n",
      "   ...\n",
      "   [0.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      "   [0.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      "   [0.0000000e+00 0.0000000e+00 0.0000000e+00]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[5.9117645e-01 7.0784312e-01 7.4215686e-01]\n",
      "   [5.9632355e-01 7.1102941e-01 7.4436277e-01]\n",
      "   [6.0661763e-01 7.1740198e-01 7.4877453e-01]\n",
      "   ...\n",
      "   [9.0441175e-02 7.4754901e-02 7.0833333e-02]\n",
      "   [9.0931371e-02 7.5245097e-02 7.1323529e-02]\n",
      "   [9.1176473e-02 7.5490199e-02 7.1568631e-02]]\n",
      "\n",
      "  [[5.9705883e-01 7.1960783e-01 7.5980395e-01]\n",
      "   [5.8897060e-01 7.0955884e-01 7.4877453e-01]\n",
      "   [5.7279414e-01 6.8946081e-01 7.2671568e-01]\n",
      "   ...\n",
      "   [9.0931371e-02 7.5245097e-02 7.1323529e-02]\n",
      "   [9.2401959e-02 7.6715685e-02 7.2794117e-02]\n",
      "   [9.3137257e-02 7.7450983e-02 7.3529415e-02]]\n",
      "\n",
      "  [[6.0000002e-01 7.2549021e-01 7.6862746e-01]\n",
      "   [5.8529413e-01 7.0882350e-01 7.5098038e-01]\n",
      "   [5.5588233e-01 6.7549020e-01 7.1568626e-01]\n",
      "   ...\n",
      "   [9.1176473e-02 7.5490199e-02 7.1568631e-02]\n",
      "   [9.3137257e-02 7.7450983e-02 7.3529415e-02]\n",
      "   [9.4117649e-02 7.8431375e-02 7.4509807e-02]]]], shape=(4, 224, 224, 3), dtype=float32)\n",
      "ลูปที่: 0\n",
      "Anchor batch shape: (4, 224, 224, 3)\n",
      "Positive batch shape: (4, 224, 224, 3)\n",
      "Negative batch shape: (4, 224, 224, 3)\n",
      "ลูปที่: tf.Tensor(\n",
      "[[[[0.1764706  0.25490198 0.14901961]\n",
      "   [0.1764706  0.25490198 0.14901961]\n",
      "   [0.1764706  0.25490198 0.14901961]\n",
      "   ...\n",
      "   [0.16568628 0.24705882 0.14803922]\n",
      "   [0.15980393 0.24705882 0.14607844]\n",
      "   [0.15686275 0.24705882 0.14509805]]\n",
      "\n",
      "  [[0.17843138 0.25686276 0.1509804 ]\n",
      "   [0.17843138 0.25686276 0.1509804 ]\n",
      "   [0.17843138 0.25686276 0.1509804 ]\n",
      "   ...\n",
      "   [0.16617647 0.24754901 0.14852941]\n",
      "   [0.16127451 0.2485294  0.14754902]\n",
      "   [0.15882353 0.24901961 0.14705883]]\n",
      "\n",
      "  [[0.18235295 0.26078433 0.15490197]\n",
      "   [0.18235295 0.26078433 0.15490197]\n",
      "   [0.18235295 0.26078433 0.15490197]\n",
      "   ...\n",
      "   [0.16715686 0.2485294  0.1495098 ]\n",
      "   [0.16421568 0.2514706  0.1504902 ]\n",
      "   [0.1627451  0.2529412  0.1509804 ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.17941177 0.25392157 0.38235295]\n",
      "   [0.17156863 0.24607843 0.3732843 ]\n",
      "   [0.15588236 0.23039216 0.35514706]\n",
      "   ...\n",
      "   [0.23553921 0.33406863 0.1985294 ]\n",
      "   [0.23995098 0.33553922 0.20147058]\n",
      "   [0.24215686 0.3362745  0.20294118]]\n",
      "\n",
      "  [[0.16176471 0.23627451 0.3627451 ]\n",
      "   [0.15392157 0.22843137 0.35318628]\n",
      "   [0.1382353  0.2127451  0.33406863]\n",
      "   ...\n",
      "   [0.2379902  0.33357844 0.1995098 ]\n",
      "   [0.23946078 0.33406863 0.20049019]\n",
      "   [0.24019608 0.33431372 0.2009804 ]]\n",
      "\n",
      "  [[0.15294118 0.22745098 0.3529412 ]\n",
      "   [0.14509805 0.21960784 0.34313726]\n",
      "   [0.12941177 0.20392157 0.32352942]\n",
      "   ...\n",
      "   [0.23921569 0.33333334 0.2       ]\n",
      "   [0.23921569 0.33333334 0.2       ]\n",
      "   [0.23921569 0.33333334 0.2       ]]]\n",
      "\n",
      "\n",
      " [[[0.99607843 1.         0.99215686]\n",
      "   [0.99607843 1.         0.99215686]\n",
      "   [0.99607843 1.         0.99215686]\n",
      "   ...\n",
      "   [0.9970588  0.9970588  0.9892157 ]\n",
      "   [0.9990196  0.9990196  0.9911765 ]\n",
      "   [1.         1.         0.99215686]]\n",
      "\n",
      "  [[0.99509805 1.         0.9911765 ]\n",
      "   [0.99534315 1.         0.9914216 ]\n",
      "   [0.99583334 1.         0.99191177]\n",
      "   ...\n",
      "   [0.9970588  0.9970588  0.9892157 ]\n",
      "   [0.9990196  0.9990196  0.9911765 ]\n",
      "   [1.         1.         0.99215686]]\n",
      "\n",
      "  [[0.99313724 1.         0.9892157 ]\n",
      "   [0.9938725  1.         0.98995095]\n",
      "   [0.99534315 1.         0.9914216 ]\n",
      "   ...\n",
      "   [0.9970588  0.9970588  0.9892157 ]\n",
      "   [0.9990196  0.9990196  0.9911765 ]\n",
      "   [1.         1.         0.99215686]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.9843137  0.99509805 0.9705882 ]\n",
      "   [0.98333335 0.99607843 0.97132355]\n",
      "   [0.98137254 0.9980392  0.9727941 ]\n",
      "   ...\n",
      "   [0.9862745  0.9990196  1.        ]\n",
      "   [0.9862745  0.9990196  1.        ]\n",
      "   [0.9862745  0.9990196  1.        ]]\n",
      "\n",
      "  [[0.96862745 0.9852941  0.9588235 ]\n",
      "   [0.96960783 0.9882353  0.9610294 ]\n",
      "   [0.97156864 0.9941176  0.96544117]\n",
      "   ...\n",
      "   [0.9823529  0.9970588  1.        ]\n",
      "   [0.9823529  0.9970588  1.        ]\n",
      "   [0.9823529  0.9970588  1.        ]]\n",
      "\n",
      "  [[0.9607843  0.98039216 0.9529412 ]\n",
      "   [0.9627451  0.9843137  0.9558824 ]\n",
      "   [0.96666664 0.99215686 0.9617647 ]\n",
      "   ...\n",
      "   [0.98039216 0.99607843 1.        ]\n",
      "   [0.98039216 0.99607843 1.        ]\n",
      "   [0.98039216 0.99607843 1.        ]]]\n",
      "\n",
      "\n",
      " [[[0.5254902  0.6627451  0.05098039]\n",
      "   [0.52156866 0.6607843  0.04803922]\n",
      "   [0.5137255  0.65686274 0.04215686]\n",
      "   ...\n",
      "   [0.22058824 0.3362745  0.07058824]\n",
      "   [0.19901961 0.31862745 0.04705882]\n",
      "   [0.1882353  0.30980393 0.03529412]]\n",
      "\n",
      "  [[0.53431374 0.6696078  0.06078431]\n",
      "   [0.5301471  0.66740197 0.05759804]\n",
      "   [0.52181375 0.6629902  0.05122549]\n",
      "   ...\n",
      "   [0.22009803 0.33308825 0.06960785]\n",
      "   [0.1995098  0.31691176 0.04803922]\n",
      "   [0.18921569 0.30882353 0.0372549 ]]\n",
      "\n",
      "  [[0.55196077 0.68333334 0.08039216]\n",
      "   [0.5473039  0.68063724 0.07671569]\n",
      "   [0.5379902  0.6752451  0.06936274]\n",
      "   ...\n",
      "   [0.21911764 0.32671568 0.06764706]\n",
      "   [0.20049019 0.3134804  0.05      ]\n",
      "   [0.19117647 0.30686274 0.04117647]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   ...\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]]\n",
      "\n",
      "  [[0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   ...\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]]\n",
      "\n",
      "  [[0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   ...\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]]]\n",
      "\n",
      "\n",
      " [[[0.92156863 0.5568628  0.24313726]\n",
      "   [0.91862744 0.55490196 0.24411765]\n",
      "   [0.9127451  0.5509804  0.24607843]\n",
      "   ...\n",
      "   [0.8901961  0.5137255  0.21176471]\n",
      "   [0.8901961  0.5137255  0.21176471]\n",
      "   [0.8901961  0.5137255  0.21176471]]\n",
      "\n",
      "  [[0.922549   0.5598039  0.24705882]\n",
      "   [0.9191176  0.55735296 0.24754901]\n",
      "   [0.9122549  0.55245095 0.2485294 ]\n",
      "   ...\n",
      "   [0.8894608  0.5129902  0.21102941]\n",
      "   [0.889951   0.51348037 0.21151961]\n",
      "   [0.8901961  0.5137255  0.21176471]]\n",
      "\n",
      "  [[0.9245098  0.5656863  0.25490198]\n",
      "   [0.92009807 0.5622549  0.25441176]\n",
      "   [0.9112745  0.55539215 0.25343138]\n",
      "   ...\n",
      "   [0.8879902  0.5115196  0.20955883]\n",
      "   [0.8894608  0.5129902  0.21102941]\n",
      "   [0.8901961  0.5137255  0.21176471]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.04411765 0.0245098  0.00882353]\n",
      "   [0.04338235 0.0252451  0.00882353]\n",
      "   [0.04191177 0.02671569 0.00882353]\n",
      "   ...\n",
      "   [0.24534313 0.1629902  0.1384804 ]\n",
      "   [0.24583334 0.15759803 0.13504902]\n",
      "   [0.24607843 0.15490197 0.13333334]]\n",
      "\n",
      "  [[0.04607843 0.02647059 0.01078431]\n",
      "   [0.04583333 0.02671569 0.01078431]\n",
      "   [0.04534314 0.02720588 0.01078431]\n",
      "   ...\n",
      "   [0.25367647 0.16936274 0.1487745 ]\n",
      "   [0.24730392 0.15710784 0.1384804 ]\n",
      "   [0.24411765 0.1509804  0.13333334]]\n",
      "\n",
      "  [[0.04705882 0.02745098 0.01176471]\n",
      "   [0.04705882 0.02745098 0.01176471]\n",
      "   [0.04705882 0.02745098 0.01176471]\n",
      "   ...\n",
      "   [0.25784314 0.17254902 0.15392157]\n",
      "   [0.24803922 0.15686275 0.14019608]\n",
      "   [0.24313726 0.14901961 0.13333334]]]], shape=(4, 224, 224, 3), dtype=float32)\n",
      "ลูปที่: 0\n",
      "Anchor batch shape: (4, 224, 224, 3)\n",
      "Positive batch shape: (4, 224, 224, 3)\n",
      "Negative batch shape: (4, 224, 224, 3)\n",
      "ลูปที่: tf.Tensor(\n",
      "[[[[0.8745098  0.88235295 0.8784314 ]\n",
      "   [0.8745098  0.88235295 0.8784314 ]\n",
      "   [0.8745098  0.88235295 0.8784314 ]\n",
      "   ...\n",
      "   [0.8862745  0.8862745  0.8862745 ]\n",
      "   [0.8862745  0.8862745  0.8862745 ]\n",
      "   [0.8862745  0.8862745  0.8862745 ]]\n",
      "\n",
      "  [[0.87352943 0.8813726  0.877451  ]\n",
      "   [0.8737745  0.88161767 0.8776961 ]\n",
      "   [0.8742647  0.88210785 0.8781863 ]\n",
      "   ...\n",
      "   [0.88529414 0.88529414 0.88529414]\n",
      "   [0.88529414 0.88529414 0.88529414]\n",
      "   [0.88529414 0.88529414 0.88529414]]\n",
      "\n",
      "  [[0.8715686  0.87941176 0.8754902 ]\n",
      "   [0.8723039  0.88014704 0.8762255 ]\n",
      "   [0.8737745  0.88161767 0.8776961 ]\n",
      "   ...\n",
      "   [0.8833333  0.8833333  0.8833333 ]\n",
      "   [0.8833333  0.8833333  0.8833333 ]\n",
      "   [0.8833333  0.8833333  0.8833333 ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.11078431 0.08333334 0.05980392]\n",
      "   [0.09362745 0.06617647 0.04558824]\n",
      "   [0.05931373 0.03186275 0.01715686]\n",
      "   ...\n",
      "   [0.21740197 0.16642156 0.14093137]\n",
      "   [0.20710784 0.15612745 0.12671569]\n",
      "   [0.20196079 0.1509804  0.11960784]]\n",
      "\n",
      "  [[0.1754902  0.14803922 0.1245098 ]\n",
      "   [0.14558823 0.11813726 0.09558824]\n",
      "   [0.08578432 0.05833333 0.0377451 ]\n",
      "   ...\n",
      "   [0.21691176 0.16593137 0.14044118]\n",
      "   [0.20955883 0.15857843 0.12916666]\n",
      "   [0.20588236 0.15490197 0.12352941]]\n",
      "\n",
      "  [[0.20784314 0.18039216 0.15686275]\n",
      "   [0.17156863 0.14411765 0.12058824]\n",
      "   [0.09901961 0.07156863 0.04803922]\n",
      "   ...\n",
      "   [0.21666667 0.16568628 0.14019608]\n",
      "   [0.21078432 0.15980393 0.13039216]\n",
      "   [0.20784314 0.15686275 0.1254902 ]]]\n",
      "\n",
      "\n",
      " [[[0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   ...\n",
      "   [0.6764706  0.6647059  0.64509803]\n",
      "   [0.6647059  0.65294117 0.6333333 ]\n",
      "   [0.65882355 0.64705884 0.627451  ]]\n",
      "\n",
      "  [[0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   ...\n",
      "   [0.6767157  0.66495097 0.6453431 ]\n",
      "   [0.66544116 0.65367645 0.6340686 ]\n",
      "   [0.6598039  0.6480392  0.6284314 ]]\n",
      "\n",
      "  [[0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   ...\n",
      "   [0.67720586 0.66544116 0.6458333 ]\n",
      "   [0.6669118  0.6551471  0.63553923]\n",
      "   [0.6617647  0.65       0.63039213]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.6627451  0.6901961  0.72156864]\n",
      "   [0.657598   0.6870098  0.717402  ]\n",
      "   [0.64730394 0.68063724 0.70906866]\n",
      "   ...\n",
      "   [0.4269608  0.28382352 0.1985294 ]\n",
      "   [0.42794117 0.28480393 0.1995098 ]\n",
      "   [0.42843136 0.28529412 0.2       ]]\n",
      "\n",
      "  [[0.6627451  0.6901961  0.72156864]\n",
      "   [0.65710783 0.6865196  0.7169118 ]\n",
      "   [0.6458333  0.6791667  0.70759803]\n",
      "   ...\n",
      "   [0.4240196  0.2769608  0.19362745]\n",
      "   [0.42303923 0.27598038 0.19264705]\n",
      "   [0.422549   0.2754902  0.19215687]]\n",
      "\n",
      "  [[0.6627451  0.6901961  0.72156864]\n",
      "   [0.65686274 0.6862745  0.71666664]\n",
      "   [0.64509803 0.6784314  0.70686275]\n",
      "   ...\n",
      "   [0.422549   0.2735294  0.19117647]\n",
      "   [0.42058823 0.27156863 0.18921569]\n",
      "   [0.41960785 0.27058825 0.1882353 ]]]\n",
      "\n",
      "\n",
      " [[[0.37254903 0.36078432 0.29411766]\n",
      "   [0.36960784 0.35784313 0.29313725]\n",
      "   [0.36372548 0.35196078 0.29117647]\n",
      "   ...\n",
      "   [0.16666667 0.1627451  0.14313726]\n",
      "   [0.17058824 0.16666667 0.14705883]\n",
      "   [0.17254902 0.16862746 0.14901961]]\n",
      "\n",
      "  [[0.36078432 0.34901962 0.28235295]\n",
      "   [0.35784313 0.34607843 0.28137255]\n",
      "   [0.35196078 0.34019607 0.27941176]\n",
      "   ...\n",
      "   [0.15269607 0.1487745  0.12916666]\n",
      "   [0.15612745 0.15220588 0.13259804]\n",
      "   [0.15784314 0.15392157 0.13431373]]\n",
      "\n",
      "  [[0.3372549  0.3254902  0.25882354]\n",
      "   [0.33431372 0.32254902 0.25784314]\n",
      "   [0.32843137 0.31666666 0.25588235]\n",
      "   ...\n",
      "   [0.1247549  0.12083333 0.10122549]\n",
      "   [0.12720588 0.12328431 0.10367647]\n",
      "   [0.12843138 0.1245098  0.10490196]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.6901961  0.5892157  0.39215687]\n",
      "   [0.68921566 0.5882353  0.38921568]\n",
      "   [0.6872549  0.5862745  0.38333333]\n",
      "   ...\n",
      "   [0.06446078 0.0752451  0.15171568]\n",
      "   [0.07377451 0.08455882 0.16102941]\n",
      "   [0.07843138 0.08921569 0.16568628]]\n",
      "\n",
      "  [[0.7764706  0.67745095 0.47058824]\n",
      "   [0.7637255  0.6647059  0.45588234]\n",
      "   [0.7382353  0.6392157  0.42647058]\n",
      "   ...\n",
      "   [0.0502451  0.05906863 0.13946079]\n",
      "   [0.05857843 0.06740196 0.14779411]\n",
      "   [0.0627451  0.07156863 0.15196079]]\n",
      "\n",
      "  [[0.81960785 0.72156864 0.50980395]\n",
      "   [0.8009804  0.7029412  0.48921567]\n",
      "   [0.7637255  0.66568625 0.4480392 ]\n",
      "   ...\n",
      "   [0.04313726 0.05098039 0.13333334]\n",
      "   [0.05098039 0.05882353 0.14117648]\n",
      "   [0.05490196 0.0627451  0.14509805]]]\n",
      "\n",
      "\n",
      " [[[0.         0.00392157 0.        ]\n",
      "   [0.         0.00392157 0.        ]\n",
      "   [0.         0.00392157 0.        ]\n",
      "   ...\n",
      "   [0.         0.00392157 0.        ]\n",
      "   [0.         0.00392157 0.        ]\n",
      "   [0.         0.00392157 0.        ]]\n",
      "\n",
      "  [[0.         0.00392157 0.        ]\n",
      "   [0.         0.00392157 0.        ]\n",
      "   [0.         0.00392157 0.        ]\n",
      "   ...\n",
      "   [0.         0.00392157 0.        ]\n",
      "   [0.         0.00392157 0.        ]\n",
      "   [0.         0.00392157 0.        ]]\n",
      "\n",
      "  [[0.         0.00392157 0.        ]\n",
      "   [0.         0.00392157 0.        ]\n",
      "   [0.         0.00392157 0.        ]\n",
      "   ...\n",
      "   [0.         0.00392157 0.        ]\n",
      "   [0.         0.00392157 0.        ]\n",
      "   [0.         0.00392157 0.        ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.02352941 0.01568628 0.02745098]\n",
      "   [0.0254902  0.01764706 0.02941176]\n",
      "   [0.02941176 0.02156863 0.03333334]\n",
      "   ...\n",
      "   [0.11911765 0.09950981 0.0877451 ]\n",
      "   [0.11617647 0.09656863 0.08480392]\n",
      "   [0.11470588 0.09509804 0.08333334]]\n",
      "\n",
      "  [[0.02352941 0.01568628 0.02745098]\n",
      "   [0.0254902  0.01764706 0.02941176]\n",
      "   [0.02941176 0.02156863 0.03333334]\n",
      "   ...\n",
      "   [0.12401961 0.10441177 0.09264706]\n",
      "   [0.11911765 0.09950981 0.0877451 ]\n",
      "   [0.11666667 0.09705883 0.08529412]]\n",
      "\n",
      "  [[0.02352941 0.01568628 0.02745098]\n",
      "   [0.0254902  0.01764706 0.02941176]\n",
      "   [0.02941176 0.02156863 0.03333334]\n",
      "   ...\n",
      "   [0.1264706  0.10686275 0.09509804]\n",
      "   [0.12058824 0.10098039 0.08921569]\n",
      "   [0.11764706 0.09803922 0.08627451]]]], shape=(4, 224, 224, 3), dtype=float32)\n",
      "ลูปที่: 0\n",
      "Anchor batch shape: (4, 224, 224, 3)\n",
      "Positive batch shape: (4, 224, 224, 3)\n",
      "Negative batch shape: (4, 224, 224, 3)\n",
      "ลูปที่: tf.Tensor(\n",
      "[[[[0.1882353  0.17254902 0.13725491]\n",
      "   [0.19803922 0.18235295 0.14705883]\n",
      "   [0.21764706 0.20196079 0.16666667]\n",
      "   ...\n",
      "   [0.2009804  0.19705883 0.1264706 ]\n",
      "   [0.20294118 0.19901961 0.12843138]\n",
      "   [0.20392157 0.2        0.12941177]]\n",
      "\n",
      "  [[0.18921569 0.17254902 0.14019608]\n",
      "   [0.19754902 0.18088235 0.14852941]\n",
      "   [0.21421568 0.19754902 0.16519608]\n",
      "   ...\n",
      "   [0.2        0.19607843 0.1254902 ]\n",
      "   [0.20196079 0.19803922 0.12745099]\n",
      "   [0.20294118 0.19901961 0.12843138]]\n",
      "\n",
      "  [[0.19117647 0.17254902 0.14607844]\n",
      "   [0.19656862 0.17794117 0.15147059]\n",
      "   [0.20735294 0.18872549 0.1622549 ]\n",
      "   ...\n",
      "   [0.19803922 0.19411765 0.12352941]\n",
      "   [0.2        0.19607843 0.1254902 ]\n",
      "   [0.2009804  0.19705883 0.1264706 ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.26862746 0.2372549  0.19215687]\n",
      "   [0.26838234 0.23700981 0.19044118]\n",
      "   [0.26789215 0.2365196  0.1870098 ]\n",
      "   ...\n",
      "   [0.6637255  0.6990196  0.68921566]\n",
      "   [0.6127451  0.6480392  0.6382353 ]\n",
      "   [0.5872549  0.622549   0.6127451 ]]\n",
      "\n",
      "  [[0.27254903 0.24117647 0.19215687]\n",
      "   [0.27181372 0.24044117 0.19093138]\n",
      "   [0.27034312 0.2389706  0.18848039]\n",
      "   ...\n",
      "   [0.7480392  0.78333336 0.777451  ]\n",
      "   [0.7127451  0.7480392  0.74215686]\n",
      "   [0.69509804 0.73039216 0.7245098 ]]\n",
      "\n",
      "  [[0.27450982 0.24313726 0.19215687]\n",
      "   [0.2735294  0.24215686 0.19117647]\n",
      "   [0.27156863 0.24019608 0.18921569]\n",
      "   ...\n",
      "   [0.79019606 0.8254902  0.8215686 ]\n",
      "   [0.7627451  0.7980392  0.7941176 ]\n",
      "   [0.7490196  0.78431374 0.78039217]]]\n",
      "\n",
      "\n",
      " [[[0.34509805 0.29803923 0.2509804 ]\n",
      "   [0.34411764 0.29705882 0.25      ]\n",
      "   [0.34215686 0.29509804 0.24803922]\n",
      "   ...\n",
      "   [0.8117647  0.9019608  0.93333334]\n",
      "   [0.8117647  0.9019608  0.93333334]\n",
      "   [0.8117647  0.9019608  0.93333334]]\n",
      "\n",
      "  [[0.34705883 0.3        0.2529412 ]\n",
      "   [0.34705883 0.3        0.2529412 ]\n",
      "   [0.34705883 0.3        0.2529412 ]\n",
      "   ...\n",
      "   [0.81102943 0.9012255  0.93259805]\n",
      "   [0.8115196  0.9017157  0.93308824]\n",
      "   [0.8117647  0.9019608  0.93333334]]\n",
      "\n",
      "  [[0.3509804  0.30392158 0.25686276]\n",
      "   [0.3529412  0.30588236 0.25882354]\n",
      "   [0.35686275 0.30980393 0.2627451 ]\n",
      "   ...\n",
      "   [0.8095588  0.8997549  0.9311274 ]\n",
      "   [0.81102943 0.9012255  0.93259805]\n",
      "   [0.8117647  0.9019608  0.93333334]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.7892157  0.69509804 0.6480392 ]\n",
      "   [0.785049   0.69191176 0.6428922 ]\n",
      "   [0.7767157  0.6855392  0.63259804]\n",
      "   ...\n",
      "   [0.6970588  0.75       0.782598  ]\n",
      "   [0.69509804 0.7519608  0.78112745]\n",
      "   [0.69411767 0.7529412  0.78039217]]\n",
      "\n",
      "  [[0.7911765  0.6970588  0.65      ]\n",
      "   [0.7865196  0.6933824  0.64436275]\n",
      "   [0.7772059  0.68602943 0.63308823]\n",
      "   ...\n",
      "   [0.68921566 0.74215686 0.7732843 ]\n",
      "   [0.6872549  0.7441176  0.7727941 ]\n",
      "   [0.6862745  0.74509805 0.77254903]]\n",
      "\n",
      "  [[0.7921569  0.69803923 0.6509804 ]\n",
      "   [0.7872549  0.69411767 0.64509803]\n",
      "   [0.777451   0.6862745  0.6333333 ]\n",
      "   ...\n",
      "   [0.6852941  0.7382353  0.76862746]\n",
      "   [0.68333334 0.74019605 0.76862746]\n",
      "   [0.68235296 0.7411765  0.76862746]]]\n",
      "\n",
      "\n",
      " [[[0.7647059  0.7490196  0.7372549 ]\n",
      "   [0.7647059  0.7490196  0.7372549 ]\n",
      "   [0.7647059  0.7490196  0.7372549 ]\n",
      "   ...\n",
      "   [0.11372549 0.04019608 0.0245098 ]\n",
      "   [0.10588235 0.03431373 0.01862745]\n",
      "   [0.10196079 0.03137255 0.01568628]]\n",
      "\n",
      "  [[0.7647059  0.7490196  0.7372549 ]\n",
      "   [0.7647059  0.7490196  0.7372549 ]\n",
      "   [0.7647059  0.7490196  0.7372549 ]\n",
      "   ...\n",
      "   [0.1120098  0.03848039 0.02279412]\n",
      "   [0.10465686 0.03308824 0.01740196]\n",
      "   [0.10098039 0.03039216 0.01470588]]\n",
      "\n",
      "  [[0.7647059  0.7490196  0.7372549 ]\n",
      "   [0.7647059  0.7490196  0.7372549 ]\n",
      "   [0.7647059  0.7490196  0.7372549 ]\n",
      "   ...\n",
      "   [0.10857843 0.03504902 0.01936275]\n",
      "   [0.10220588 0.03063725 0.01495098]\n",
      "   [0.09901961 0.02843137 0.0127451 ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.7882353  0.76862746 0.75686276]\n",
      "   [0.7882353  0.76862746 0.75686276]\n",
      "   [0.7882353  0.76862746 0.75686276]\n",
      "   ...\n",
      "   [0.7252451  0.44191176 0.2840686 ]\n",
      "   [0.72083336 0.4375     0.27965686]\n",
      "   [0.71862745 0.43529412 0.27745098]]\n",
      "\n",
      "  [[0.7882353  0.76862746 0.75686276]\n",
      "   [0.7882353  0.76862746 0.75686276]\n",
      "   [0.7882353  0.76862746 0.75686276]\n",
      "   ...\n",
      "   [0.73651963 0.4512255  0.29142156]\n",
      "   [0.73112744 0.44583333 0.2860294 ]\n",
      "   [0.72843134 0.44313726 0.28333333]]\n",
      "\n",
      "  [[0.7882353  0.76862746 0.75686276]\n",
      "   [0.7882353  0.76862746 0.75686276]\n",
      "   [0.7882353  0.76862746 0.75686276]\n",
      "   ...\n",
      "   [0.74215686 0.45588234 0.29509804]\n",
      "   [0.7362745  0.45       0.28921568]\n",
      "   [0.73333335 0.44705883 0.28627452]]]\n",
      "\n",
      "\n",
      " [[[0.49411765 0.5137255  0.49803922]\n",
      "   [0.4990196  0.5156863  0.4990196 ]\n",
      "   [0.5088235  0.51960784 0.5009804 ]\n",
      "   ...\n",
      "   [0.26862746 0.49313724 0.40784314]\n",
      "   [0.27254903 0.49117646 0.40784314]\n",
      "   [0.27450982 0.49019608 0.40784314]]\n",
      "\n",
      "  [[0.48921567 0.5058824  0.49117646]\n",
      "   [0.49191177 0.5063726  0.49044117]\n",
      "   [0.49730393 0.50735295 0.48897058]\n",
      "   ...\n",
      "   [0.27009803 0.49534315 0.40980393]\n",
      "   [0.27107844 0.49191177 0.40784314]\n",
      "   [0.27156863 0.49019608 0.40686274]]\n",
      "\n",
      "  [[0.47941175 0.49019608 0.47745097]\n",
      "   [0.4776961  0.4877451  0.4732843 ]\n",
      "   [0.4742647  0.48284313 0.46495098]\n",
      "   ...\n",
      "   [0.27303922 0.4997549  0.4137255 ]\n",
      "   [0.26813725 0.49338236 0.40784314]\n",
      "   [0.26568627 0.49019608 0.40490195]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.07058824 0.07058824 0.0627451 ]\n",
      "   [0.06960785 0.06960785 0.06176471]\n",
      "   [0.06764706 0.06764706 0.05980392]\n",
      "   ...\n",
      "   [0.06421569 0.06029412 0.07990196]\n",
      "   [0.06715687 0.0632353  0.08284314]\n",
      "   [0.06862745 0.06470589 0.08431373]]\n",
      "\n",
      "  [[0.07058824 0.07058824 0.0627451 ]\n",
      "   [0.06960785 0.06960785 0.06176471]\n",
      "   [0.06764706 0.06764706 0.05980392]\n",
      "   ...\n",
      "   [0.06519608 0.06127451 0.08088236]\n",
      "   [0.07009804 0.06617647 0.08578432]\n",
      "   [0.07254902 0.06862745 0.0882353 ]]\n",
      "\n",
      "  [[0.07058824 0.07058824 0.0627451 ]\n",
      "   [0.06960785 0.06960785 0.06176471]\n",
      "   [0.06764706 0.06764706 0.05980392]\n",
      "   ...\n",
      "   [0.06568628 0.06176471 0.08137255]\n",
      "   [0.07156863 0.06764706 0.0872549 ]\n",
      "   [0.07450981 0.07058824 0.09019608]]]], shape=(4, 224, 224, 3), dtype=float32)\n",
      "ลูปที่: 0\n"
     ]
    }
   ],
   "source": [
    "l = 0\n",
    "# ทดสอบ\n",
    "for a, p, n in train_dataset.take(5):\n",
    "    print(\"Anchor batch shape:\", a.shape)\n",
    "    print(\"Positive batch shape:\", p.shape)\n",
    "    print(\"Negative batch shape:\", n.shape)\n",
    "    print(\"ลูปที่:\", a)\n",
    "    #l = l + 1Q\n",
    "    print(\"ลูปที่:\", l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96adb3fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Lambda, Input,Dropout\n",
    "\n",
    "def QQQ():\n",
    "    input_shape = (224, 224, 3)\n",
    "\n",
    "    base_model = ResNet50(\n",
    "        include_top=False,\n",
    "        weights='imagenet',\n",
    "        input_shape=input_shape\n",
    "    )\n",
    "    # เพิ่มโค้ดนี้ในฟังก์ชัน cor() ก่อน return model\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "        \n",
    "    x = base_model.output\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dense(128)(x)\n",
    "    embedding = Lambda(lambda x: tf.math.l2_normalize(x, axis=1))(x)\n",
    "    \n",
    "    # สร้างโมเดลและ return\n",
    "    model = Model(inputs=base_model.input, outputs=embedding)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a524018e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_resnet_facenet(input_shape=(160, 160, 3), embedding_dim=128):\n",
    "\n",
    "    base_model = ResNet50(weights='imagenet', include_top=False, input_shape=input_shape, pooling='avg')\n",
    "    inputs = Input(shape=input_shape)\n",
    "    x = base_model(inputs)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Dense(embedding_dim)(x)\n",
    "    embedding = Lambda(lambda y: tf.math.l2_normalize(y, axis=1), name='l2_normalization')(x)\n",
    "\n",
    "    # สร้าง Model\n",
    "    model = Model(inputs=inputs, outputs=embedding)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a9002532",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_3 (InputLayer)           [(None, 224, 224, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " conv1_pad (ZeroPadding2D)      (None, 230, 230, 3)  0           ['input_3[0][0]']                \n",
      "                                                                                                  \n",
      " conv1_conv (Conv2D)            (None, 112, 112, 64  9472        ['conv1_pad[0][0]']              \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv1_bn (BatchNormalization)  (None, 112, 112, 64  256         ['conv1_conv[0][0]']             \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv1_relu (Activation)        (None, 112, 112, 64  0           ['conv1_bn[0][0]']               \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " pool1_pad (ZeroPadding2D)      (None, 114, 114, 64  0           ['conv1_relu[0][0]']             \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " pool1_pool (MaxPooling2D)      (None, 56, 56, 64)   0           ['pool1_pad[0][0]']              \n",
      "                                                                                                  \n",
      " conv2_block1_1_conv (Conv2D)   (None, 56, 56, 64)   4160        ['pool1_pool[0][0]']             \n",
      "                                                                                                  \n",
      " conv2_block1_1_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block1_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block1_1_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block1_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block1_2_conv (Conv2D)   (None, 56, 56, 64)   36928       ['conv2_block1_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block1_2_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block1_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block1_2_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block1_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block1_0_conv (Conv2D)   (None, 56, 56, 256)  16640       ['pool1_pool[0][0]']             \n",
      "                                                                                                  \n",
      " conv2_block1_3_conv (Conv2D)   (None, 56, 56, 256)  16640       ['conv2_block1_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block1_0_bn (BatchNormal  (None, 56, 56, 256)  1024       ['conv2_block1_0_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block1_3_bn (BatchNormal  (None, 56, 56, 256)  1024       ['conv2_block1_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block1_add (Add)         (None, 56, 56, 256)  0           ['conv2_block1_0_bn[0][0]',      \n",
      "                                                                  'conv2_block1_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv2_block1_out (Activation)  (None, 56, 56, 256)  0           ['conv2_block1_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv2_block2_1_conv (Conv2D)   (None, 56, 56, 64)   16448       ['conv2_block1_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv2_block2_1_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block2_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block2_1_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block2_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block2_2_conv (Conv2D)   (None, 56, 56, 64)   36928       ['conv2_block2_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block2_2_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block2_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block2_2_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block2_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block2_3_conv (Conv2D)   (None, 56, 56, 256)  16640       ['conv2_block2_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block2_3_bn (BatchNormal  (None, 56, 56, 256)  1024       ['conv2_block2_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block2_add (Add)         (None, 56, 56, 256)  0           ['conv2_block1_out[0][0]',       \n",
      "                                                                  'conv2_block2_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv2_block2_out (Activation)  (None, 56, 56, 256)  0           ['conv2_block2_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv2_block3_1_conv (Conv2D)   (None, 56, 56, 64)   16448       ['conv2_block2_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv2_block3_1_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block3_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block3_1_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block3_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block3_2_conv (Conv2D)   (None, 56, 56, 64)   36928       ['conv2_block3_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block3_2_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block3_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block3_2_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block3_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block3_3_conv (Conv2D)   (None, 56, 56, 256)  16640       ['conv2_block3_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block3_3_bn (BatchNormal  (None, 56, 56, 256)  1024       ['conv2_block3_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block3_add (Add)         (None, 56, 56, 256)  0           ['conv2_block2_out[0][0]',       \n",
      "                                                                  'conv2_block3_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv2_block3_out (Activation)  (None, 56, 56, 256)  0           ['conv2_block3_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block1_1_conv (Conv2D)   (None, 28, 28, 128)  32896       ['conv2_block3_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block1_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block1_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block1_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block1_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block1_2_conv (Conv2D)   (None, 28, 28, 128)  147584      ['conv3_block1_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block1_2_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block1_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block1_2_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block1_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block1_0_conv (Conv2D)   (None, 28, 28, 512)  131584      ['conv2_block3_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block1_3_conv (Conv2D)   (None, 28, 28, 512)  66048       ['conv3_block1_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block1_0_bn (BatchNormal  (None, 28, 28, 512)  2048       ['conv3_block1_0_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block1_3_bn (BatchNormal  (None, 28, 28, 512)  2048       ['conv3_block1_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block1_add (Add)         (None, 28, 28, 512)  0           ['conv3_block1_0_bn[0][0]',      \n",
      "                                                                  'conv3_block1_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv3_block1_out (Activation)  (None, 28, 28, 512)  0           ['conv3_block1_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block2_1_conv (Conv2D)   (None, 28, 28, 128)  65664       ['conv3_block1_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block2_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block2_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block2_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block2_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block2_2_conv (Conv2D)   (None, 28, 28, 128)  147584      ['conv3_block2_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block2_2_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block2_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block2_2_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block2_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block2_3_conv (Conv2D)   (None, 28, 28, 512)  66048       ['conv3_block2_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block2_3_bn (BatchNormal  (None, 28, 28, 512)  2048       ['conv3_block2_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block2_add (Add)         (None, 28, 28, 512)  0           ['conv3_block1_out[0][0]',       \n",
      "                                                                  'conv3_block2_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv3_block2_out (Activation)  (None, 28, 28, 512)  0           ['conv3_block2_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block3_1_conv (Conv2D)   (None, 28, 28, 128)  65664       ['conv3_block2_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block3_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block3_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block3_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block3_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block3_2_conv (Conv2D)   (None, 28, 28, 128)  147584      ['conv3_block3_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block3_2_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block3_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block3_2_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block3_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block3_3_conv (Conv2D)   (None, 28, 28, 512)  66048       ['conv3_block3_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block3_3_bn (BatchNormal  (None, 28, 28, 512)  2048       ['conv3_block3_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block3_add (Add)         (None, 28, 28, 512)  0           ['conv3_block2_out[0][0]',       \n",
      "                                                                  'conv3_block3_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv3_block3_out (Activation)  (None, 28, 28, 512)  0           ['conv3_block3_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block4_1_conv (Conv2D)   (None, 28, 28, 128)  65664       ['conv3_block3_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block4_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block4_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block4_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block4_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block4_2_conv (Conv2D)   (None, 28, 28, 128)  147584      ['conv3_block4_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block4_2_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block4_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block4_2_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block4_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block4_3_conv (Conv2D)   (None, 28, 28, 512)  66048       ['conv3_block4_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block4_3_bn (BatchNormal  (None, 28, 28, 512)  2048       ['conv3_block4_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block4_add (Add)         (None, 28, 28, 512)  0           ['conv3_block3_out[0][0]',       \n",
      "                                                                  'conv3_block4_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv3_block4_out (Activation)  (None, 28, 28, 512)  0           ['conv3_block4_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block1_1_conv (Conv2D)   (None, 14, 14, 256)  131328      ['conv3_block4_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block1_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block1_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block1_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block1_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block1_2_conv (Conv2D)   (None, 14, 14, 256)  590080      ['conv4_block1_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block1_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block1_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block1_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block1_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block1_0_conv (Conv2D)   (None, 14, 14, 1024  525312      ['conv3_block4_out[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block1_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block1_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block1_0_bn (BatchNormal  (None, 14, 14, 1024  4096       ['conv4_block1_0_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block1_3_bn (BatchNormal  (None, 14, 14, 1024  4096       ['conv4_block1_3_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block1_add (Add)         (None, 14, 14, 1024  0           ['conv4_block1_0_bn[0][0]',      \n",
      "                                )                                 'conv4_block1_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block1_out (Activation)  (None, 14, 14, 1024  0           ['conv4_block1_add[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block2_1_conv (Conv2D)   (None, 14, 14, 256)  262400      ['conv4_block1_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block2_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block2_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block2_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block2_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block2_2_conv (Conv2D)   (None, 14, 14, 256)  590080      ['conv4_block2_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block2_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block2_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block2_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block2_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block2_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block2_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block2_3_bn (BatchNormal  (None, 14, 14, 1024  4096       ['conv4_block2_3_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block2_add (Add)         (None, 14, 14, 1024  0           ['conv4_block1_out[0][0]',       \n",
      "                                )                                 'conv4_block2_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block2_out (Activation)  (None, 14, 14, 1024  0           ['conv4_block2_add[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block3_1_conv (Conv2D)   (None, 14, 14, 256)  262400      ['conv4_block2_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block3_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block3_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block3_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block3_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block3_2_conv (Conv2D)   (None, 14, 14, 256)  590080      ['conv4_block3_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block3_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block3_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block3_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block3_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block3_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block3_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block3_3_bn (BatchNormal  (None, 14, 14, 1024  4096       ['conv4_block3_3_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block3_add (Add)         (None, 14, 14, 1024  0           ['conv4_block2_out[0][0]',       \n",
      "                                )                                 'conv4_block3_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block3_out (Activation)  (None, 14, 14, 1024  0           ['conv4_block3_add[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block4_1_conv (Conv2D)   (None, 14, 14, 256)  262400      ['conv4_block3_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block4_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block4_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block4_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block4_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block4_2_conv (Conv2D)   (None, 14, 14, 256)  590080      ['conv4_block4_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block4_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block4_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block4_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block4_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block4_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block4_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block4_3_bn (BatchNormal  (None, 14, 14, 1024  4096       ['conv4_block4_3_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block4_add (Add)         (None, 14, 14, 1024  0           ['conv4_block3_out[0][0]',       \n",
      "                                )                                 'conv4_block4_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block4_out (Activation)  (None, 14, 14, 1024  0           ['conv4_block4_add[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block5_1_conv (Conv2D)   (None, 14, 14, 256)  262400      ['conv4_block4_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block5_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block5_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block5_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block5_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block5_2_conv (Conv2D)   (None, 14, 14, 256)  590080      ['conv4_block5_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block5_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block5_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block5_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block5_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block5_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block5_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block5_3_bn (BatchNormal  (None, 14, 14, 1024  4096       ['conv4_block5_3_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block5_add (Add)         (None, 14, 14, 1024  0           ['conv4_block4_out[0][0]',       \n",
      "                                )                                 'conv4_block5_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block5_out (Activation)  (None, 14, 14, 1024  0           ['conv4_block5_add[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block6_1_conv (Conv2D)   (None, 14, 14, 256)  262400      ['conv4_block5_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block6_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block6_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block6_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block6_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block6_2_conv (Conv2D)   (None, 14, 14, 256)  590080      ['conv4_block6_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block6_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block6_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block6_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block6_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block6_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block6_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block6_3_bn (BatchNormal  (None, 14, 14, 1024  4096       ['conv4_block6_3_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block6_add (Add)         (None, 14, 14, 1024  0           ['conv4_block5_out[0][0]',       \n",
      "                                )                                 'conv4_block6_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block6_out (Activation)  (None, 14, 14, 1024  0           ['conv4_block6_add[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv5_block1_1_conv (Conv2D)   (None, 7, 7, 512)    524800      ['conv4_block6_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv5_block1_1_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block1_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block1_1_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block1_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block1_2_conv (Conv2D)   (None, 7, 7, 512)    2359808     ['conv5_block1_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block1_2_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block1_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block1_2_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block1_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block1_0_conv (Conv2D)   (None, 7, 7, 2048)   2099200     ['conv4_block6_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv5_block1_3_conv (Conv2D)   (None, 7, 7, 2048)   1050624     ['conv5_block1_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block1_0_bn (BatchNormal  (None, 7, 7, 2048)  8192        ['conv5_block1_0_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block1_3_bn (BatchNormal  (None, 7, 7, 2048)  8192        ['conv5_block1_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block1_add (Add)         (None, 7, 7, 2048)   0           ['conv5_block1_0_bn[0][0]',      \n",
      "                                                                  'conv5_block1_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv5_block1_out (Activation)  (None, 7, 7, 2048)   0           ['conv5_block1_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv5_block2_1_conv (Conv2D)   (None, 7, 7, 512)    1049088     ['conv5_block1_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv5_block2_1_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block2_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block2_1_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block2_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block2_2_conv (Conv2D)   (None, 7, 7, 512)    2359808     ['conv5_block2_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block2_2_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block2_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block2_2_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block2_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block2_3_conv (Conv2D)   (None, 7, 7, 2048)   1050624     ['conv5_block2_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block2_3_bn (BatchNormal  (None, 7, 7, 2048)  8192        ['conv5_block2_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block2_add (Add)         (None, 7, 7, 2048)   0           ['conv5_block1_out[0][0]',       \n",
      "                                                                  'conv5_block2_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv5_block2_out (Activation)  (None, 7, 7, 2048)   0           ['conv5_block2_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv5_block3_1_conv (Conv2D)   (None, 7, 7, 512)    1049088     ['conv5_block2_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv5_block3_1_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block3_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block3_1_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block3_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block3_2_conv (Conv2D)   (None, 7, 7, 512)    2359808     ['conv5_block3_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block3_2_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block3_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block3_2_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block3_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block3_3_conv (Conv2D)   (None, 7, 7, 2048)   1050624     ['conv5_block3_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block3_3_bn (BatchNormal  (None, 7, 7, 2048)  8192        ['conv5_block3_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block3_add (Add)         (None, 7, 7, 2048)   0           ['conv5_block2_out[0][0]',       \n",
      "                                                                  'conv5_block3_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv5_block3_out (Activation)  (None, 7, 7, 2048)   0           ['conv5_block3_add[0][0]']       \n",
      "                                                                                                  \n",
      " global_average_pooling2d_2 (Gl  (None, 2048)        0           ['conv5_block3_out[0][0]']       \n",
      " obalAveragePooling2D)                                                                            \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 128)          262272      ['global_average_pooling2d_2[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " lambda_2 (Lambda)              (None, 128)          0           ['dense_2[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 23,849,984\n",
      "Trainable params: 262,272\n",
      "Non-trainable params: 23,587,712\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = QQQ()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "77ba54b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2f07c9a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def triplet_loss(anchor, positive, negative, alpha=0.2):\n",
    "    epsilon = 1e-8\n",
    "    \n",
    "    # คำนวณระยะห่างแบบ Euclidean squared\n",
    "    pos_dist = tf.reduce_sum(tf.square(anchor - positive), axis=1)\n",
    "    neg_dist = tf.reduce_sum(tf.square(anchor - negative), axis=1)\n",
    "    \n",
    "    # เพิ่ม epsilon และใช้ tf.clip_by_value เพื่อป้องกันค่าผิดปกติ\n",
    "    pos_dist = tf.clip_by_value(pos_dist, epsilon, 10.0)\n",
    "    neg_dist = tf.clip_by_value(neg_dist, epsilon, 10.0)\n",
    "    \n",
    "    # คำนวณ basic loss\n",
    "    basic_loss = pos_dist - neg_dist + alpha\n",
    "    \n",
    "    # ใช้ tf.nn.relu แทน tf.maximum\n",
    "    loss = tf.reduce_mean(tf.nn.relu(basic_loss))\n",
    "    \n",
    "    # ตรวจสอบ NaN\n",
    "    loss = tf.where(tf.math.is_finite(loss), loss, tf.constant(0.0))\n",
    "    \n",
    "    return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c33b7610",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def losshard_mining(anchor, positive, negative, alpha=0.2):\n",
    "    \"\"\"\n",
    "    Computes Triplet Loss with Hard Triplet Mining.\n",
    "    \"\"\"\n",
    "    # 1. Calculate squared Euclidean distances\n",
    "    pos_dist = tf.reduce_sum(tf.square(anchor - positive), axis=1)\n",
    "    neg_dist = tf.reduce_sum(tf.square(anchor - negative), axis=1)\n",
    "\n",
    "    # 2. Find all valid triplets in the batch\n",
    "    all_triplets = pos_dist - neg_dist + alpha\n",
    "    \n",
    "    # 3. Filter out the easy triplets (loss <= 0)\n",
    "    hard_triplets = tf.where(all_triplets > 0, all_triplets, tf.zeros_like(all_triplets))\n",
    "\n",
    "    # 4. Take the mean of the hard triplets\n",
    "    # Add a small value to the denominator to avoid division by zero\n",
    "    num_hard_triplets = tf.reduce_sum(tf.cast(hard_triplets > 0, dtype=tf.float32))\n",
    "    \n",
    "    # Check if there are any hard triplets. If not, the loss is 0\n",
    "    if num_hard_triplets > 0:\n",
    "        loss = tf.reduce_sum(hard_triplets) / num_hard_triplets\n",
    "    else:\n",
    "        loss = tf.constant(0.0)\n",
    "\n",
    "    # Return the loss\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3660810d",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def triplet_loss_val(anchor, positive, negative, alpha=0.2):\n",
    "    epsilon = 1e-8\n",
    "    \n",
    "    # คำนวณระยะห่างแบบ Euclidean squared\n",
    "    pos_dist = tf.reduce_sum(tf.square(anchor - positive), axis=1)\n",
    "    neg_dist = tf.reduce_sum(tf.square(anchor - negative), axis=1)\n",
    "    \n",
    "    # เพิ่ม epsilon และใช้ tf.clip_by_value เพื่อป้องกันค่าผิดปกติ\n",
    "    pos_dist = tf.clip_by_value(pos_dist, epsilon, 10.0)\n",
    "    neg_dist = tf.clip_by_value(neg_dist, epsilon, 10.0)\n",
    "    \n",
    "    # คำนวณ basic loss\n",
    "    basic_loss = pos_dist - neg_dist + alpha\n",
    "    \n",
    "    # ใช้ tf.nn.relu แทน tf.maximum\n",
    "    loss = tf.reduce_mean(tf.nn.relu(basic_loss))\n",
    "    \n",
    "    # ตรวจสอบ NaN\n",
    "    loss = tf.where(tf.math.is_finite(loss), loss, tf.constant(0.0))\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9b1151c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(anchor, positive, negative):\n",
    "    with tf.GradientTape() as tape:\n",
    "        anchor_embedding = model(anchor, training=True)\n",
    "        positive_embedding = model(positive, training=True)\n",
    "        negative_embedding = model(negative, training=True)\n",
    "        loss = triplet_loss(anchor_embedding, positive_embedding, negative_embedding)\n",
    "    \n",
    "    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e8d3434c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- เริ่มการฝึกโมเดล ---\n",
      "\n",
      "--- Epoch 1/50 ---\n",
      "Batch 5000, Training Loss: 0.2273\n",
      "Batch 10000, Training Loss: 0.1292\n",
      "Batch 15000, Training Loss: 0.1406\n",
      "\n",
      "สรุป Epoch 1/50, Training Loss เฉลี่ย: 0.1810\n",
      "\n",
      "--- เริ่ม Validation ---\n",
      "Validation Batch 500, Validation Loss: 0.2207\n",
      "Validation Batch 1000, Validation Loss: 0.1797\n",
      "Validation Batch 1500, Validation Loss: 0.2212\n",
      "สรุป Validation Loss เฉลี่ย: 0.1809\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "\n",
      "--- Epoch 2/50 ---\n",
      "Batch 5000, Training Loss: 0.1683\n",
      "Batch 10000, Training Loss: 0.1406\n",
      "Batch 15000, Training Loss: 0.1708\n",
      "\n",
      "สรุป Epoch 2/50, Training Loss เฉลี่ย: 0.1581\n",
      "\n",
      "--- เริ่ม Validation ---\n",
      "Validation Batch 500, Validation Loss: 0.1924\n",
      "Validation Batch 1000, Validation Loss: 0.1721\n",
      "Validation Batch 1500, Validation Loss: 0.1740\n",
      "สรุป Validation Loss เฉลี่ย: 0.1554\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "\n",
      "--- Epoch 3/50 ---\n",
      "Batch 5000, Training Loss: 0.1243\n",
      "Batch 10000, Training Loss: 0.1905\n",
      "Batch 15000, Training Loss: 0.0385\n",
      "\n",
      "สรุป Epoch 3/50, Training Loss เฉลี่ย: 0.1470\n",
      "\n",
      "--- เริ่ม Validation ---\n",
      "Validation Batch 500, Validation Loss: 0.1826\n",
      "Validation Batch 1000, Validation Loss: 0.1615\n",
      "Validation Batch 1500, Validation Loss: 0.1521\n",
      "สรุป Validation Loss เฉลี่ย: 0.1443\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "\n",
      "--- Epoch 4/50 ---\n",
      "Batch 5000, Training Loss: 0.2601\n",
      "Batch 10000, Training Loss: 0.1854\n",
      "Batch 15000, Training Loss: 0.1767\n",
      "\n",
      "สรุป Epoch 4/50, Training Loss เฉลี่ย: 0.1398\n",
      "\n",
      "--- เริ่ม Validation ---\n",
      "Validation Batch 500, Validation Loss: 0.0980\n",
      "Validation Batch 1000, Validation Loss: 0.2016\n",
      "Validation Batch 1500, Validation Loss: 0.0552\n",
      "สรุป Validation Loss เฉลี่ย: 0.1373\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "\n",
      "--- Epoch 5/50 ---\n",
      "Batch 5000, Training Loss: 0.0594\n",
      "Batch 10000, Training Loss: 0.1232\n",
      "Batch 15000, Training Loss: 0.1222\n",
      "\n",
      "สรุป Epoch 5/50, Training Loss เฉลี่ย: 0.1341\n",
      "\n",
      "--- เริ่ม Validation ---\n",
      "Validation Batch 500, Validation Loss: 0.1756\n",
      "Validation Batch 1000, Validation Loss: 0.0816\n",
      "Validation Batch 1500, Validation Loss: 0.0146\n",
      "สรุป Validation Loss เฉลี่ย: 0.1404\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "\n",
      "--- Epoch 6/50 ---\n",
      "Batch 5000, Training Loss: 0.0754\n",
      "Batch 10000, Training Loss: 0.0641\n",
      "Batch 15000, Training Loss: 0.0191\n",
      "\n",
      "สรุป Epoch 6/50, Training Loss เฉลี่ย: 0.1319\n",
      "\n",
      "--- เริ่ม Validation ---\n",
      "Validation Batch 500, Validation Loss: 0.2015\n",
      "Validation Batch 1000, Validation Loss: 0.0304\n",
      "Validation Batch 1500, Validation Loss: 0.0660\n",
      "สรุป Validation Loss เฉลี่ย: 0.1265\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "\n",
      "--- Epoch 7/50 ---\n",
      "Batch 5000, Training Loss: 0.1776\n",
      "Batch 10000, Training Loss: 0.1124\n",
      "Batch 15000, Training Loss: 0.0093\n",
      "\n",
      "สรุป Epoch 7/50, Training Loss เฉลี่ย: 0.1282\n",
      "\n",
      "--- เริ่ม Validation ---\n",
      "Validation Batch 500, Validation Loss: 0.1493\n",
      "Validation Batch 1000, Validation Loss: 0.0832\n",
      "Validation Batch 1500, Validation Loss: 0.0679\n",
      "สรุป Validation Loss เฉลี่ย: 0.1252\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "\n",
      "--- Epoch 8/50 ---\n",
      "Batch 5000, Training Loss: 0.2053\n",
      "Batch 10000, Training Loss: 0.0336\n",
      "Batch 15000, Training Loss: 0.1268\n",
      "\n",
      "สรุป Epoch 8/50, Training Loss เฉลี่ย: 0.1274\n",
      "\n",
      "--- เริ่ม Validation ---\n",
      "Validation Batch 500, Validation Loss: 0.1092\n",
      "Validation Batch 1000, Validation Loss: 0.1070\n",
      "Validation Batch 1500, Validation Loss: 0.2576\n",
      "สรุป Validation Loss เฉลี่ย: 0.1268\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "\n",
      "--- Epoch 9/50 ---\n",
      "Batch 5000, Training Loss: 0.1015\n",
      "Batch 10000, Training Loss: 0.0531\n",
      "Batch 15000, Training Loss: 0.1023\n",
      "\n",
      "สรุป Epoch 9/50, Training Loss เฉลี่ย: 0.1251\n",
      "\n",
      "--- เริ่ม Validation ---\n",
      "Validation Batch 500, Validation Loss: 0.0767\n",
      "Validation Batch 1000, Validation Loss: 0.1249\n",
      "Validation Batch 1500, Validation Loss: 0.0897\n",
      "สรุป Validation Loss เฉลี่ย: 0.1202\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "\n",
      "--- Epoch 10/50 ---\n",
      "Batch 5000, Training Loss: 0.1500\n",
      "Batch 10000, Training Loss: 0.1030\n",
      "Batch 15000, Training Loss: 0.0940\n",
      "\n",
      "สรุป Epoch 10/50, Training Loss เฉลี่ย: 0.1241\n",
      "\n",
      "--- เริ่ม Validation ---\n",
      "Validation Batch 500, Validation Loss: 0.1496\n",
      "Validation Batch 1000, Validation Loss: 0.0437\n",
      "Validation Batch 1500, Validation Loss: 0.1875\n",
      "สรุป Validation Loss เฉลี่ย: 0.1346\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "\n",
      "--- Epoch 11/50 ---\n",
      "Batch 5000, Training Loss: 0.1729\n",
      "Batch 10000, Training Loss: 0.0821\n",
      "Batch 15000, Training Loss: 0.1586\n",
      "\n",
      "สรุป Epoch 11/50, Training Loss เฉลี่ย: 0.1230\n",
      "\n",
      "--- เริ่ม Validation ---\n",
      "Validation Batch 500, Validation Loss: 0.0225\n",
      "Validation Batch 1000, Validation Loss: 0.1626\n",
      "Validation Batch 1500, Validation Loss: 0.0452\n",
      "สรุป Validation Loss เฉลี่ย: 0.1219\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "\n",
      "--- Epoch 12/50 ---\n",
      "Batch 5000, Training Loss: 0.1693\n",
      "Batch 10000, Training Loss: 0.1400\n",
      "Batch 15000, Training Loss: 0.1375\n",
      "\n",
      "สรุป Epoch 12/50, Training Loss เฉลี่ย: 0.1206\n",
      "\n",
      "--- เริ่ม Validation ---\n",
      "Validation Batch 500, Validation Loss: 0.0200\n",
      "Validation Batch 1000, Validation Loss: 0.0000\n",
      "Validation Batch 1500, Validation Loss: 0.1900\n",
      "สรุป Validation Loss เฉลี่ย: 0.1185\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "\n",
      "--- Epoch 13/50 ---\n",
      "Batch 5000, Training Loss: 0.1449\n",
      "Batch 10000, Training Loss: 0.1344\n",
      "Batch 15000, Training Loss: 0.0761\n",
      "\n",
      "สรุป Epoch 13/50, Training Loss เฉลี่ย: 0.1197\n",
      "\n",
      "--- เริ่ม Validation ---\n",
      "Validation Batch 500, Validation Loss: 0.3174\n",
      "Validation Batch 1000, Validation Loss: 0.1484\n",
      "Validation Batch 1500, Validation Loss: 0.1224\n",
      "สรุป Validation Loss เฉลี่ย: 0.1205\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "\n",
      "--- Epoch 14/50 ---\n",
      "Batch 5000, Training Loss: 0.2582\n",
      "Batch 10000, Training Loss: 0.0887\n",
      "Batch 15000, Training Loss: 0.1160\n",
      "\n",
      "สรุป Epoch 14/50, Training Loss เฉลี่ย: 0.1202\n",
      "\n",
      "--- เริ่ม Validation ---\n",
      "Validation Batch 500, Validation Loss: 0.1647\n",
      "Validation Batch 1000, Validation Loss: 0.0063\n",
      "Validation Batch 1500, Validation Loss: 0.1819\n",
      "สรุป Validation Loss เฉลี่ย: 0.1174\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "\n",
      "--- Epoch 15/50 ---\n",
      "Batch 5000, Training Loss: 0.0000\n",
      "Batch 10000, Training Loss: 0.0970\n",
      "Batch 15000, Training Loss: 0.1420\n",
      "\n",
      "สรุป Epoch 15/50, Training Loss เฉลี่ย: 0.1174\n",
      "\n",
      "--- เริ่ม Validation ---\n",
      "Validation Batch 500, Validation Loss: 0.0383\n",
      "Validation Batch 1000, Validation Loss: 0.1085\n",
      "Validation Batch 1500, Validation Loss: 0.1156\n",
      "สรุป Validation Loss เฉลี่ย: 0.1159\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "\n",
      "--- Epoch 16/50 ---\n",
      "Batch 5000, Training Loss: 0.0130\n",
      "Batch 10000, Training Loss: 0.1161\n",
      "Batch 15000, Training Loss: 0.1458\n",
      "\n",
      "สรุป Epoch 16/50, Training Loss เฉลี่ย: 0.1170\n",
      "\n",
      "--- เริ่ม Validation ---\n",
      "Validation Batch 500, Validation Loss: 0.0433\n",
      "Validation Batch 1000, Validation Loss: 0.1326\n",
      "Validation Batch 1500, Validation Loss: 0.0322\n",
      "สรุป Validation Loss เฉลี่ย: 0.1147\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "\n",
      "--- Epoch 17/50 ---\n",
      "Batch 5000, Training Loss: 0.1144\n",
      "Batch 10000, Training Loss: 0.0229\n",
      "Batch 15000, Training Loss: 0.1098\n",
      "\n",
      "สรุป Epoch 17/50, Training Loss เฉลี่ย: 0.1156\n",
      "\n",
      "--- เริ่ม Validation ---\n",
      "Validation Batch 500, Validation Loss: 0.2117\n",
      "Validation Batch 1000, Validation Loss: 0.0129\n",
      "Validation Batch 1500, Validation Loss: 0.0541\n",
      "สรุป Validation Loss เฉลี่ย: 0.1112\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "\n",
      "--- Epoch 18/50 ---\n",
      "Batch 5000, Training Loss: 0.0200\n",
      "Batch 10000, Training Loss: 0.0808\n",
      "Batch 15000, Training Loss: 0.1372\n",
      "\n",
      "สรุป Epoch 18/50, Training Loss เฉลี่ย: 0.1154\n",
      "\n",
      "--- เริ่ม Validation ---\n",
      "Validation Batch 500, Validation Loss: 0.1988\n",
      "Validation Batch 1000, Validation Loss: 0.1200\n",
      "Validation Batch 1500, Validation Loss: 0.0689\n",
      "สรุป Validation Loss เฉลี่ย: 0.1093\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "\n",
      "--- Epoch 19/50 ---\n",
      "Batch 5000, Training Loss: 0.1671\n",
      "Batch 10000, Training Loss: 0.0676\n",
      "Batch 15000, Training Loss: 0.0125\n",
      "\n",
      "สรุป Epoch 19/50, Training Loss เฉลี่ย: 0.1155\n",
      "\n",
      "--- เริ่ม Validation ---\n",
      "Validation Batch 500, Validation Loss: 0.1614\n",
      "Validation Batch 1000, Validation Loss: 0.2751\n",
      "Validation Batch 1500, Validation Loss: 0.2382\n",
      "สรุป Validation Loss เฉลี่ย: 0.1135\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "\n",
      "--- Epoch 20/50 ---\n",
      "Batch 5000, Training Loss: 0.0704\n",
      "Batch 10000, Training Loss: 0.1031\n",
      "Batch 15000, Training Loss: 0.0807\n",
      "\n",
      "สรุป Epoch 20/50, Training Loss เฉลี่ย: 0.1152\n",
      "\n",
      "--- เริ่ม Validation ---\n",
      "Validation Batch 500, Validation Loss: 0.0282\n",
      "Validation Batch 1000, Validation Loss: 0.2373\n",
      "Validation Batch 1500, Validation Loss: 0.0573\n",
      "สรุป Validation Loss เฉลี่ย: 0.1118\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "\n",
      "--- Epoch 21/50 ---\n",
      "Batch 5000, Training Loss: 0.0843\n",
      "Batch 10000, Training Loss: 0.0866\n",
      "Batch 15000, Training Loss: 0.0852\n",
      "\n",
      "สรุป Epoch 21/50, Training Loss เฉลี่ย: 0.1134\n",
      "\n",
      "--- เริ่ม Validation ---\n",
      "Validation Batch 500, Validation Loss: 0.0574\n",
      "Validation Batch 1000, Validation Loss: 0.2640\n",
      "Validation Batch 1500, Validation Loss: 0.1193\n",
      "สรุป Validation Loss เฉลี่ย: 0.1172\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "\n",
      "--- Epoch 22/50 ---\n",
      "Batch 5000, Training Loss: 0.0117\n",
      "Batch 10000, Training Loss: 0.0593\n",
      "Batch 15000, Training Loss: 0.1330\n",
      "\n",
      "สรุป Epoch 22/50, Training Loss เฉลี่ย: 0.1124\n",
      "\n",
      "--- เริ่ม Validation ---\n",
      "Validation Batch 500, Validation Loss: 0.1208\n",
      "Validation Batch 1000, Validation Loss: 0.0684\n",
      "Validation Batch 1500, Validation Loss: 0.0991\n",
      "สรุป Validation Loss เฉลี่ย: 0.1160\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "\n",
      "--- Epoch 23/50 ---\n",
      "Batch 5000, Training Loss: 0.1131\n",
      "Batch 10000, Training Loss: 0.0334\n",
      "Batch 15000, Training Loss: 0.2072\n",
      "\n",
      "สรุป Epoch 23/50, Training Loss เฉลี่ย: 0.1125\n",
      "\n",
      "--- เริ่ม Validation ---\n",
      "Validation Batch 500, Validation Loss: 0.0716\n",
      "Validation Batch 1000, Validation Loss: 0.0431\n",
      "Validation Batch 1500, Validation Loss: 0.0727\n",
      "สรุป Validation Loss เฉลี่ย: 0.1252\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "\n",
      "--- Epoch 24/50 ---\n",
      "Batch 5000, Training Loss: 0.1850\n",
      "Batch 10000, Training Loss: 0.2156\n",
      "Batch 15000, Training Loss: 0.1096\n",
      "\n",
      "สรุป Epoch 24/50, Training Loss เฉลี่ย: 0.1112\n",
      "\n",
      "--- เริ่ม Validation ---\n",
      "Validation Batch 500, Validation Loss: 0.0679\n",
      "Validation Batch 1000, Validation Loss: 0.1721\n",
      "Validation Batch 1500, Validation Loss: 0.0870\n",
      "สรุป Validation Loss เฉลี่ย: 0.1176\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "\n",
      "--- Epoch 25/50 ---\n",
      "Batch 5000, Training Loss: 0.1571\n",
      "Batch 10000, Training Loss: 0.0739\n",
      "Batch 15000, Training Loss: 0.0911\n",
      "\n",
      "สรุป Epoch 25/50, Training Loss เฉลี่ย: 0.1103\n",
      "\n",
      "--- เริ่ม Validation ---\n",
      "Validation Batch 500, Validation Loss: 0.2632\n",
      "Validation Batch 1000, Validation Loss: 0.1427\n",
      "Validation Batch 1500, Validation Loss: 0.1370\n",
      "สรุป Validation Loss เฉลี่ย: 0.1117\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "\n",
      "--- Epoch 26/50 ---\n",
      "Batch 5000, Training Loss: 0.0388\n",
      "Batch 10000, Training Loss: 0.1390\n",
      "Batch 15000, Training Loss: 0.0807\n",
      "\n",
      "สรุป Epoch 26/50, Training Loss เฉลี่ย: 0.1103\n",
      "\n",
      "--- เริ่ม Validation ---\n",
      "Validation Batch 500, Validation Loss: 0.1222\n",
      "Validation Batch 1000, Validation Loss: 0.0730\n",
      "Validation Batch 1500, Validation Loss: 0.1379\n",
      "สรุป Validation Loss เฉลี่ย: 0.1307\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "\n",
      "--- Epoch 27/50 ---\n",
      "Batch 5000, Training Loss: 0.0695\n",
      "Batch 10000, Training Loss: 0.0561\n",
      "Batch 15000, Training Loss: 0.1803\n",
      "\n",
      "สรุป Epoch 27/50, Training Loss เฉลี่ย: 0.1112\n",
      "\n",
      "--- เริ่ม Validation ---\n",
      "Validation Batch 500, Validation Loss: 0.1997\n",
      "Validation Batch 1000, Validation Loss: 0.0637\n",
      "Validation Batch 1500, Validation Loss: 0.1840\n",
      "สรุป Validation Loss เฉลี่ย: 0.1082\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "\n",
      "--- Epoch 28/50 ---\n",
      "Batch 5000, Training Loss: 0.0888\n",
      "Batch 10000, Training Loss: 0.1157\n",
      "Batch 15000, Training Loss: 0.1394\n",
      "\n",
      "สรุป Epoch 28/50, Training Loss เฉลี่ย: 0.1103\n",
      "\n",
      "--- เริ่ม Validation ---\n",
      "Validation Batch 500, Validation Loss: 0.0138\n",
      "Validation Batch 1000, Validation Loss: 0.1266\n",
      "Validation Batch 1500, Validation Loss: 0.0000\n",
      "สรุป Validation Loss เฉลี่ย: 0.1090\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "\n",
      "--- Epoch 29/50 ---\n",
      "Batch 5000, Training Loss: 0.0996\n",
      "Batch 10000, Training Loss: 0.1254\n",
      "Batch 15000, Training Loss: 0.1473\n",
      "\n",
      "สรุป Epoch 29/50, Training Loss เฉลี่ย: 0.1097\n",
      "\n",
      "--- เริ่ม Validation ---\n",
      "Validation Batch 500, Validation Loss: 0.0991\n",
      "Validation Batch 1000, Validation Loss: 0.0731\n",
      "Validation Batch 1500, Validation Loss: 0.1385\n",
      "สรุป Validation Loss เฉลี่ย: 0.1101\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "\n",
      "--- Epoch 30/50 ---\n",
      "Batch 5000, Training Loss: 0.0236\n",
      "Batch 10000, Training Loss: 0.0322\n",
      "Batch 15000, Training Loss: 0.2845\n",
      "\n",
      "สรุป Epoch 30/50, Training Loss เฉลี่ย: 0.1092\n",
      "\n",
      "--- เริ่ม Validation ---\n",
      "Validation Batch 500, Validation Loss: 0.1565\n",
      "Validation Batch 1000, Validation Loss: 0.0663\n",
      "Validation Batch 1500, Validation Loss: 0.1442\n",
      "สรุป Validation Loss เฉลี่ย: 0.1090\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "\n",
      "--- Epoch 31/50 ---\n",
      "Batch 5000, Training Loss: 0.0000\n",
      "Batch 10000, Training Loss: 0.1029\n",
      "Batch 15000, Training Loss: 0.1383\n",
      "\n",
      "สรุป Epoch 31/50, Training Loss เฉลี่ย: 0.1097\n",
      "\n",
      "--- เริ่ม Validation ---\n",
      "Validation Batch 500, Validation Loss: 0.0760\n",
      "Validation Batch 1000, Validation Loss: 0.1482\n",
      "Validation Batch 1500, Validation Loss: 0.1327\n",
      "สรุป Validation Loss เฉลี่ย: 0.1204\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "\n",
      "--- Epoch 32/50 ---\n",
      "Batch 5000, Training Loss: 0.0254\n",
      "Batch 10000, Training Loss: 0.0616\n",
      "Batch 15000, Training Loss: 0.0666\n",
      "\n",
      "สรุป Epoch 32/50, Training Loss เฉลี่ย: 0.1077\n",
      "\n",
      "--- เริ่ม Validation ---\n",
      "Validation Batch 500, Validation Loss: 0.0191\n",
      "Validation Batch 1000, Validation Loss: 0.3538\n",
      "Validation Batch 1500, Validation Loss: 0.1075\n",
      "สรุป Validation Loss เฉลี่ย: 0.1102\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "\n",
      "--- Epoch 33/50 ---\n",
      "Batch 5000, Training Loss: 0.0799\n",
      "Batch 10000, Training Loss: 0.1131\n",
      "Batch 15000, Training Loss: 0.1502\n",
      "\n",
      "สรุป Epoch 33/50, Training Loss เฉลี่ย: 0.1088\n",
      "\n",
      "--- เริ่ม Validation ---\n",
      "Validation Batch 500, Validation Loss: 0.1742\n",
      "Validation Batch 1000, Validation Loss: 0.1531\n",
      "Validation Batch 1500, Validation Loss: 0.0520\n",
      "สรุป Validation Loss เฉลี่ย: 0.1079\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "\n",
      "--- Epoch 34/50 ---\n",
      "Batch 5000, Training Loss: 0.1424\n",
      "Batch 10000, Training Loss: 0.1190\n",
      "Batch 15000, Training Loss: 0.1273\n",
      "\n",
      "สรุป Epoch 34/50, Training Loss เฉลี่ย: 0.1071\n",
      "\n",
      "--- เริ่ม Validation ---\n",
      "Validation Batch 500, Validation Loss: 0.2628\n",
      "Validation Batch 1000, Validation Loss: 0.0138\n",
      "Validation Batch 1500, Validation Loss: 0.2253\n",
      "สรุป Validation Loss เฉลี่ย: 0.1073\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "\n",
      "--- Epoch 35/50 ---\n",
      "Batch 5000, Training Loss: 0.0000\n",
      "Batch 10000, Training Loss: 0.2375\n",
      "Batch 15000, Training Loss: 0.0019\n",
      "\n",
      "สรุป Epoch 35/50, Training Loss เฉลี่ย: 0.1078\n",
      "\n",
      "--- เริ่ม Validation ---\n",
      "Validation Batch 500, Validation Loss: 0.2093\n",
      "Validation Batch 1000, Validation Loss: 0.0842\n",
      "Validation Batch 1500, Validation Loss: 0.0847\n",
      "สรุป Validation Loss เฉลี่ย: 0.1034\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "\n",
      "--- Epoch 36/50 ---\n",
      "Batch 5000, Training Loss: 0.1119\n",
      "Batch 10000, Training Loss: 0.1236\n",
      "Batch 15000, Training Loss: 0.0629\n",
      "\n",
      "สรุป Epoch 36/50, Training Loss เฉลี่ย: 0.1061\n",
      "\n",
      "--- เริ่ม Validation ---\n",
      "Validation Batch 500, Validation Loss: 0.1403\n",
      "Validation Batch 1000, Validation Loss: 0.1645\n",
      "Validation Batch 1500, Validation Loss: 0.2973\n",
      "สรุป Validation Loss เฉลี่ย: 0.1108\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "\n",
      "--- Epoch 37/50 ---\n",
      "Batch 5000, Training Loss: 0.3856\n",
      "Batch 10000, Training Loss: 0.1263\n",
      "Batch 15000, Training Loss: 0.0558\n",
      "\n",
      "สรุป Epoch 37/50, Training Loss เฉลี่ย: 0.1071\n",
      "\n",
      "--- เริ่ม Validation ---\n",
      "Validation Batch 500, Validation Loss: 0.0687\n",
      "Validation Batch 1000, Validation Loss: 0.1047\n",
      "Validation Batch 1500, Validation Loss: 0.1372\n",
      "สรุป Validation Loss เฉลี่ย: 0.1100\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "\n",
      "--- Epoch 38/50 ---\n",
      "Batch 5000, Training Loss: 0.1668\n",
      "Batch 10000, Training Loss: 0.1363\n",
      "Batch 15000, Training Loss: 0.1278\n",
      "\n",
      "สรุป Epoch 38/50, Training Loss เฉลี่ย: 0.1063\n",
      "\n",
      "--- เริ่ม Validation ---\n",
      "Validation Batch 500, Validation Loss: 0.0306\n",
      "Validation Batch 1000, Validation Loss: 0.1341\n",
      "Validation Batch 1500, Validation Loss: 0.0746\n",
      "สรุป Validation Loss เฉลี่ย: 0.1018\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "\n",
      "--- Epoch 39/50 ---\n",
      "Batch 5000, Training Loss: 0.1349\n",
      "Batch 10000, Training Loss: 0.0207\n",
      "Batch 15000, Training Loss: 0.1384\n",
      "\n",
      "สรุป Epoch 39/50, Training Loss เฉลี่ย: 0.1050\n",
      "\n",
      "--- เริ่ม Validation ---\n",
      "Validation Batch 500, Validation Loss: 0.2255\n",
      "Validation Batch 1000, Validation Loss: 0.0553\n",
      "Validation Batch 1500, Validation Loss: 0.2822\n",
      "สรุป Validation Loss เฉลี่ย: 0.1064\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "\n",
      "--- Epoch 40/50 ---\n",
      "Batch 5000, Training Loss: 0.1072\n",
      "Batch 10000, Training Loss: 0.0687\n",
      "Batch 15000, Training Loss: 0.0948\n",
      "\n",
      "สรุป Epoch 40/50, Training Loss เฉลี่ย: 0.1053\n",
      "\n",
      "--- เริ่ม Validation ---\n",
      "Validation Batch 500, Validation Loss: 0.1281\n",
      "Validation Batch 1000, Validation Loss: 0.1559\n",
      "Validation Batch 1500, Validation Loss: 0.0180\n",
      "สรุป Validation Loss เฉลี่ย: 0.1037\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "\n",
      "--- Epoch 41/50 ---\n",
      "Batch 5000, Training Loss: 0.1995\n",
      "Batch 10000, Training Loss: 0.0653\n",
      "Batch 15000, Training Loss: 0.0452\n",
      "\n",
      "สรุป Epoch 41/50, Training Loss เฉลี่ย: 0.1051\n",
      "\n",
      "--- เริ่ม Validation ---\n",
      "Validation Batch 500, Validation Loss: 0.2641\n",
      "Validation Batch 1000, Validation Loss: 0.0569\n",
      "Validation Batch 1500, Validation Loss: 0.0012\n",
      "สรุป Validation Loss เฉลี่ย: 0.1048\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "\n",
      "--- Epoch 42/50 ---\n",
      "Batch 5000, Training Loss: 0.0379\n",
      "Batch 10000, Training Loss: 0.1104\n",
      "Batch 15000, Training Loss: 0.1303\n",
      "\n",
      "สรุป Epoch 42/50, Training Loss เฉลี่ย: 0.1042\n",
      "\n",
      "--- เริ่ม Validation ---\n",
      "Validation Batch 500, Validation Loss: 0.0000\n",
      "Validation Batch 1000, Validation Loss: 0.0929\n",
      "Validation Batch 1500, Validation Loss: 0.1260\n",
      "สรุป Validation Loss เฉลี่ย: 0.1016\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "\n",
      "--- Epoch 43/50 ---\n",
      "Batch 5000, Training Loss: 0.0303\n",
      "Batch 10000, Training Loss: 0.1469\n",
      "Batch 15000, Training Loss: 0.1640\n",
      "\n",
      "สรุป Epoch 43/50, Training Loss เฉลี่ย: 0.1039\n",
      "\n",
      "--- เริ่ม Validation ---\n",
      "Validation Batch 500, Validation Loss: 0.1892\n",
      "Validation Batch 1000, Validation Loss: 0.1013\n",
      "Validation Batch 1500, Validation Loss: 0.0464\n",
      "สรุป Validation Loss เฉลี่ย: 0.1046\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "\n",
      "--- Epoch 44/50 ---\n",
      "Batch 5000, Training Loss: 0.0749\n",
      "Batch 10000, Training Loss: 0.0870\n",
      "Batch 15000, Training Loss: 0.0531\n",
      "\n",
      "สรุป Epoch 44/50, Training Loss เฉลี่ย: 0.1043\n",
      "\n",
      "--- เริ่ม Validation ---\n",
      "Validation Batch 500, Validation Loss: 0.1688\n",
      "Validation Batch 1000, Validation Loss: 0.0162\n",
      "Validation Batch 1500, Validation Loss: 0.0273\n",
      "สรุป Validation Loss เฉลี่ย: 0.1011\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "\n",
      "--- Epoch 45/50 ---\n",
      "Batch 5000, Training Loss: 0.2242\n",
      "Batch 10000, Training Loss: 0.0995\n",
      "Batch 15000, Training Loss: 0.1339\n",
      "\n",
      "สรุป Epoch 45/50, Training Loss เฉลี่ย: 0.1045\n",
      "\n",
      "--- เริ่ม Validation ---\n",
      "Validation Batch 500, Validation Loss: 0.1265\n",
      "Validation Batch 1000, Validation Loss: 0.0636\n",
      "Validation Batch 1500, Validation Loss: 0.0805\n",
      "สรุป Validation Loss เฉลี่ย: 0.1047\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "\n",
      "--- Epoch 46/50 ---\n",
      "Batch 5000, Training Loss: 0.0080\n",
      "Batch 10000, Training Loss: 0.1741\n",
      "Batch 15000, Training Loss: 0.2157\n",
      "\n",
      "สรุป Epoch 46/50, Training Loss เฉลี่ย: 0.1047\n",
      "\n",
      "--- เริ่ม Validation ---\n",
      "Validation Batch 500, Validation Loss: 0.2074\n",
      "Validation Batch 1000, Validation Loss: 0.1444\n",
      "Validation Batch 1500, Validation Loss: 0.0045\n",
      "สรุป Validation Loss เฉลี่ย: 0.1045\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "\n",
      "--- Epoch 47/50 ---\n",
      "Batch 5000, Training Loss: 0.0692\n",
      "Batch 10000, Training Loss: 0.1886\n",
      "Batch 15000, Training Loss: 0.0910\n",
      "\n",
      "สรุป Epoch 47/50, Training Loss เฉลี่ย: 0.1033\n",
      "\n",
      "--- เริ่ม Validation ---\n",
      "Validation Batch 500, Validation Loss: 0.1255\n",
      "Validation Batch 1000, Validation Loss: 0.0744\n",
      "Validation Batch 1500, Validation Loss: 0.1180\n",
      "สรุป Validation Loss เฉลี่ย: 0.1092\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "\n",
      "--- Epoch 48/50 ---\n",
      "Batch 5000, Training Loss: 0.1688\n",
      "Batch 10000, Training Loss: 0.0370\n",
      "Batch 15000, Training Loss: 0.1756\n",
      "\n",
      "สรุป Epoch 48/50, Training Loss เฉลี่ย: 0.1037\n",
      "\n",
      "--- เริ่ม Validation ---\n",
      "Validation Batch 500, Validation Loss: 0.0860\n",
      "Validation Batch 1000, Validation Loss: 0.2470\n",
      "Validation Batch 1500, Validation Loss: 0.1963\n",
      "สรุป Validation Loss เฉลี่ย: 0.1051\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "\n",
      "--- Epoch 49/50 ---\n",
      "Batch 5000, Training Loss: 0.0000\n",
      "Batch 10000, Training Loss: 0.2840\n",
      "Batch 15000, Training Loss: 0.0676\n",
      "\n",
      "สรุป Epoch 49/50, Training Loss เฉลี่ย: 0.1034\n",
      "\n",
      "--- เริ่ม Validation ---\n",
      "Validation Batch 500, Validation Loss: 0.2512\n",
      "Validation Batch 1000, Validation Loss: 0.0592\n",
      "Validation Batch 1500, Validation Loss: 0.0512\n",
      "สรุป Validation Loss เฉลี่ย: 0.1102\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "\n",
      "--- Epoch 50/50 ---\n",
      "Batch 5000, Training Loss: 0.1203\n",
      "Batch 10000, Training Loss: 0.0325\n",
      "Batch 15000, Training Loss: 0.0424\n",
      "\n",
      "สรุป Epoch 50/50, Training Loss เฉลี่ย: 0.1041\n",
      "\n",
      "--- เริ่ม Validation ---\n",
      "Validation Batch 500, Validation Loss: 0.1992\n",
      "Validation Batch 1000, Validation Loss: 0.1384\n",
      "Validation Batch 1500, Validation Loss: 0.0601\n",
      "สรุป Validation Loss เฉลี่ย: 0.1022\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- การฝึกโมเดลเสร็จสิ้น ---\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 50\n",
    "print(\"--- เริ่มการฝึกโมเดล ---\")\n",
    "train_loss_history = []\n",
    "val_loss_history = []\n",
    "for epoch in range(EPOCHS):\n",
    "    total_loss = 0.0\n",
    "    num_batches = 0\n",
    "    \n",
    "    # วนลูปใน training dataset\n",
    "    print(f\"\\n--- Epoch {epoch+1}/{EPOCHS} ---\")\n",
    "    for anchor, positive, negative in train_dataset:\n",
    "        loss = train_step(anchor, positive, negative)\n",
    "        total_loss += loss\n",
    "        num_batches += 1\n",
    "        \n",
    "        # ปริ้นท์\n",
    "        if num_batches % 5000 == 0:\n",
    "            print(f\"Batch {num_batches}, Training Loss: {loss.numpy():.4f}\")\n",
    "    \n",
    "    avg_loss = total_loss / num_batches if num_batches > 0 else 0\n",
    "    print(f\"\\nสรุป Epoch {epoch+1}/{EPOCHS}, Training Loss เฉลี่ย: {avg_loss.numpy():.4f}\")\n",
    "    train_loss_history.append(avg_loss)\n",
    "    # Optional: ตรวจสอบ Validation Loss ในแต่ละ Epoch\n",
    "    val_total_loss = 0.0\n",
    "    val_num_batches = 0\n",
    "    \n",
    "    # วนลูปใน validation dataset\n",
    "    print(\"\\n--- เริ่ม Validation ---\")\n",
    "    for anchor, positive, negative in val_dataset:\n",
    "        anchor_embedding = model(anchor, training=False)\n",
    "        positive_embedding = model(positive, training=False)\n",
    "        negative_embedding = model(negative, training=False)\n",
    "        val_loss = triplet_loss(anchor_embedding, positive_embedding, negative_embedding)\n",
    "        val_total_loss += val_loss\n",
    "        val_num_batches += 1\n",
    "        \n",
    "        # ปริ้นท์ Val\n",
    "        if val_num_batches % 500 == 0:\n",
    "             print(f\"Validation Batch {val_num_batches}, Validation Loss: {val_loss.numpy():.4f}\")\n",
    "             \n",
    "    val_avg_loss = val_total_loss / val_num_batches if val_num_batches > 0 else 0\n",
    "    print(f\"สรุป Validation Loss เฉลี่ย: {val_avg_loss.numpy():.4f}\")\n",
    "    val_loss_history.append(val_avg_loss)\n",
    "    nameModel = f\"modelR{epoch+1}.h5\"\n",
    "    model.save(nameModel)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(range(1, EPOCHS + 1), train_loss_history, 'o-', label='Training Loss',color='red')\n",
    "plt.plot(range(1, EPOCHS + 1), val_loss_history, 'x-', label='Validation Loss',color=\"#00FF2A\")\n",
    "plt.title('Training vs. Validation Loss Over Epochs')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n--- การฝึกโมเดลเสร็จสิ้น ---\")\n",
    "model.save(\"2M.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca062932",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def hard_mining(anchor, positive, negative, alpha=0.2):\n",
    "    pos_dist = tf.reduce_sum(tf.square(anchor - positive), axis=1)\n",
    "    neg_dist = tf.reduce_sum(tf.square(anchor - negative), axis=1)\n",
    "    hardest_pos_dist = tf.reduce_max(pos_dist)\n",
    "    hardest_neg_dist = tf.reduce_min(neg_dist)\n",
    "    basic_loss = hardest_pos_dist - hardest_neg_dist + alpha\n",
    "    loss = tf.nn.relu(basic_loss)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6635dbe6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c01838d3",
   "metadata": {},
   "source": [
    "recall\n",
    "f1score\n",
    "precision\n",
    "auc\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c907545",
   "metadata": {},
   "source": [
    "ROC Curve กราฟ"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
