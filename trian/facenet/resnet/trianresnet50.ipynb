{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ee18ecb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, Model\n",
    "from tensorflow.keras.initializers import HeNormal, RandomNormal\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import cv2\n",
    "import matplotlib\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1c4d0d8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.7.1\n",
      "2.10.0\n"
     ]
    }
   ],
   "source": [
    "print(matplotlib.__version__)\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "88b5c5af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image_paths_by_class(dataset_path):\n",
    "    \n",
    "    #สร้าง dictionary \n",
    "    class_image_paths = {}\n",
    "\n",
    "    for class_name in os.listdir(dataset_path): #os.listdir ดึงรายชื่อไฟล์/โฟเดอร์ใน paht\n",
    "        class_dir = os.path.join(dataset_path, class_name)#os.path.join = images\\photo.jpg\n",
    "        #print(class_dir)\n",
    "        if os.path.isdir(class_dir):#ตรวจสอบclass_dir เป็นโฟลเดอร์ถ้าเป็นโฟลเดอร์ จะเข้าไปทำงานต่อ\n",
    "            image_files = [ \n",
    "                os.path.join(class_dir, img) #\n",
    "                for img in os.listdir(class_dir) # ดึงรายชื่อ\n",
    "                if img.lower().endswith(('.jpg', '.jpeg', '.png')) #\n",
    "            ]\n",
    "            if len(image_files) >= 20:  # ขั้นต่ำ 3 ภาพผป\n",
    "                class_image_paths[class_name] = image_files # สร้าง dictionary\n",
    "\n",
    "    return class_image_paths\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "df934d51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11023\n"
     ]
    }
   ],
   "source": [
    "#dataset_path = r'C:\\InceptionNet\\mediamdata' \n",
    "dataset_path3 = r\"D:\\InceptionNet\\GLint360K\\glint360k_3\"\n",
    "dic = load_image_paths_by_class(dataset_path3)\n",
    "print(len(dic))\n",
    "#print(dictm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e1668f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = list(dic.keys())\n",
    "#print(classes)\n",
    "#print(len(classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "167006af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "จำนวนคลาสสำหรับ Training: 8818\n",
      "จำนวนคลาสสำหรับ Validation: 2205\n"
     ]
    }
   ],
   "source": [
    "train_classes, val_classes = train_test_split(classes, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"จำนวนคลาสสำหรับ Training: {len(train_classes)}\")\n",
    "print(f\"จำนวนคลาสสำหรับ Validation: {len(val_classes)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b2971923",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ขนาดของ Dictionary สำหรับ Training: 8818\n",
      "ขนาดของ Dictionary สำหรับ Validation: 2205\n"
     ]
    }
   ],
   "source": [
    "train_image_dict1 = {\n",
    "    class_name: dic[class_name]\n",
    "    for class_name in train_classes\n",
    "}\n",
    "\n",
    "# สร้าง dictionary สำหรับ Validation\n",
    "val_image_dict1 = {\n",
    "    class_name: dic[class_name]\n",
    "    for class_name in val_classes\n",
    "}\n",
    "print(f\"ขนาดของ Dictionary สำหรับ Training: {len(train_image_dict1)}\")\n",
    "print(f\"ขนาดของ Dictionary สำหรับ Validation: {len(val_image_dict1)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9b9826d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(\"\\n--- รายชื่อคลาสสำหรับ Training ---\")\n",
    "#for class_name in train_classes:\n",
    "    #print(class_name)\n",
    "\n",
    "# ---\n",
    "# ปริ้นชื่อคลาสสำหรับ Validation\n",
    "print(\"\\n--- รายชื่อคลาสสำหรับ Validation ---\")\n",
    "for class_name in val_classes:\n",
    "    print(class_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1a463475",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadimage(image_path):\n",
    "    try:\n",
    "        img = tf.io.read_file(image_path)\n",
    "        img = tf.image.decode_jpeg(img, channels=3)\n",
    "        img = tf.image.resize(img, (224, 224))\n",
    "        img = tf.cast(img, tf.float32)\n",
    "        img = img / 255.0  # Normalization\n",
    "        img = tf.clip_by_value(img, 0.0, 1.0)#img = tf.where(tf.math.is_finite(img), img, tf.zeros_like(img)) # แทนที่ค่า NaN หรือ Inf ด้วย 0\n",
    "        img.set_shape((224, 224, 3))\n",
    "        return img\n",
    "    except:\n",
    "        print(f\"Error loading image {image_path}. Returning a zero tensor.\")\n",
    "        return tf.zeros((224, 224, 3), dtype=tf.float32)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e53ea715",
   "metadata": {},
   "source": [
    "Online Triplet Mining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4aa8f866",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "def triplet_generator(image_dict, num_triplets_per_epoch):\n",
    "    # image_dict คือ dictionary ของคุณที่ได้จากขั้นตอนที่ 1\n",
    "    # num_triplets_per_epoch คือจำนวน triplet ที่ต้องการใน 1 รอบ (epoch)\n",
    "    classes = list(image_dict.keys()) # ดึงชื่อคลาสทั้งหมด\n",
    "    for _ in range(num_triplets_per_epoch):\n",
    "        # 1. สุ่ม anchor และ positive จากคลาสเดียวกัน\n",
    "        anchor_class = random.choice(classes)\n",
    "        # ตรวจสอบว่าคลาสนั้นมีรูปภาพอย่างน้อย 2 รูป\n",
    "        if len(image_dict[anchor_class]) < 2:\n",
    "            continue\n",
    "\n",
    "        a, p = random.sample(image_dict[anchor_class], 2)\n",
    "        \n",
    "        # 2. สุ่ม negative จากคลาสอื่น\n",
    "        neg_classes = [c for c in classes if c != anchor_class]\n",
    "        if not neg_classes:\n",
    "            continue\n",
    "            \n",
    "        negative_class = random.choice(neg_classes)\n",
    "        n = random.choice(image_dict[negative_class])\n",
    "        \n",
    "        # คืนค่า (yield) Path ของรูปภาพ\n",
    "        yield (a, p, n)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d7093b3",
   "metadata": {},
   "source": [
    "Hard Negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03e4b8cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "375351c6",
   "metadata": {},
   "source": [
    "Semi-Hard Negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29c4f6e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "797e39ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def builddataset1(image_dict, num_triplets, batch_size):\n",
    "    dataset = tf.data.Dataset.from_generator(\n",
    "        lambda: triplet_generator(image_dict, num_triplets),\n",
    "        output_signature=(\n",
    "            tf.TensorSpec(shape=(), dtype=tf.string),\n",
    "            tf.TensorSpec(shape=(), dtype=tf.string),\n",
    "            tf.TensorSpec(shape=(), dtype=tf.string)\n",
    "        )\n",
    "    )\n",
    "    dataset = dataset.map(\n",
    "        lambda a, p, n: (loadimage(a), loadimage(p), loadimage(n)),\n",
    "        num_parallel_calls=tf.data.AUTOTUNE\n",
    "    )\n",
    "    dataset = dataset.batch(batch_size).prefetch(tf.data.AUTOTUNE) #เพิ่มมิติ btach\n",
    "    return dataset\n",
    "\n",
    "triple = 50000\n",
    "BATCH_SIZE = 4\n",
    "\n",
    "train_dataset = builddataset1(train_image_dict1, triple, BATCH_SIZE)\n",
    "val_dataset = builddataset1(val_image_dict1, int(triple*0.1), BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "4b40cafd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anchor batch shape: (4, 224, 224, 3)\n",
      "Positive batch shape: (4, 224, 224, 3)\n",
      "Negative batch shape: (4, 224, 224, 3)\n",
      "ลูปที่: tf.Tensor(\n",
      "[[[[0.12156863 0.14117648 0.02352941]\n",
      "   [0.12941177 0.14901961 0.03137255]\n",
      "   [0.14509805 0.16470589 0.04705882]\n",
      "   ...\n",
      "   [0.85490197 0.8509804  0.83137256]\n",
      "   [0.9254902  0.92156863 0.9019608 ]\n",
      "   [0.9607843  0.95686275 0.9372549 ]]\n",
      "\n",
      "  [[0.12745099 0.14705883 0.02941176]\n",
      "   [0.13480392 0.15441176 0.03676471]\n",
      "   [0.1495098  0.16911764 0.05147059]\n",
      "   ...\n",
      "   [0.8490196  0.845098   0.8254902 ]\n",
      "   [0.9235294  0.9196078  0.9       ]\n",
      "   [0.9607843  0.95686275 0.9372549 ]]\n",
      "\n",
      "  [[0.1392157  0.15882353 0.04117647]\n",
      "   [0.14558823 0.16519608 0.04754902]\n",
      "   [0.15833333 0.17794117 0.06029412]\n",
      "   ...\n",
      "   [0.8372549  0.8333333  0.8137255 ]\n",
      "   [0.9196078  0.91568625 0.8960784 ]\n",
      "   [0.9607843  0.95686275 0.9372549 ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.7892157  0.7852941  0.70686275]\n",
      "   [0.7742647  0.7703431  0.69191176]\n",
      "   [0.7443628  0.7404412  0.6620098 ]\n",
      "   ...\n",
      "   [0.38602942 0.24485295 0.14289215]\n",
      "   [0.3855392  0.24436274 0.14240196]\n",
      "   [0.3852941  0.24411765 0.14215687]]\n",
      "\n",
      "  [[0.8147059  0.81078434 0.7323529 ]\n",
      "   [0.8012255  0.7973039  0.71887255]\n",
      "   [0.7742647  0.7703431  0.69191176]\n",
      "   ...\n",
      "   [0.40710783 0.26593137 0.16397059]\n",
      "   [0.40955883 0.26838234 0.16642156]\n",
      "   [0.4107843  0.26960784 0.16764706]]\n",
      "\n",
      "  [[0.827451   0.8235294  0.74509805]\n",
      "   [0.8147059  0.81078434 0.7323529 ]\n",
      "   [0.7892157  0.7852941  0.70686275]\n",
      "   ...\n",
      "   [0.41764706 0.2764706  0.17450981]\n",
      "   [0.42156863 0.28039217 0.17843138]\n",
      "   [0.42352942 0.28235295 0.18039216]]]\n",
      "\n",
      "\n",
      " [[[0.6784314  0.7176471  0.7137255 ]\n",
      "   [0.6784314  0.7176471  0.7137255 ]\n",
      "   [0.6784314  0.7176471  0.7137255 ]\n",
      "   ...\n",
      "   [0.622549   0.6696078  0.65392154]\n",
      "   [0.62058824 0.66764706 0.6519608 ]\n",
      "   [0.61960787 0.6666667  0.6509804 ]]\n",
      "\n",
      "  [[0.6784314  0.7176471  0.7137255 ]\n",
      "   [0.6786765  0.71789217 0.7139706 ]\n",
      "   [0.6791667  0.71838236 0.7144608 ]\n",
      "   ...\n",
      "   [0.62328434 0.67034316 0.6546569 ]\n",
      "   [0.62083334 0.66789216 0.6522059 ]\n",
      "   [0.61960787 0.6666667  0.6509804 ]]\n",
      "\n",
      "  [[0.6784314  0.7176471  0.7137255 ]\n",
      "   [0.6791667  0.71838236 0.7144608 ]\n",
      "   [0.68063724 0.7198529  0.71593136]\n",
      "   ...\n",
      "   [0.6247549  0.6718137  0.65612745]\n",
      "   [0.6213235  0.66838235 0.6526961 ]\n",
      "   [0.61960787 0.6666667  0.6509804 ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.34019607 0.38333333 0.3970588 ]\n",
      "   [0.33210784 0.3752451  0.38897058]\n",
      "   [0.31593138 0.35906863 0.37279412]\n",
      "   ...\n",
      "   [0.17156863 0.15588236 0.11862745]\n",
      "   [0.18333334 0.16764706 0.1264706 ]\n",
      "   [0.18921569 0.17352942 0.13039216]]\n",
      "\n",
      "  [[0.40882352 0.45196077 0.4617647 ]\n",
      "   [0.40416667 0.44730392 0.45710784]\n",
      "   [0.39485294 0.4379902  0.4477941 ]\n",
      "   ...\n",
      "   [0.16764706 0.15196079 0.11470588]\n",
      "   [0.18333334 0.16764706 0.1264706 ]\n",
      "   [0.19117647 0.1754902  0.13235295]]\n",
      "\n",
      "  [[0.44313726 0.4862745  0.49411765]\n",
      "   [0.44019607 0.48333332 0.49117646]\n",
      "   [0.4343137  0.47745097 0.4852941 ]\n",
      "   ...\n",
      "   [0.16568628 0.15       0.1127451 ]\n",
      "   [0.18333334 0.16764706 0.1264706 ]\n",
      "   [0.19215687 0.1764706  0.13333334]]]\n",
      "\n",
      "\n",
      " [[[0.5372549  0.4745098  0.41568628]\n",
      "   [0.53431374 0.4715686  0.4117647 ]\n",
      "   [0.52843136 0.46568626 0.40392157]\n",
      "   ...\n",
      "   [0.22352941 0.20490196 0.21764706]\n",
      "   [0.22352941 0.20686275 0.21372549]\n",
      "   [0.22352941 0.20784314 0.21176471]]\n",
      "\n",
      "  [[0.53431374 0.47058824 0.4107843 ]\n",
      "   [0.53186274 0.46813726 0.40710783]\n",
      "   [0.5269608  0.4632353  0.3997549 ]\n",
      "   ...\n",
      "   [0.22279412 0.20490196 0.21544118]\n",
      "   [0.22328432 0.20686275 0.2129902 ]\n",
      "   [0.22352941 0.20784314 0.21176471]]\n",
      "\n",
      "  [[0.52843136 0.4627451  0.40098038]\n",
      "   [0.5269608  0.4612745  0.39779413]\n",
      "   [0.5240196  0.45833334 0.39142156]\n",
      "   ...\n",
      "   [0.22132353 0.20490196 0.21102941]\n",
      "   [0.22279412 0.20686275 0.21151961]\n",
      "   [0.22352941 0.20784314 0.21176471]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.24705882 0.13725491 0.05490196]\n",
      "   [0.25       0.13725491 0.05490196]\n",
      "   [0.25588235 0.13725491 0.05490196]\n",
      "   ...\n",
      "   [0.61691177 0.46789217 0.3230392 ]\n",
      "   [0.61740196 0.46838236 0.3240196 ]\n",
      "   [0.61764705 0.46862745 0.3245098 ]]\n",
      "\n",
      "  [[0.2784314  0.16862746 0.08627451]\n",
      "   [0.27941176 0.16666667 0.08431373]\n",
      "   [0.28137255 0.1627451  0.08039216]\n",
      "   ...\n",
      "   [0.61151963 0.4625     0.31813726]\n",
      "   [0.6129902  0.4639706  0.32107842]\n",
      "   [0.6137255  0.46470588 0.32254902]]\n",
      "\n",
      "  [[0.29411766 0.18431373 0.10196079]\n",
      "   [0.29411766 0.18137255 0.09901961]\n",
      "   [0.29411766 0.1754902  0.09313726]\n",
      "   ...\n",
      "   [0.60882354 0.4598039  0.3156863 ]\n",
      "   [0.6107843  0.4617647  0.31960785]\n",
      "   [0.6117647  0.4627451  0.32156864]]]\n",
      "\n",
      "\n",
      " [[[0.3137255  0.29411766 0.2784314 ]\n",
      "   [0.2990196  0.27941176 0.2637255 ]\n",
      "   [0.26960784 0.25       0.23431373]\n",
      "   ...\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]]\n",
      "\n",
      "  [[0.30686274 0.2872549  0.27156863]\n",
      "   [0.29264706 0.27303922 0.25735295]\n",
      "   [0.26421568 0.24460784 0.22892156]\n",
      "   ...\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]]\n",
      "\n",
      "  [[0.29313725 0.2735294  0.25784314]\n",
      "   [0.27990195 0.2602941  0.24460784]\n",
      "   [0.25343138 0.23382352 0.21813725]\n",
      "   ...\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.5745098  0.5156863  0.50392157]\n",
      "   [0.59460783 0.532598   0.5147059 ]\n",
      "   [0.63480395 0.56642157 0.5362745 ]\n",
      "   ...\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]]\n",
      "\n",
      "  [[0.5862745  0.527451   0.5156863 ]\n",
      "   [0.60539216 0.54289216 0.5264706 ]\n",
      "   [0.64362746 0.5737745  0.5480392 ]\n",
      "   ...\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]]\n",
      "\n",
      "  [[0.5921569  0.53333336 0.52156866]\n",
      "   [0.6107843  0.5480392  0.5323529 ]\n",
      "   [0.6480392  0.577451   0.5539216 ]\n",
      "   ...\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]]]], shape=(4, 224, 224, 3), dtype=float32)\n",
      "ลูปที่: 0\n",
      "Anchor batch shape: (4, 224, 224, 3)\n",
      "Positive batch shape: (4, 224, 224, 3)\n",
      "Negative batch shape: (4, 224, 224, 3)\n",
      "ลูปที่: tf.Tensor(\n",
      "[[[[0.         0.00392157 0.        ]\n",
      "   [0.         0.00392157 0.        ]\n",
      "   [0.         0.00392157 0.        ]\n",
      "   ...\n",
      "   [0.30490196 0.30490196 0.3127451 ]\n",
      "   [0.29509804 0.29509804 0.30294117]\n",
      "   [0.2901961  0.2901961  0.29803923]]\n",
      "\n",
      "  [[0.         0.00392157 0.        ]\n",
      "   [0.         0.00392157 0.        ]\n",
      "   [0.         0.00392157 0.        ]\n",
      "   ...\n",
      "   [0.30686274 0.30686274 0.31470588]\n",
      "   [0.29705882 0.29705882 0.30490196]\n",
      "   [0.29215688 0.29215688 0.3       ]]\n",
      "\n",
      "  [[0.         0.00392157 0.        ]\n",
      "   [0.         0.00392157 0.        ]\n",
      "   [0.         0.00392157 0.        ]\n",
      "   ...\n",
      "   [0.3107843  0.3107843  0.31862745]\n",
      "   [0.3009804  0.3009804  0.30882353]\n",
      "   [0.29607844 0.29607844 0.30392158]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.3509804  0.28431374 0.32352942]\n",
      "   [0.34901962 0.28235295 0.32009804]\n",
      "   [0.34509805 0.2784314  0.31323528]\n",
      "   ...\n",
      "   [0.63480395 0.5504902  0.47696078]\n",
      "   [0.6397059  0.55539215 0.48186275]\n",
      "   [0.64215684 0.55784315 0.48431373]]\n",
      "\n",
      "  [[0.34705883 0.28039217 0.31960785]\n",
      "   [0.34509805 0.2784314  0.31715685]\n",
      "   [0.34117648 0.27450982 0.3122549 ]\n",
      "   ...\n",
      "   [0.6514706  0.5632353  0.49166667]\n",
      "   [0.6544118  0.5661765  0.49460784]\n",
      "   [0.65588236 0.56764704 0.49607843]]\n",
      "\n",
      "  [[0.34509805 0.2784314  0.31764707]\n",
      "   [0.34313726 0.2764706  0.3156863 ]\n",
      "   [0.3392157  0.27254903 0.31176472]\n",
      "   ...\n",
      "   [0.6598039  0.56960785 0.4990196 ]\n",
      "   [0.6617647  0.5715686  0.5009804 ]\n",
      "   [0.6627451  0.57254905 0.5019608 ]]]\n",
      "\n",
      "\n",
      " [[[0.44313726 0.5019608  0.52156866]\n",
      "   [0.44411764 0.5029412  0.52254903]\n",
      "   [0.44607842 0.50490195 0.5245098 ]\n",
      "   ...\n",
      "   [0.1382353  0.20490196 0.23627451]\n",
      "   [0.14019608 0.20686275 0.2382353 ]\n",
      "   [0.14117648 0.20784314 0.23921569]]\n",
      "\n",
      "  [[0.44313726 0.5019608  0.52156866]\n",
      "   [0.44411764 0.5029412  0.52254903]\n",
      "   [0.44607842 0.50490195 0.5245098 ]\n",
      "   ...\n",
      "   [0.14019608 0.20490196 0.23529412]\n",
      "   [0.14215687 0.20686275 0.2372549 ]\n",
      "   [0.14313726 0.20784314 0.2382353 ]]\n",
      "\n",
      "  [[0.44313726 0.5019608  0.52156866]\n",
      "   [0.44411764 0.5029412  0.52254903]\n",
      "   [0.44607842 0.50490195 0.5245098 ]\n",
      "   ...\n",
      "   [0.14411765 0.20490196 0.23333333]\n",
      "   [0.14607844 0.20686275 0.23529412]\n",
      "   [0.14705883 0.20784314 0.23627451]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.13235295 0.14803922 0.15196079]\n",
      "   [0.1264706  0.14215687 0.14607844]\n",
      "   [0.11470588 0.13039216 0.13431373]\n",
      "   ...\n",
      "   [0.2752451  0.28308824 0.2757353 ]\n",
      "   [0.18848039 0.19632353 0.1860294 ]\n",
      "   [0.14509805 0.15294118 0.14117648]]\n",
      "\n",
      "  [[0.13039216 0.14607844 0.15      ]\n",
      "   [0.1245098  0.14019608 0.14411765]\n",
      "   [0.1127451  0.12843138 0.13235295]\n",
      "   ...\n",
      "   [0.25710785 0.264951   0.25465685]\n",
      "   [0.17720588 0.18504901 0.17377451]\n",
      "   [0.13725491 0.14509805 0.13333334]]\n",
      "\n",
      "  [[0.12941177 0.14509805 0.14901961]\n",
      "   [0.12352941 0.1392157  0.14313726]\n",
      "   [0.11176471 0.12745099 0.13137256]\n",
      "   ...\n",
      "   [0.24803922 0.25588235 0.24411765]\n",
      "   [0.17156863 0.17941177 0.16764706]\n",
      "   [0.13333334 0.14117648 0.12941177]]]\n",
      "\n",
      "\n",
      " [[[0.6509804  0.5176471  0.36862746]\n",
      "   [0.6666667  0.53333336 0.38431373]\n",
      "   [0.69803923 0.5647059  0.41568628]\n",
      "   ...\n",
      "   [0.21078432 0.13235295 0.10490196]\n",
      "   [0.20882353 0.13039216 0.10294118]\n",
      "   [0.20784314 0.12941177 0.10196079]]\n",
      "\n",
      "  [[0.6617647  0.52843136 0.37941176]\n",
      "   [0.6745098  0.5411765  0.39215687]\n",
      "   [0.7        0.56666666 0.41764706]\n",
      "   ...\n",
      "   [0.21078432 0.13235295 0.10490196]\n",
      "   [0.20882353 0.13039216 0.10294118]\n",
      "   [0.20784314 0.12941177 0.10196079]]\n",
      "\n",
      "  [[0.68333334 0.55       0.40098038]\n",
      "   [0.6901961  0.5568628  0.40784314]\n",
      "   [0.70392156 0.57058823 0.42156863]\n",
      "   ...\n",
      "   [0.21078432 0.13235295 0.10490196]\n",
      "   [0.20882353 0.13039216 0.10294118]\n",
      "   [0.20784314 0.12941177 0.10196079]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.5764706  0.44313726 0.30588236]\n",
      "   [0.58112746 0.4477941  0.30857843]\n",
      "   [0.59044117 0.45710784 0.3139706 ]\n",
      "   ...\n",
      "   [0.48088235 0.26666668 0.11299019]\n",
      "   [0.49754903 0.28627452 0.13112745]\n",
      "   [0.5058824  0.29607844 0.14019608]]\n",
      "\n",
      "  [[0.5686275  0.43529412 0.29803923]\n",
      "   [0.5747549  0.44142157 0.3022059 ]\n",
      "   [0.5870098  0.45367646 0.31053922]\n",
      "   ...\n",
      "   [0.49362746 0.2784314  0.1252451 ]\n",
      "   [0.5122549  0.29803923 0.14436275]\n",
      "   [0.52156866 0.30784315 0.15392157]]\n",
      "\n",
      "  [[0.5647059  0.43137255 0.29411766]\n",
      "   [0.5715686  0.43823528 0.2990196 ]\n",
      "   [0.5852941  0.45196077 0.30882353]\n",
      "   ...\n",
      "   [0.5        0.28431374 0.13137256]\n",
      "   [0.51960784 0.30392158 0.1509804 ]\n",
      "   [0.5294118  0.3137255  0.16078432]]]\n",
      "\n",
      "\n",
      " [[[0.6392157  0.68235296 0.76862746]\n",
      "   [0.63529414 0.6784314  0.7627451 ]\n",
      "   [0.627451   0.67058825 0.7509804 ]\n",
      "   ...\n",
      "   [0.62647057 0.65       0.70490193]\n",
      "   [0.6245098  0.6480392  0.7029412 ]\n",
      "   [0.62352943 0.64705884 0.7019608 ]]\n",
      "\n",
      "  [[0.6401961  0.68333334 0.76960784]\n",
      "   [0.6377451  0.68088233 0.7651961 ]\n",
      "   [0.63284314 0.6759804  0.7563726 ]\n",
      "   ...\n",
      "   [0.62647057 0.65       0.70490193]\n",
      "   [0.6245098  0.6480392  0.7029412 ]\n",
      "   [0.62352943 0.64705884 0.7019608 ]]\n",
      "\n",
      "  [[0.64215684 0.6852941  0.77156866]\n",
      "   [0.6426471  0.68578434 0.77009803]\n",
      "   [0.64362746 0.6867647  0.76715684]\n",
      "   ...\n",
      "   [0.62647057 0.65       0.70490193]\n",
      "   [0.6245098  0.6480392  0.7029412 ]\n",
      "   [0.62352943 0.64705884 0.7019608 ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.6598039  0.69509804 0.73039216]\n",
      "   [0.65931374 0.6931372  0.7291667 ]\n",
      "   [0.65833336 0.68921566 0.7267157 ]\n",
      "   ...\n",
      "   [0.60539216 0.63284314 0.6642157 ]\n",
      "   [0.6044118  0.63186276 0.6632353 ]\n",
      "   [0.6039216  0.6313726  0.6627451 ]]\n",
      "\n",
      "  [[0.6617647  0.6970588  0.7323529 ]\n",
      "   [0.6602941  0.69509804 0.73063725]\n",
      "   [0.6573529  0.6911765  0.7272059 ]\n",
      "   ...\n",
      "   [0.60245097 0.62990195 0.6612745 ]\n",
      "   [0.60343134 0.6308824  0.6622549 ]\n",
      "   [0.6039216  0.6313726  0.6627451 ]]\n",
      "\n",
      "  [[0.6627451  0.69803923 0.73333335]\n",
      "   [0.6607843  0.6960784  0.73137254]\n",
      "   [0.65686274 0.69215685 0.72745097]\n",
      "   ...\n",
      "   [0.6009804  0.6284314  0.6598039 ]\n",
      "   [0.60294116 0.63039213 0.6617647 ]\n",
      "   [0.6039216  0.6313726  0.6627451 ]]]], shape=(4, 224, 224, 3), dtype=float32)\n",
      "ลูปที่: 0\n",
      "Anchor batch shape: (4, 224, 224, 3)\n",
      "Positive batch shape: (4, 224, 224, 3)\n",
      "Negative batch shape: (4, 224, 224, 3)\n",
      "ลูปที่: tf.Tensor(\n",
      "[[[[0.32941177 0.2627451  0.28627452]\n",
      "   [0.32843137 0.2617647  0.28529412]\n",
      "   [0.32647058 0.25980392 0.28333333]\n",
      "   ...\n",
      "   [0.44019607 0.30686274 0.2990196 ]\n",
      "   [0.4343137  0.3009804  0.29313725]\n",
      "   [0.43137255 0.29803923 0.2901961 ]]\n",
      "\n",
      "  [[0.33333334 0.26666668 0.2901961 ]\n",
      "   [0.33210784 0.26544118 0.2889706 ]\n",
      "   [0.32965687 0.2629902  0.28651962]\n",
      "   ...\n",
      "   [0.44215685 0.30882353 0.3009804 ]\n",
      "   [0.4362745  0.30294117 0.29509804]\n",
      "   [0.43333334 0.3        0.29215688]]\n",
      "\n",
      "  [[0.34117648 0.27450982 0.29803923]\n",
      "   [0.3394608  0.27279413 0.29632354]\n",
      "   [0.3360294  0.26936275 0.29289216]\n",
      "   ...\n",
      "   [0.44607842 0.3127451  0.30490196]\n",
      "   [0.44019607 0.30686274 0.2990196 ]\n",
      "   [0.4372549  0.30392158 0.29607844]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.5156863  0.42941177 0.44117647]\n",
      "   [0.5125     0.42769608 0.4387255 ]\n",
      "   [0.5061275  0.4242647  0.43382353]\n",
      "   ...\n",
      "   [0.6112745  0.38382354 0.32941177]\n",
      "   [0.6044118  0.37696078 0.32352942]\n",
      "   [0.6009804  0.3735294  0.32058823]]\n",
      "\n",
      "  [[0.51960784 0.43333334 0.44509804]\n",
      "   [0.51593137 0.43014705 0.44166666]\n",
      "   [0.5085784  0.4237745  0.43480393]\n",
      "   ...\n",
      "   [0.6102941  0.38284314 0.32941177]\n",
      "   [0.60539216 0.3779412  0.327451  ]\n",
      "   [0.60294116 0.3754902  0.32647058]]\n",
      "\n",
      "  [[0.52156866 0.43529412 0.44705883]\n",
      "   [0.5176471  0.43137255 0.44313726]\n",
      "   [0.50980395 0.42352942 0.43529412]\n",
      "   ...\n",
      "   [0.6098039  0.38235295 0.32941177]\n",
      "   [0.60588235 0.37843138 0.32941177]\n",
      "   [0.6039216  0.3764706  0.32941177]]]\n",
      "\n",
      "\n",
      " [[[0.07843138 0.07843138 0.07843138]\n",
      "   [0.07941177 0.07941177 0.07941177]\n",
      "   [0.08137255 0.08137255 0.08137255]\n",
      "   ...\n",
      "   [0.04901961 0.04901961 0.04901961]\n",
      "   [0.05294118 0.05294118 0.05294118]\n",
      "   [0.05490196 0.05490196 0.05490196]]\n",
      "\n",
      "  [[0.08039216 0.08039216 0.08039216]\n",
      "   [0.08088236 0.08088236 0.08088236]\n",
      "   [0.08186275 0.08186275 0.08186275]\n",
      "   ...\n",
      "   [0.04926471 0.04926471 0.04926471]\n",
      "   [0.05367647 0.05367647 0.05367647]\n",
      "   [0.05588235 0.05588235 0.05588235]]\n",
      "\n",
      "  [[0.08431373 0.08431373 0.08431373]\n",
      "   [0.08382353 0.08382353 0.08382353]\n",
      "   [0.08284314 0.08284314 0.08284314]\n",
      "   ...\n",
      "   [0.0497549  0.0497549  0.0497549 ]\n",
      "   [0.05514706 0.05514706 0.05514706]\n",
      "   [0.05784314 0.05784314 0.05784314]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.07450981 0.07450981 0.07450981]\n",
      "   [0.07450981 0.07450981 0.07450981]\n",
      "   [0.07450981 0.07450981 0.07450981]\n",
      "   ...\n",
      "   [0.24656862 0.24656862 0.24656862]\n",
      "   [0.22205882 0.22205882 0.22205882]\n",
      "   [0.20980392 0.20980392 0.20980392]]\n",
      "\n",
      "  [[0.07450981 0.07450981 0.07450981]\n",
      "   [0.07450981 0.07450981 0.07450981]\n",
      "   [0.07450981 0.07450981 0.07450981]\n",
      "   ...\n",
      "   [0.23970588 0.23970588 0.23970588]\n",
      "   [0.21715686 0.21715686 0.21715686]\n",
      "   [0.20588236 0.20588236 0.20588236]]\n",
      "\n",
      "  [[0.07450981 0.07450981 0.07450981]\n",
      "   [0.07450981 0.07450981 0.07450981]\n",
      "   [0.07450981 0.07450981 0.07450981]\n",
      "   ...\n",
      "   [0.23627451 0.23627451 0.23627451]\n",
      "   [0.21470588 0.21470588 0.21470588]\n",
      "   [0.20392157 0.20392157 0.20392157]]]\n",
      "\n",
      "\n",
      " [[[0.         0.00392157 0.        ]\n",
      "   [0.         0.00392157 0.        ]\n",
      "   [0.         0.00392157 0.        ]\n",
      "   ...\n",
      "   [0.15980393 0.10882353 0.04607843]\n",
      "   [0.15784314 0.10686275 0.04411765]\n",
      "   [0.15686275 0.10588235 0.04313726]]\n",
      "\n",
      "  [[0.         0.00392157 0.        ]\n",
      "   [0.         0.00392157 0.        ]\n",
      "   [0.         0.00392157 0.        ]\n",
      "   ...\n",
      "   [0.1637255  0.1127451  0.05      ]\n",
      "   [0.15980393 0.10882353 0.04607843]\n",
      "   [0.15784314 0.10686275 0.04411765]]\n",
      "\n",
      "  [[0.         0.00392157 0.        ]\n",
      "   [0.         0.00392157 0.        ]\n",
      "   [0.         0.00392157 0.        ]\n",
      "   ...\n",
      "   [0.17156863 0.12058824 0.05784314]\n",
      "   [0.1637255  0.1127451  0.05      ]\n",
      "   [0.15980393 0.10882353 0.04607843]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.16568628 0.15       0.14607844]\n",
      "   [0.16642156 0.15073529 0.14681372]\n",
      "   [0.16789216 0.15220588 0.14828432]\n",
      "   ...\n",
      "   [0.9637255  0.6911765  0.5686275 ]\n",
      "   [0.95392156 0.67745095 0.5529412 ]\n",
      "   [0.9490196  0.67058825 0.54509807]]\n",
      "\n",
      "  [[0.16764706 0.15196079 0.14803922]\n",
      "   [0.16789216 0.15220588 0.14828432]\n",
      "   [0.16838235 0.15269607 0.1487745 ]\n",
      "   ...\n",
      "   [0.9637255  0.6911765  0.5686275 ]\n",
      "   [0.95392156 0.67745095 0.5529412 ]\n",
      "   [0.9490196  0.67058825 0.54509807]]\n",
      "\n",
      "  [[0.16862746 0.15294118 0.14901961]\n",
      "   [0.16862746 0.15294118 0.14901961]\n",
      "   [0.16862746 0.15294118 0.14901961]\n",
      "   ...\n",
      "   [0.9637255  0.6911765  0.5686275 ]\n",
      "   [0.95392156 0.67745095 0.5529412 ]\n",
      "   [0.9490196  0.67058825 0.54509807]]]\n",
      "\n",
      "\n",
      " [[[0.6117647  0.6        0.47058824]\n",
      "   [0.6156863  0.6039216  0.4745098 ]\n",
      "   [0.62352943 0.6117647  0.48235294]\n",
      "   ...\n",
      "   [0.3382353  0.3480392  0.3382353 ]\n",
      "   [0.36372548 0.37745097 0.37156862]\n",
      "   [0.3764706  0.39215687 0.3882353 ]]\n",
      "\n",
      "  [[0.6107843  0.5990196  0.46764705]\n",
      "   [0.61519605 0.60343134 0.47205883]\n",
      "   [0.6240196  0.6122549  0.48088235]\n",
      "   ...\n",
      "   [0.32107842 0.32965687 0.31789216]\n",
      "   [0.3514706  0.3634804  0.35563725]\n",
      "   [0.36666667 0.38039216 0.3745098 ]]\n",
      "\n",
      "  [[0.60882354 0.59705883 0.4617647 ]\n",
      "   [0.6142157  0.60245097 0.46715686]\n",
      "   [0.625      0.6132353  0.4779412 ]\n",
      "   ...\n",
      "   [0.2867647  0.29289216 0.27720588]\n",
      "   [0.32696077 0.33553922 0.32377452]\n",
      "   [0.34705883 0.35686275 0.34705883]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.32941177 0.32156864 0.09803922]\n",
      "   [0.32941177 0.32156864 0.09803922]\n",
      "   [0.32941177 0.32156864 0.09803922]\n",
      "   ...\n",
      "   [0.28995097 0.3134804  0.30367646]\n",
      "   [0.31495097 0.33848038 0.3247549 ]\n",
      "   [0.327451   0.3509804  0.33529413]]\n",
      "\n",
      "  [[0.32941177 0.32156864 0.09803922]\n",
      "   [0.32941177 0.32156864 0.09803922]\n",
      "   [0.32941177 0.32156864 0.09803922]\n",
      "   ...\n",
      "   [0.29534313 0.31887254 0.30906862]\n",
      "   [0.31936276 0.34289217 0.32916668]\n",
      "   [0.33137256 0.35490197 0.3392157 ]]\n",
      "\n",
      "  [[0.32941177 0.32156864 0.09803922]\n",
      "   [0.32941177 0.32156864 0.09803922]\n",
      "   [0.32941177 0.32156864 0.09803922]\n",
      "   ...\n",
      "   [0.29803923 0.32156864 0.31176472]\n",
      "   [0.32156864 0.34509805 0.33137256]\n",
      "   [0.33333334 0.35686275 0.34117648]]]], shape=(4, 224, 224, 3), dtype=float32)\n",
      "ลูปที่: 0\n",
      "Anchor batch shape: (4, 224, 224, 3)\n",
      "Positive batch shape: (4, 224, 224, 3)\n",
      "Negative batch shape: (4, 224, 224, 3)\n",
      "ลูปที่: tf.Tensor(\n",
      "[[[[0.22745098 0.27450982 0.23529412]\n",
      "   [0.22647059 0.2735294  0.23431373]\n",
      "   [0.2245098  0.27156863 0.23235294]\n",
      "   ...\n",
      "   [0.20392157 0.26666668 0.21568628]\n",
      "   [0.20392157 0.26666668 0.21568628]\n",
      "   [0.20392157 0.26666668 0.21568628]]\n",
      "\n",
      "  [[0.22745098 0.27450982 0.23529412]\n",
      "   [0.22671568 0.2737745  0.23455882]\n",
      "   [0.2252451  0.2723039  0.23308824]\n",
      "   ...\n",
      "   [0.20318627 0.26593137 0.21495098]\n",
      "   [0.20367648 0.26642156 0.21544118]\n",
      "   [0.20392157 0.26666668 0.21568628]]\n",
      "\n",
      "  [[0.22745098 0.27450982 0.23529412]\n",
      "   [0.22720589 0.2742647  0.23504902]\n",
      "   [0.22671568 0.2737745  0.23455882]\n",
      "   ...\n",
      "   [0.2017157  0.26446077 0.2134804 ]\n",
      "   [0.20318627 0.26593137 0.21495098]\n",
      "   [0.20392157 0.26666668 0.21568628]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.5901961  0.5686275  0.54509807]\n",
      "   [0.5990196  0.577451   0.5539216 ]\n",
      "   [0.6166667  0.595098   0.5715686 ]\n",
      "   ...\n",
      "   [0.3095588  0.264951   0.25588235]\n",
      "   [0.3110294  0.26936275 0.25980392]\n",
      "   [0.31176472 0.27156863 0.2617647 ]]\n",
      "\n",
      "  [[0.5235294  0.49803922 0.4745098 ]\n",
      "   [0.5323529  0.50686276 0.48333332]\n",
      "   [0.55       0.5245098  0.5009804 ]\n",
      "   ...\n",
      "   [0.30710784 0.25759804 0.24607843]\n",
      "   [0.30759802 0.2629902  0.25      ]\n",
      "   [0.30784315 0.26568627 0.25196078]]\n",
      "\n",
      "  [[0.49019608 0.4627451  0.4392157 ]\n",
      "   [0.4990196  0.4715686  0.4480392 ]\n",
      "   [0.51666665 0.48921567 0.46568626]\n",
      "   ...\n",
      "   [0.30588236 0.25392157 0.24117647]\n",
      "   [0.30588236 0.25980392 0.24509804]\n",
      "   [0.30588236 0.2627451  0.24705882]]]\n",
      "\n",
      "\n",
      " [[[0.11372549 0.18039216 0.14901961]\n",
      "   [0.11372549 0.18039216 0.14901961]\n",
      "   [0.11372549 0.18039216 0.14901961]\n",
      "   ...\n",
      "   [0.55588233 0.60294116 0.595098  ]\n",
      "   [0.6637255  0.7107843  0.7029412 ]\n",
      "   [0.7176471  0.7647059  0.75686276]]\n",
      "\n",
      "  [[0.11764706 0.18431373 0.15294118]\n",
      "   [0.11911765 0.18578431 0.15441176]\n",
      "   [0.12205882 0.18872549 0.15735294]\n",
      "   ...\n",
      "   [0.5502451  0.5973039  0.5894608 ]\n",
      "   [0.65857846 0.7056373  0.69779414]\n",
      "   [0.7127451  0.75980395 0.7519608 ]]\n",
      "\n",
      "  [[0.1254902  0.19215687 0.16078432]\n",
      "   [0.12990196 0.19656862 0.16519608]\n",
      "   [0.13872549 0.20539215 0.1740196 ]\n",
      "   ...\n",
      "   [0.5389706  0.5860294  0.5781863 ]\n",
      "   [0.6482843  0.69534314 0.6875    ]\n",
      "   [0.7029412  0.75       0.74215686]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.57843137 0.6509804  0.32058823]\n",
      "   [0.5767157  0.6507353  0.31911764]\n",
      "   [0.5732843  0.6502451  0.31617647]\n",
      "   ...\n",
      "   [0.5448529  0.5997549  0.47034314]\n",
      "   [0.54044116 0.5953431  0.4659314 ]\n",
      "   [0.5382353  0.59313726 0.46372548]]\n",
      "\n",
      "  [[0.58235294 0.65882355 0.32647058]\n",
      "   [0.57916665 0.65612745 0.32205883]\n",
      "   [0.57279414 0.6507353  0.31323528]\n",
      "   ...\n",
      "   [0.55808824 0.6129902  0.48357844]\n",
      "   [0.5566176  0.61151963 0.48210785]\n",
      "   [0.55588233 0.6107843  0.48137254]]\n",
      "\n",
      "  [[0.58431375 0.6627451  0.32941177]\n",
      "   [0.5803922  0.65882355 0.32352942]\n",
      "   [0.57254905 0.6509804  0.31176472]\n",
      "   ...\n",
      "   [0.5647059  0.61960787 0.49019608]\n",
      "   [0.5647059  0.61960787 0.49019608]\n",
      "   [0.5647059  0.61960787 0.49019608]]]\n",
      "\n",
      "\n",
      " [[[0.7254902  0.6666667  0.54509807]\n",
      "   [0.74509805 0.6862745  0.5647059 ]\n",
      "   [0.78431374 0.7254902  0.6039216 ]\n",
      "   ...\n",
      "   [0.5352941  0.5588235  0.37254903]\n",
      "   [0.6254902  0.6490196  0.46666667]\n",
      "   [0.67058825 0.69411767 0.5137255 ]]\n",
      "\n",
      "  [[0.7411765  0.68235296 0.56078434]\n",
      "   [0.75661767 0.69779414 0.5762255 ]\n",
      "   [0.7875     0.7286765  0.6071078 ]\n",
      "   ...\n",
      "   [0.5247549  0.5509804  0.35980392]\n",
      "   [0.6036765  0.62941176 0.44215685]\n",
      "   [0.6431373  0.66862744 0.48333332]]\n",
      "\n",
      "  [[0.77254903 0.7137255  0.5921569 ]\n",
      "   [0.7796569  0.72083336 0.5992647 ]\n",
      "   [0.79387254 0.735049   0.6134804 ]\n",
      "   ...\n",
      "   [0.5036765  0.5352941  0.33431372]\n",
      "   [0.560049   0.5901961  0.39313725]\n",
      "   [0.5882353  0.61764705 0.422549  ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.19705883 0.15       0.0872549 ]\n",
      "   [0.19607843 0.14901961 0.0882353 ]\n",
      "   [0.19411765 0.14705883 0.09019608]\n",
      "   ...\n",
      "   [0.19240196 0.17279412 0.09828431]\n",
      "   [0.19877452 0.17916666 0.10465686]\n",
      "   [0.20196079 0.18235295 0.10784314]]\n",
      "\n",
      "  [[0.19901961 0.15196079 0.08921569]\n",
      "   [0.19803922 0.1509804  0.09019608]\n",
      "   [0.19607843 0.14901961 0.09215686]\n",
      "   ...\n",
      "   [0.19485295 0.17524509 0.10073529]\n",
      "   [0.20220588 0.18259804 0.10808823]\n",
      "   [0.20588236 0.18627451 0.11176471]]\n",
      "\n",
      "  [[0.2        0.15294118 0.09019608]\n",
      "   [0.19901961 0.15196079 0.09117647]\n",
      "   [0.19705883 0.15       0.09313726]\n",
      "   ...\n",
      "   [0.19607843 0.1764706  0.10196079]\n",
      "   [0.20392157 0.18431373 0.10980392]\n",
      "   [0.20784314 0.1882353  0.11372549]]]\n",
      "\n",
      "\n",
      " [[[0.33333334 0.34509805 0.52156866]\n",
      "   [0.33137256 0.34313726 0.51960784]\n",
      "   [0.327451   0.3392157  0.5156863 ]\n",
      "   ...\n",
      "   [0.70686275 0.70686275 0.7147059 ]\n",
      "   [0.70098037 0.70098037 0.7088235 ]\n",
      "   [0.69803923 0.69803923 0.7058824 ]]\n",
      "\n",
      "  [[0.33333334 0.34509805 0.52156866]\n",
      "   [0.33137256 0.34313726 0.51960784]\n",
      "   [0.327451   0.3392157  0.5156863 ]\n",
      "   ...\n",
      "   [0.70686275 0.70686275 0.7147059 ]\n",
      "   [0.70098037 0.70098037 0.7088235 ]\n",
      "   [0.69803923 0.69803923 0.7058824 ]]\n",
      "\n",
      "  [[0.33333334 0.34509805 0.52156866]\n",
      "   [0.33137256 0.34313726 0.51960784]\n",
      "   [0.327451   0.3392157  0.5156863 ]\n",
      "   ...\n",
      "   [0.70686275 0.70686275 0.7147059 ]\n",
      "   [0.70098037 0.70098037 0.7088235 ]\n",
      "   [0.69803923 0.69803923 0.7058824 ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.49509802 0.55784315 0.6872549 ]\n",
      "   [0.49607843 0.5588235  0.6882353 ]\n",
      "   [0.49803922 0.56078434 0.6901961 ]\n",
      "   ...\n",
      "   [0.39803922 0.32941177 0.2990196 ]\n",
      "   [0.40392157 0.33137256 0.30294117]\n",
      "   [0.40686274 0.33235294 0.30490196]]\n",
      "\n",
      "  [[0.48921567 0.55196077 0.6813725 ]\n",
      "   [0.49019608 0.5529412  0.68235296]\n",
      "   [0.49215686 0.55490196 0.6843137 ]\n",
      "   ...\n",
      "   [0.39607844 0.327451   0.29705882]\n",
      "   [0.4019608  0.32941177 0.3009804 ]\n",
      "   [0.40490195 0.33039215 0.30294117]]\n",
      "\n",
      "  [[0.4862745  0.54901963 0.6784314 ]\n",
      "   [0.4872549  0.55       0.67941177]\n",
      "   [0.48921567 0.55196077 0.6813725 ]\n",
      "   ...\n",
      "   [0.39509803 0.32647058 0.29607844]\n",
      "   [0.40098038 0.32843137 0.3       ]\n",
      "   [0.40392157 0.32941177 0.3019608 ]]]], shape=(4, 224, 224, 3), dtype=float32)\n",
      "ลูปที่: 0\n",
      "Anchor batch shape: (4, 224, 224, 3)\n",
      "Positive batch shape: (4, 224, 224, 3)\n",
      "Negative batch shape: (4, 224, 224, 3)\n",
      "ลูปที่: tf.Tensor(\n",
      "[[[[0.24313726 0.24313726 0.2509804 ]\n",
      "   [0.23921569 0.23921569 0.24705882]\n",
      "   [0.23137255 0.23137255 0.23921569]\n",
      "   ...\n",
      "   [0.28627452 0.2509804  0.27058825]\n",
      "   [0.28627452 0.2509804  0.27058825]\n",
      "   [0.28627452 0.2509804  0.27058825]]\n",
      "\n",
      "  [[0.24117647 0.24117647 0.24901961]\n",
      "   [0.2365196  0.2365196  0.24436274]\n",
      "   [0.22720589 0.22720589 0.23504902]\n",
      "   ...\n",
      "   [0.2857843  0.25269607 0.26960784]\n",
      "   [0.2867647  0.25220588 0.26960784]\n",
      "   [0.2872549  0.25196078 0.26960784]]\n",
      "\n",
      "  [[0.2372549  0.2372549  0.24509804]\n",
      "   [0.23112746 0.23112746 0.2389706 ]\n",
      "   [0.21887255 0.21887255 0.22671568]\n",
      "   ...\n",
      "   [0.28480393 0.25612745 0.26764706]\n",
      "   [0.2877451  0.25465685 0.26764706]\n",
      "   [0.28921568 0.25392157 0.26764706]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.40490195 0.44019607 0.4990196 ]\n",
      "   [0.38504902 0.42132354 0.4757353 ]\n",
      "   [0.34534314 0.38357842 0.42916667]\n",
      "   ...\n",
      "   [0.3737745  0.3110294  0.16985294]\n",
      "   [0.37230393 0.3095588  0.16838235]\n",
      "   [0.37156862 0.30882353 0.16764706]]\n",
      "\n",
      "  [[0.23431373 0.26960784 0.32843137]\n",
      "   [0.22377451 0.26004902 0.3154412 ]\n",
      "   [0.20269608 0.24093138 0.28946078]\n",
      "   ...\n",
      "   [0.37034315 0.30759802 0.16642156]\n",
      "   [0.36985293 0.30710784 0.16593137]\n",
      "   [0.36960784 0.30686274 0.16568628]]\n",
      "\n",
      "  [[0.14901961 0.18431373 0.24313726]\n",
      "   [0.14313726 0.17941177 0.23529412]\n",
      "   [0.13137256 0.16960785 0.21960784]\n",
      "   ...\n",
      "   [0.36862746 0.30588236 0.16470589]\n",
      "   [0.36862746 0.30588236 0.16470589]\n",
      "   [0.36862746 0.30588236 0.16470589]]]\n",
      "\n",
      "\n",
      " [[[0.02745098 0.01176471 0.01568628]\n",
      "   [0.02647059 0.01078431 0.01470588]\n",
      "   [0.0245098  0.00882353 0.0127451 ]\n",
      "   ...\n",
      "   [0.06078431 0.03235294 0.02352941]\n",
      "   [0.05686275 0.03431373 0.02352941]\n",
      "   [0.05490196 0.03529412 0.02352941]]\n",
      "\n",
      "  [[0.02745098 0.01176471 0.01568628]\n",
      "   [0.02647059 0.01078431 0.01470588]\n",
      "   [0.0245098  0.00882353 0.0127451 ]\n",
      "   ...\n",
      "   [0.06004902 0.03161765 0.02205882]\n",
      "   [0.05661765 0.03406863 0.02303922]\n",
      "   [0.05490196 0.03529412 0.02352941]]\n",
      "\n",
      "  [[0.02745098 0.01176471 0.01568628]\n",
      "   [0.02647059 0.01078431 0.01470588]\n",
      "   [0.0245098  0.00882353 0.0127451 ]\n",
      "   ...\n",
      "   [0.05857843 0.03014706 0.01911765]\n",
      "   [0.05612745 0.03357843 0.02205882]\n",
      "   [0.05490196 0.03529412 0.02352941]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.00882353 0.00098039 0.00490196]\n",
      "   [0.00955882 0.00171569 0.00563726]\n",
      "   [0.01102941 0.00318627 0.00710784]\n",
      "   ...\n",
      "   [0.10931373 0.06617647 0.0504902 ]\n",
      "   [0.11029412 0.06715687 0.05147059]\n",
      "   [0.11078431 0.06764706 0.05196078]]\n",
      "\n",
      "  [[0.01078431 0.00294118 0.00686275]\n",
      "   [0.01102941 0.00318627 0.00710784]\n",
      "   [0.01151961 0.00367647 0.00759804]\n",
      "   ...\n",
      "   [0.11617647 0.07303922 0.05735294]\n",
      "   [0.11911765 0.0759804  0.06029412]\n",
      "   [0.12058824 0.07745098 0.06176471]]\n",
      "\n",
      "  [[0.01176471 0.00392157 0.00784314]\n",
      "   [0.01176471 0.00392157 0.00784314]\n",
      "   [0.01176471 0.00392157 0.00784314]\n",
      "   ...\n",
      "   [0.11960784 0.07647059 0.06078431]\n",
      "   [0.12352941 0.08039216 0.06470589]\n",
      "   [0.1254902  0.08235294 0.06666667]]]\n",
      "\n",
      "\n",
      " [[[0.17254902 0.10588235 0.04313726]\n",
      "   [0.17254902 0.10588235 0.04313726]\n",
      "   [0.17254902 0.10588235 0.04313726]\n",
      "   ...\n",
      "   [0.6617647  0.37941176 0.15196079]\n",
      "   [0.6598039  0.37745097 0.15      ]\n",
      "   [0.65882355 0.3764706  0.14901961]]\n",
      "\n",
      "  [[0.17156863 0.10490196 0.04215686]\n",
      "   [0.17156863 0.10490196 0.04215686]\n",
      "   [0.17156863 0.10490196 0.04215686]\n",
      "   ...\n",
      "   [0.6644608  0.38137254 0.15416667]\n",
      "   [0.6639706  0.37941176 0.15269607]\n",
      "   [0.6637255  0.37843138 0.15196079]]\n",
      "\n",
      "  [[0.16960785 0.10294118 0.04019608]\n",
      "   [0.16960785 0.10294118 0.04019608]\n",
      "   [0.16960785 0.10294118 0.04019608]\n",
      "   ...\n",
      "   [0.6698529  0.3852941  0.15857843]\n",
      "   [0.6723039  0.38333333 0.15808824]\n",
      "   [0.6735294  0.38235295 0.15784314]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.13725491 0.10588235 0.09411765]\n",
      "   [0.13553922 0.10416666 0.09240196]\n",
      "   [0.13210784 0.10073529 0.08897059]\n",
      "   ...\n",
      "   [0.6044118  0.5370098  0.4742647 ]\n",
      "   [0.7112745  0.64436275 0.5776961 ]\n",
      "   [0.7647059  0.69803923 0.62941176]]\n",
      "\n",
      "  [[0.13725491 0.10588235 0.09411765]\n",
      "   [0.1360294  0.10465686 0.09289216]\n",
      "   [0.13357843 0.10220588 0.09044117]\n",
      "   ...\n",
      "   [0.58186275 0.5129902  0.45416668]\n",
      "   [0.6985294  0.6311275  0.5683824 ]\n",
      "   [0.75686276 0.6901961  0.6254902 ]]\n",
      "\n",
      "  [[0.13725491 0.10588235 0.09411765]\n",
      "   [0.13627452 0.10490196 0.09313726]\n",
      "   [0.13431373 0.10294118 0.09117647]\n",
      "   ...\n",
      "   [0.57058823 0.5009804  0.44411764]\n",
      "   [0.69215685 0.6245098  0.5637255 ]\n",
      "   [0.7529412  0.6862745  0.62352943]]]\n",
      "\n",
      "\n",
      " [[[0.         0.00392157 0.01960784]\n",
      "   [0.02745098 0.03431373 0.05686275]\n",
      "   [0.08235294 0.09509804 0.13137256]\n",
      "   ...\n",
      "   [0.1127451  0.1127451  0.15980393]\n",
      "   [0.11862745 0.11862745 0.16568628]\n",
      "   [0.12156863 0.12156863 0.16862746]]\n",
      "\n",
      "  [[0.         0.00490196 0.02254902]\n",
      "   [0.02965686 0.0372549  0.06127451]\n",
      "   [0.08897059 0.10196079 0.13872549]\n",
      "   ...\n",
      "   [0.10882353 0.10882353 0.15441176]\n",
      "   [0.11470588 0.11470588 0.16127451]\n",
      "   [0.11764706 0.11764706 0.16470589]]\n",
      "\n",
      "  [[0.         0.00686275 0.02843137]\n",
      "   [0.03406863 0.04313726 0.07009804]\n",
      "   [0.10220588 0.11568628 0.15343137]\n",
      "   ...\n",
      "   [0.10098039 0.10098039 0.14362745]\n",
      "   [0.10686275 0.10686275 0.15245098]\n",
      "   [0.10980392 0.10980392 0.15686275]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.         0.         0.00784314]\n",
      "   [0.02818627 0.02818627 0.03602941]\n",
      "   [0.08455882 0.08455882 0.09240196]\n",
      "   ...\n",
      "   [0.11887255 0.11102941 0.1620098 ]\n",
      "   [0.12132353 0.11348039 0.16446078]\n",
      "   [0.12254902 0.11470588 0.16568628]]\n",
      "\n",
      "  [[0.         0.         0.00784314]\n",
      "   [0.02965686 0.02965686 0.0375    ]\n",
      "   [0.08897059 0.08897059 0.09681372]\n",
      "   ...\n",
      "   [0.11936274 0.1115196  0.1625    ]\n",
      "   [0.12279411 0.11495098 0.16593137]\n",
      "   [0.1245098  0.11666667 0.16764706]]\n",
      "\n",
      "  [[0.         0.         0.00784314]\n",
      "   [0.03039216 0.03039216 0.0382353 ]\n",
      "   [0.09117647 0.09117647 0.09901961]\n",
      "   ...\n",
      "   [0.11960784 0.11176471 0.1627451 ]\n",
      "   [0.12352941 0.11568628 0.16666667]\n",
      "   [0.1254902  0.11764706 0.16862746]]]], shape=(4, 224, 224, 3), dtype=float32)\n",
      "ลูปที่: 0\n"
     ]
    }
   ],
   "source": [
    "l = 0\n",
    "\n",
    "# ทดสอบ\n",
    "for a, p, n in train_dataset.take(5):\n",
    "    print(\"Anchor batch shape:\", a.shape)\n",
    "    print(\"Positive batch shape:\", p.shape)\n",
    "    print(\"Negative batch shape:\", n.shape)\n",
    "    print(\"ลูปที่:\", a)\n",
    "    #l = l + 1Q\n",
    "    print(\"ลูปที่:\", l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bbf76720",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Lambda, Input,Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "96adb3fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def QQQ():\n",
    "    input_shape = (224, 224, 3)\n",
    "\n",
    "    base_model = ResNet50(\n",
    "        include_top=False,\n",
    "        weights='imagenet',\n",
    "        input_shape=input_shape\n",
    "    )\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "        \n",
    "    x = base_model.output\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dense(128)(x)\n",
    "    embedding = Lambda(lambda x: tf.math.l2_normalize(x, axis=1))(x)\n",
    "    \n",
    "    # สร้างโมเดลและ return\n",
    "    model = Model(inputs=base_model.input, outputs=embedding)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9227a545",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_5 (InputLayer)           [(None, 224, 224, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " conv1_pad (ZeroPadding2D)      (None, 230, 230, 3)  0           ['input_5[0][0]']                \n",
      "                                                                                                  \n",
      " conv1_conv (Conv2D)            (None, 112, 112, 64  9472        ['conv1_pad[0][0]']              \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv1_bn (BatchNormalization)  (None, 112, 112, 64  256         ['conv1_conv[0][0]']             \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv1_relu (Activation)        (None, 112, 112, 64  0           ['conv1_bn[0][0]']               \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " pool1_pad (ZeroPadding2D)      (None, 114, 114, 64  0           ['conv1_relu[0][0]']             \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " pool1_pool (MaxPooling2D)      (None, 56, 56, 64)   0           ['pool1_pad[0][0]']              \n",
      "                                                                                                  \n",
      " conv2_block1_1_conv (Conv2D)   (None, 56, 56, 64)   4160        ['pool1_pool[0][0]']             \n",
      "                                                                                                  \n",
      " conv2_block1_1_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block1_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block1_1_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block1_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block1_2_conv (Conv2D)   (None, 56, 56, 64)   36928       ['conv2_block1_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block1_2_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block1_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block1_2_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block1_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block1_0_conv (Conv2D)   (None, 56, 56, 256)  16640       ['pool1_pool[0][0]']             \n",
      "                                                                                                  \n",
      " conv2_block1_3_conv (Conv2D)   (None, 56, 56, 256)  16640       ['conv2_block1_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block1_0_bn (BatchNormal  (None, 56, 56, 256)  1024       ['conv2_block1_0_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block1_3_bn (BatchNormal  (None, 56, 56, 256)  1024       ['conv2_block1_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block1_add (Add)         (None, 56, 56, 256)  0           ['conv2_block1_0_bn[0][0]',      \n",
      "                                                                  'conv2_block1_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv2_block1_out (Activation)  (None, 56, 56, 256)  0           ['conv2_block1_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv2_block2_1_conv (Conv2D)   (None, 56, 56, 64)   16448       ['conv2_block1_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv2_block2_1_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block2_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block2_1_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block2_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block2_2_conv (Conv2D)   (None, 56, 56, 64)   36928       ['conv2_block2_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block2_2_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block2_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block2_2_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block2_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block2_3_conv (Conv2D)   (None, 56, 56, 256)  16640       ['conv2_block2_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block2_3_bn (BatchNormal  (None, 56, 56, 256)  1024       ['conv2_block2_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block2_add (Add)         (None, 56, 56, 256)  0           ['conv2_block1_out[0][0]',       \n",
      "                                                                  'conv2_block2_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv2_block2_out (Activation)  (None, 56, 56, 256)  0           ['conv2_block2_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv2_block3_1_conv (Conv2D)   (None, 56, 56, 64)   16448       ['conv2_block2_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv2_block3_1_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block3_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block3_1_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block3_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block3_2_conv (Conv2D)   (None, 56, 56, 64)   36928       ['conv2_block3_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block3_2_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block3_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block3_2_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block3_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block3_3_conv (Conv2D)   (None, 56, 56, 256)  16640       ['conv2_block3_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block3_3_bn (BatchNormal  (None, 56, 56, 256)  1024       ['conv2_block3_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block3_add (Add)         (None, 56, 56, 256)  0           ['conv2_block2_out[0][0]',       \n",
      "                                                                  'conv2_block3_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv2_block3_out (Activation)  (None, 56, 56, 256)  0           ['conv2_block3_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block1_1_conv (Conv2D)   (None, 28, 28, 128)  32896       ['conv2_block3_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block1_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block1_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block1_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block1_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block1_2_conv (Conv2D)   (None, 28, 28, 128)  147584      ['conv3_block1_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block1_2_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block1_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block1_2_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block1_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block1_0_conv (Conv2D)   (None, 28, 28, 512)  131584      ['conv2_block3_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block1_3_conv (Conv2D)   (None, 28, 28, 512)  66048       ['conv3_block1_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block1_0_bn (BatchNormal  (None, 28, 28, 512)  2048       ['conv3_block1_0_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block1_3_bn (BatchNormal  (None, 28, 28, 512)  2048       ['conv3_block1_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block1_add (Add)         (None, 28, 28, 512)  0           ['conv3_block1_0_bn[0][0]',      \n",
      "                                                                  'conv3_block1_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv3_block1_out (Activation)  (None, 28, 28, 512)  0           ['conv3_block1_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block2_1_conv (Conv2D)   (None, 28, 28, 128)  65664       ['conv3_block1_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block2_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block2_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block2_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block2_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block2_2_conv (Conv2D)   (None, 28, 28, 128)  147584      ['conv3_block2_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block2_2_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block2_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block2_2_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block2_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block2_3_conv (Conv2D)   (None, 28, 28, 512)  66048       ['conv3_block2_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block2_3_bn (BatchNormal  (None, 28, 28, 512)  2048       ['conv3_block2_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block2_add (Add)         (None, 28, 28, 512)  0           ['conv3_block1_out[0][0]',       \n",
      "                                                                  'conv3_block2_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv3_block2_out (Activation)  (None, 28, 28, 512)  0           ['conv3_block2_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block3_1_conv (Conv2D)   (None, 28, 28, 128)  65664       ['conv3_block2_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block3_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block3_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block3_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block3_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block3_2_conv (Conv2D)   (None, 28, 28, 128)  147584      ['conv3_block3_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block3_2_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block3_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block3_2_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block3_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block3_3_conv (Conv2D)   (None, 28, 28, 512)  66048       ['conv3_block3_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block3_3_bn (BatchNormal  (None, 28, 28, 512)  2048       ['conv3_block3_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block3_add (Add)         (None, 28, 28, 512)  0           ['conv3_block2_out[0][0]',       \n",
      "                                                                  'conv3_block3_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv3_block3_out (Activation)  (None, 28, 28, 512)  0           ['conv3_block3_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block4_1_conv (Conv2D)   (None, 28, 28, 128)  65664       ['conv3_block3_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block4_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block4_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block4_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block4_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block4_2_conv (Conv2D)   (None, 28, 28, 128)  147584      ['conv3_block4_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block4_2_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block4_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block4_2_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block4_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block4_3_conv (Conv2D)   (None, 28, 28, 512)  66048       ['conv3_block4_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block4_3_bn (BatchNormal  (None, 28, 28, 512)  2048       ['conv3_block4_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block4_add (Add)         (None, 28, 28, 512)  0           ['conv3_block3_out[0][0]',       \n",
      "                                                                  'conv3_block4_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv3_block4_out (Activation)  (None, 28, 28, 512)  0           ['conv3_block4_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block1_1_conv (Conv2D)   (None, 14, 14, 256)  131328      ['conv3_block4_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block1_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block1_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block1_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block1_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block1_2_conv (Conv2D)   (None, 14, 14, 256)  590080      ['conv4_block1_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block1_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block1_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block1_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block1_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block1_0_conv (Conv2D)   (None, 14, 14, 1024  525312      ['conv3_block4_out[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block1_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block1_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block1_0_bn (BatchNormal  (None, 14, 14, 1024  4096       ['conv4_block1_0_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block1_3_bn (BatchNormal  (None, 14, 14, 1024  4096       ['conv4_block1_3_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block1_add (Add)         (None, 14, 14, 1024  0           ['conv4_block1_0_bn[0][0]',      \n",
      "                                )                                 'conv4_block1_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block1_out (Activation)  (None, 14, 14, 1024  0           ['conv4_block1_add[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block2_1_conv (Conv2D)   (None, 14, 14, 256)  262400      ['conv4_block1_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block2_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block2_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block2_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block2_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block2_2_conv (Conv2D)   (None, 14, 14, 256)  590080      ['conv4_block2_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block2_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block2_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block2_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block2_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block2_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block2_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block2_3_bn (BatchNormal  (None, 14, 14, 1024  4096       ['conv4_block2_3_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block2_add (Add)         (None, 14, 14, 1024  0           ['conv4_block1_out[0][0]',       \n",
      "                                )                                 'conv4_block2_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block2_out (Activation)  (None, 14, 14, 1024  0           ['conv4_block2_add[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block3_1_conv (Conv2D)   (None, 14, 14, 256)  262400      ['conv4_block2_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block3_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block3_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block3_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block3_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block3_2_conv (Conv2D)   (None, 14, 14, 256)  590080      ['conv4_block3_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block3_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block3_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block3_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block3_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block3_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block3_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block3_3_bn (BatchNormal  (None, 14, 14, 1024  4096       ['conv4_block3_3_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block3_add (Add)         (None, 14, 14, 1024  0           ['conv4_block2_out[0][0]',       \n",
      "                                )                                 'conv4_block3_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block3_out (Activation)  (None, 14, 14, 1024  0           ['conv4_block3_add[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block4_1_conv (Conv2D)   (None, 14, 14, 256)  262400      ['conv4_block3_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block4_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block4_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block4_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block4_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block4_2_conv (Conv2D)   (None, 14, 14, 256)  590080      ['conv4_block4_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block4_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block4_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block4_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block4_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block4_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block4_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block4_3_bn (BatchNormal  (None, 14, 14, 1024  4096       ['conv4_block4_3_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block4_add (Add)         (None, 14, 14, 1024  0           ['conv4_block3_out[0][0]',       \n",
      "                                )                                 'conv4_block4_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block4_out (Activation)  (None, 14, 14, 1024  0           ['conv4_block4_add[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block5_1_conv (Conv2D)   (None, 14, 14, 256)  262400      ['conv4_block4_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block5_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block5_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block5_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block5_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block5_2_conv (Conv2D)   (None, 14, 14, 256)  590080      ['conv4_block5_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block5_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block5_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block5_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block5_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block5_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block5_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block5_3_bn (BatchNormal  (None, 14, 14, 1024  4096       ['conv4_block5_3_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block5_add (Add)         (None, 14, 14, 1024  0           ['conv4_block4_out[0][0]',       \n",
      "                                )                                 'conv4_block5_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block5_out (Activation)  (None, 14, 14, 1024  0           ['conv4_block5_add[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block6_1_conv (Conv2D)   (None, 14, 14, 256)  262400      ['conv4_block5_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block6_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block6_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block6_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block6_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block6_2_conv (Conv2D)   (None, 14, 14, 256)  590080      ['conv4_block6_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block6_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block6_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block6_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block6_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block6_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block6_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block6_3_bn (BatchNormal  (None, 14, 14, 1024  4096       ['conv4_block6_3_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block6_add (Add)         (None, 14, 14, 1024  0           ['conv4_block5_out[0][0]',       \n",
      "                                )                                 'conv4_block6_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block6_out (Activation)  (None, 14, 14, 1024  0           ['conv4_block6_add[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv5_block1_1_conv (Conv2D)   (None, 7, 7, 512)    524800      ['conv4_block6_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv5_block1_1_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block1_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block1_1_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block1_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block1_2_conv (Conv2D)   (None, 7, 7, 512)    2359808     ['conv5_block1_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block1_2_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block1_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block1_2_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block1_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block1_0_conv (Conv2D)   (None, 7, 7, 2048)   2099200     ['conv4_block6_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv5_block1_3_conv (Conv2D)   (None, 7, 7, 2048)   1050624     ['conv5_block1_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block1_0_bn (BatchNormal  (None, 7, 7, 2048)  8192        ['conv5_block1_0_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block1_3_bn (BatchNormal  (None, 7, 7, 2048)  8192        ['conv5_block1_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block1_add (Add)         (None, 7, 7, 2048)   0           ['conv5_block1_0_bn[0][0]',      \n",
      "                                                                  'conv5_block1_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv5_block1_out (Activation)  (None, 7, 7, 2048)   0           ['conv5_block1_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv5_block2_1_conv (Conv2D)   (None, 7, 7, 512)    1049088     ['conv5_block1_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv5_block2_1_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block2_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block2_1_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block2_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block2_2_conv (Conv2D)   (None, 7, 7, 512)    2359808     ['conv5_block2_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block2_2_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block2_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block2_2_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block2_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block2_3_conv (Conv2D)   (None, 7, 7, 2048)   1050624     ['conv5_block2_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block2_3_bn (BatchNormal  (None, 7, 7, 2048)  8192        ['conv5_block2_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block2_add (Add)         (None, 7, 7, 2048)   0           ['conv5_block1_out[0][0]',       \n",
      "                                                                  'conv5_block2_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv5_block2_out (Activation)  (None, 7, 7, 2048)   0           ['conv5_block2_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv5_block3_1_conv (Conv2D)   (None, 7, 7, 512)    1049088     ['conv5_block2_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv5_block3_1_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block3_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block3_1_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block3_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block3_2_conv (Conv2D)   (None, 7, 7, 512)    2359808     ['conv5_block3_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block3_2_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block3_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block3_2_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block3_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block3_3_conv (Conv2D)   (None, 7, 7, 2048)   1050624     ['conv5_block3_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block3_3_bn (BatchNormal  (None, 7, 7, 2048)  8192        ['conv5_block3_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block3_add (Add)         (None, 7, 7, 2048)   0           ['conv5_block2_out[0][0]',       \n",
      "                                                                  'conv5_block3_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv5_block3_out (Activation)  (None, 7, 7, 2048)   0           ['conv5_block3_add[0][0]']       \n",
      "                                                                                                  \n",
      " global_average_pooling2d_4 (Gl  (None, 2048)        0           ['conv5_block3_out[0][0]']       \n",
      " obalAveragePooling2D)                                                                            \n",
      "                                                                                                  \n",
      " dense_4 (Dense)                (None, 128)          262272      ['global_average_pooling2d_4[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " lambda_4 (Lambda)              (None, 128)          0           ['dense_4[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 23,849,984\n",
      "Trainable params: 262,272\n",
      "Non-trainable params: 23,587,712\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = QQQ()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2d5e89ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 input_5 False\n",
      "1 conv1_pad False\n",
      "2 conv1_conv False\n",
      "3 conv1_bn False\n",
      "4 conv1_relu False\n",
      "5 pool1_pad False\n",
      "6 pool1_pool False\n",
      "7 conv2_block1_1_conv False\n",
      "8 conv2_block1_1_bn False\n",
      "9 conv2_block1_1_relu False\n",
      "10 conv2_block1_2_conv False\n",
      "11 conv2_block1_2_bn False\n",
      "12 conv2_block1_2_relu False\n",
      "13 conv2_block1_0_conv False\n",
      "14 conv2_block1_3_conv False\n",
      "15 conv2_block1_0_bn False\n",
      "16 conv2_block1_3_bn False\n",
      "17 conv2_block1_add False\n",
      "18 conv2_block1_out False\n",
      "19 conv2_block2_1_conv False\n",
      "20 conv2_block2_1_bn False\n",
      "21 conv2_block2_1_relu False\n",
      "22 conv2_block2_2_conv False\n",
      "23 conv2_block2_2_bn False\n",
      "24 conv2_block2_2_relu False\n",
      "25 conv2_block2_3_conv False\n",
      "26 conv2_block2_3_bn False\n",
      "27 conv2_block2_add False\n",
      "28 conv2_block2_out False\n",
      "29 conv2_block3_1_conv False\n",
      "30 conv2_block3_1_bn False\n",
      "31 conv2_block3_1_relu False\n",
      "32 conv2_block3_2_conv False\n",
      "33 conv2_block3_2_bn False\n",
      "34 conv2_block3_2_relu False\n",
      "35 conv2_block3_3_conv False\n",
      "36 conv2_block3_3_bn False\n",
      "37 conv2_block3_add False\n",
      "38 conv2_block3_out False\n",
      "39 conv3_block1_1_conv False\n",
      "40 conv3_block1_1_bn False\n",
      "41 conv3_block1_1_relu False\n",
      "42 conv3_block1_2_conv False\n",
      "43 conv3_block1_2_bn False\n",
      "44 conv3_block1_2_relu False\n",
      "45 conv3_block1_0_conv False\n",
      "46 conv3_block1_3_conv False\n",
      "47 conv3_block1_0_bn False\n",
      "48 conv3_block1_3_bn False\n",
      "49 conv3_block1_add False\n",
      "50 conv3_block1_out False\n",
      "51 conv3_block2_1_conv False\n",
      "52 conv3_block2_1_bn False\n",
      "53 conv3_block2_1_relu False\n",
      "54 conv3_block2_2_conv False\n",
      "55 conv3_block2_2_bn False\n",
      "56 conv3_block2_2_relu False\n",
      "57 conv3_block2_3_conv False\n",
      "58 conv3_block2_3_bn False\n",
      "59 conv3_block2_add False\n",
      "60 conv3_block2_out False\n",
      "61 conv3_block3_1_conv False\n",
      "62 conv3_block3_1_bn False\n",
      "63 conv3_block3_1_relu False\n",
      "64 conv3_block3_2_conv False\n",
      "65 conv3_block3_2_bn False\n",
      "66 conv3_block3_2_relu False\n",
      "67 conv3_block3_3_conv False\n",
      "68 conv3_block3_3_bn False\n",
      "69 conv3_block3_add False\n",
      "70 conv3_block3_out False\n",
      "71 conv3_block4_1_conv False\n",
      "72 conv3_block4_1_bn False\n",
      "73 conv3_block4_1_relu False\n",
      "74 conv3_block4_2_conv False\n",
      "75 conv3_block4_2_bn False\n",
      "76 conv3_block4_2_relu False\n",
      "77 conv3_block4_3_conv False\n",
      "78 conv3_block4_3_bn False\n",
      "79 conv3_block4_add False\n",
      "80 conv3_block4_out False\n",
      "81 conv4_block1_1_conv False\n",
      "82 conv4_block1_1_bn False\n",
      "83 conv4_block1_1_relu False\n",
      "84 conv4_block1_2_conv False\n",
      "85 conv4_block1_2_bn False\n",
      "86 conv4_block1_2_relu False\n",
      "87 conv4_block1_0_conv False\n",
      "88 conv4_block1_3_conv False\n",
      "89 conv4_block1_0_bn False\n",
      "90 conv4_block1_3_bn False\n",
      "91 conv4_block1_add False\n",
      "92 conv4_block1_out False\n",
      "93 conv4_block2_1_conv False\n",
      "94 conv4_block2_1_bn False\n",
      "95 conv4_block2_1_relu False\n",
      "96 conv4_block2_2_conv False\n",
      "97 conv4_block2_2_bn False\n",
      "98 conv4_block2_2_relu False\n",
      "99 conv4_block2_3_conv False\n",
      "100 conv4_block2_3_bn False\n",
      "101 conv4_block2_add False\n",
      "102 conv4_block2_out False\n",
      "103 conv4_block3_1_conv False\n",
      "104 conv4_block3_1_bn False\n",
      "105 conv4_block3_1_relu False\n",
      "106 conv4_block3_2_conv False\n",
      "107 conv4_block3_2_bn False\n",
      "108 conv4_block3_2_relu False\n",
      "109 conv4_block3_3_conv False\n",
      "110 conv4_block3_3_bn False\n",
      "111 conv4_block3_add False\n",
      "112 conv4_block3_out False\n",
      "113 conv4_block4_1_conv False\n",
      "114 conv4_block4_1_bn False\n",
      "115 conv4_block4_1_relu False\n",
      "116 conv4_block4_2_conv False\n",
      "117 conv4_block4_2_bn False\n",
      "118 conv4_block4_2_relu False\n",
      "119 conv4_block4_3_conv False\n",
      "120 conv4_block4_3_bn False\n",
      "121 conv4_block4_add False\n",
      "122 conv4_block4_out False\n",
      "123 conv4_block5_1_conv False\n",
      "124 conv4_block5_1_bn False\n",
      "125 conv4_block5_1_relu False\n",
      "126 conv4_block5_2_conv False\n",
      "127 conv4_block5_2_bn False\n",
      "128 conv4_block5_2_relu False\n",
      "129 conv4_block5_3_conv False\n",
      "130 conv4_block5_3_bn False\n",
      "131 conv4_block5_add False\n",
      "132 conv4_block5_out False\n",
      "133 conv4_block6_1_conv False\n",
      "134 conv4_block6_1_bn False\n",
      "135 conv4_block6_1_relu False\n",
      "136 conv4_block6_2_conv False\n",
      "137 conv4_block6_2_bn False\n",
      "138 conv4_block6_2_relu False\n",
      "139 conv4_block6_3_conv False\n",
      "140 conv4_block6_3_bn False\n",
      "141 conv4_block6_add False\n",
      "142 conv4_block6_out False\n",
      "143 conv5_block1_1_conv False\n",
      "144 conv5_block1_1_bn False\n",
      "145 conv5_block1_1_relu False\n",
      "146 conv5_block1_2_conv False\n",
      "147 conv5_block1_2_bn False\n",
      "148 conv5_block1_2_relu False\n",
      "149 conv5_block1_0_conv False\n",
      "150 conv5_block1_3_conv False\n",
      "151 conv5_block1_0_bn False\n",
      "152 conv5_block1_3_bn False\n",
      "153 conv5_block1_add False\n",
      "154 conv5_block1_out False\n",
      "155 conv5_block2_1_conv False\n",
      "156 conv5_block2_1_bn False\n",
      "157 conv5_block2_1_relu False\n",
      "158 conv5_block2_2_conv False\n",
      "159 conv5_block2_2_bn False\n",
      "160 conv5_block2_2_relu False\n",
      "161 conv5_block2_3_conv False\n",
      "162 conv5_block2_3_bn False\n",
      "163 conv5_block2_add False\n",
      "164 conv5_block2_out False\n",
      "165 conv5_block3_1_conv False\n",
      "166 conv5_block3_1_bn False\n",
      "167 conv5_block3_1_relu False\n",
      "168 conv5_block3_2_conv False\n",
      "169 conv5_block3_2_bn False\n",
      "170 conv5_block3_2_relu False\n",
      "171 conv5_block3_3_conv False\n",
      "172 conv5_block3_3_bn False\n",
      "173 conv5_block3_add False\n",
      "174 conv5_block3_out False\n",
      "175 global_average_pooling2d_4 True\n",
      "176 dense_4 True\n",
      "177 lambda_4 True\n"
     ]
    }
   ],
   "source": [
    "for i, layer in enumerate(model.layers):\n",
    "    print(i, layer.name, layer.trainable)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecab1404",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model2():\n",
    "    input_shape = (224, 224, 3)\n",
    "\n",
    "    base_model = ResNet50(\n",
    "        include_top=False,\n",
    "        weights='imagenet',\n",
    "        input_shape=input_shape\n",
    "    )\n",
    "    # เพิ่มโค้ดนี้ในฟังก์ชัน cor() ก่อน return model\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = True\n",
    "        \n",
    "    x = base_model.output\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dense(128)(x)\n",
    "    embedding = Lambda(lambda x: tf.math.l2_normalize(x, axis=1))(x)\n",
    "    \n",
    "    # สร้างโมเดลและ return\n",
    "    model = Model(inputs=base_model.input, outputs=embedding)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2c1ca454",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def model3():\n",
    "    input_shape = (224, 224, 3)\n",
    "\n",
    "    base_model = ResNet50(\n",
    "        include_top=False,\n",
    "        weights='imagenet',\n",
    "        input_shape=input_shape\n",
    "    )\n",
    "    \n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "    \n",
    "    for layer in base_model.layers[-30:]:\n",
    "        layer.trainable = True\n",
    "\n",
    "    x = base_model.output\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dense(128)(x)\n",
    "    embedding = Lambda(lambda x: tf.math.l2_normalize(x, axis=1))(x)\n",
    "    \n",
    "    # สร้างโมเดลและ return\n",
    "    model = Model(inputs=base_model.input, outputs=embedding)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0643ed9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 224, 224, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " conv1_pad (ZeroPadding2D)      (None, 230, 230, 3)  0           ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " conv1_conv (Conv2D)            (None, 112, 112, 64  9472        ['conv1_pad[0][0]']              \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv1_bn (BatchNormalization)  (None, 112, 112, 64  256         ['conv1_conv[0][0]']             \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv1_relu (Activation)        (None, 112, 112, 64  0           ['conv1_bn[0][0]']               \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " pool1_pad (ZeroPadding2D)      (None, 114, 114, 64  0           ['conv1_relu[0][0]']             \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " pool1_pool (MaxPooling2D)      (None, 56, 56, 64)   0           ['pool1_pad[0][0]']              \n",
      "                                                                                                  \n",
      " conv2_block1_1_conv (Conv2D)   (None, 56, 56, 64)   4160        ['pool1_pool[0][0]']             \n",
      "                                                                                                  \n",
      " conv2_block1_1_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block1_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block1_1_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block1_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block1_2_conv (Conv2D)   (None, 56, 56, 64)   36928       ['conv2_block1_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block1_2_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block1_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block1_2_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block1_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block1_0_conv (Conv2D)   (None, 56, 56, 256)  16640       ['pool1_pool[0][0]']             \n",
      "                                                                                                  \n",
      " conv2_block1_3_conv (Conv2D)   (None, 56, 56, 256)  16640       ['conv2_block1_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block1_0_bn (BatchNormal  (None, 56, 56, 256)  1024       ['conv2_block1_0_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block1_3_bn (BatchNormal  (None, 56, 56, 256)  1024       ['conv2_block1_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block1_add (Add)         (None, 56, 56, 256)  0           ['conv2_block1_0_bn[0][0]',      \n",
      "                                                                  'conv2_block1_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv2_block1_out (Activation)  (None, 56, 56, 256)  0           ['conv2_block1_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv2_block2_1_conv (Conv2D)   (None, 56, 56, 64)   16448       ['conv2_block1_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv2_block2_1_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block2_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block2_1_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block2_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block2_2_conv (Conv2D)   (None, 56, 56, 64)   36928       ['conv2_block2_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block2_2_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block2_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block2_2_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block2_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block2_3_conv (Conv2D)   (None, 56, 56, 256)  16640       ['conv2_block2_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block2_3_bn (BatchNormal  (None, 56, 56, 256)  1024       ['conv2_block2_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block2_add (Add)         (None, 56, 56, 256)  0           ['conv2_block1_out[0][0]',       \n",
      "                                                                  'conv2_block2_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv2_block2_out (Activation)  (None, 56, 56, 256)  0           ['conv2_block2_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv2_block3_1_conv (Conv2D)   (None, 56, 56, 64)   16448       ['conv2_block2_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv2_block3_1_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block3_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block3_1_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block3_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block3_2_conv (Conv2D)   (None, 56, 56, 64)   36928       ['conv2_block3_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block3_2_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block3_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block3_2_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block3_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block3_3_conv (Conv2D)   (None, 56, 56, 256)  16640       ['conv2_block3_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block3_3_bn (BatchNormal  (None, 56, 56, 256)  1024       ['conv2_block3_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block3_add (Add)         (None, 56, 56, 256)  0           ['conv2_block2_out[0][0]',       \n",
      "                                                                  'conv2_block3_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv2_block3_out (Activation)  (None, 56, 56, 256)  0           ['conv2_block3_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block1_1_conv (Conv2D)   (None, 28, 28, 128)  32896       ['conv2_block3_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block1_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block1_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block1_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block1_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block1_2_conv (Conv2D)   (None, 28, 28, 128)  147584      ['conv3_block1_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block1_2_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block1_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block1_2_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block1_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block1_0_conv (Conv2D)   (None, 28, 28, 512)  131584      ['conv2_block3_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block1_3_conv (Conv2D)   (None, 28, 28, 512)  66048       ['conv3_block1_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block1_0_bn (BatchNormal  (None, 28, 28, 512)  2048       ['conv3_block1_0_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block1_3_bn (BatchNormal  (None, 28, 28, 512)  2048       ['conv3_block1_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block1_add (Add)         (None, 28, 28, 512)  0           ['conv3_block1_0_bn[0][0]',      \n",
      "                                                                  'conv3_block1_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv3_block1_out (Activation)  (None, 28, 28, 512)  0           ['conv3_block1_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block2_1_conv (Conv2D)   (None, 28, 28, 128)  65664       ['conv3_block1_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block2_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block2_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block2_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block2_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block2_2_conv (Conv2D)   (None, 28, 28, 128)  147584      ['conv3_block2_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block2_2_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block2_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block2_2_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block2_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block2_3_conv (Conv2D)   (None, 28, 28, 512)  66048       ['conv3_block2_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block2_3_bn (BatchNormal  (None, 28, 28, 512)  2048       ['conv3_block2_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block2_add (Add)         (None, 28, 28, 512)  0           ['conv3_block1_out[0][0]',       \n",
      "                                                                  'conv3_block2_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv3_block2_out (Activation)  (None, 28, 28, 512)  0           ['conv3_block2_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block3_1_conv (Conv2D)   (None, 28, 28, 128)  65664       ['conv3_block2_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block3_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block3_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block3_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block3_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block3_2_conv (Conv2D)   (None, 28, 28, 128)  147584      ['conv3_block3_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block3_2_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block3_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block3_2_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block3_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block3_3_conv (Conv2D)   (None, 28, 28, 512)  66048       ['conv3_block3_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block3_3_bn (BatchNormal  (None, 28, 28, 512)  2048       ['conv3_block3_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block3_add (Add)         (None, 28, 28, 512)  0           ['conv3_block2_out[0][0]',       \n",
      "                                                                  'conv3_block3_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv3_block3_out (Activation)  (None, 28, 28, 512)  0           ['conv3_block3_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block4_1_conv (Conv2D)   (None, 28, 28, 128)  65664       ['conv3_block3_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block4_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block4_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block4_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block4_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block4_2_conv (Conv2D)   (None, 28, 28, 128)  147584      ['conv3_block4_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block4_2_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block4_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block4_2_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block4_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block4_3_conv (Conv2D)   (None, 28, 28, 512)  66048       ['conv3_block4_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block4_3_bn (BatchNormal  (None, 28, 28, 512)  2048       ['conv3_block4_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block4_add (Add)         (None, 28, 28, 512)  0           ['conv3_block3_out[0][0]',       \n",
      "                                                                  'conv3_block4_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv3_block4_out (Activation)  (None, 28, 28, 512)  0           ['conv3_block4_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block1_1_conv (Conv2D)   (None, 14, 14, 256)  131328      ['conv3_block4_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block1_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block1_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block1_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block1_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block1_2_conv (Conv2D)   (None, 14, 14, 256)  590080      ['conv4_block1_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block1_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block1_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block1_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block1_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block1_0_conv (Conv2D)   (None, 14, 14, 1024  525312      ['conv3_block4_out[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block1_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block1_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block1_0_bn (BatchNormal  (None, 14, 14, 1024  4096       ['conv4_block1_0_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block1_3_bn (BatchNormal  (None, 14, 14, 1024  4096       ['conv4_block1_3_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block1_add (Add)         (None, 14, 14, 1024  0           ['conv4_block1_0_bn[0][0]',      \n",
      "                                )                                 'conv4_block1_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block1_out (Activation)  (None, 14, 14, 1024  0           ['conv4_block1_add[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block2_1_conv (Conv2D)   (None, 14, 14, 256)  262400      ['conv4_block1_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block2_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block2_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block2_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block2_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block2_2_conv (Conv2D)   (None, 14, 14, 256)  590080      ['conv4_block2_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block2_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block2_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block2_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block2_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block2_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block2_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block2_3_bn (BatchNormal  (None, 14, 14, 1024  4096       ['conv4_block2_3_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block2_add (Add)         (None, 14, 14, 1024  0           ['conv4_block1_out[0][0]',       \n",
      "                                )                                 'conv4_block2_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block2_out (Activation)  (None, 14, 14, 1024  0           ['conv4_block2_add[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block3_1_conv (Conv2D)   (None, 14, 14, 256)  262400      ['conv4_block2_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block3_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block3_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block3_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block3_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block3_2_conv (Conv2D)   (None, 14, 14, 256)  590080      ['conv4_block3_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block3_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block3_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block3_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block3_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block3_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block3_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block3_3_bn (BatchNormal  (None, 14, 14, 1024  4096       ['conv4_block3_3_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block3_add (Add)         (None, 14, 14, 1024  0           ['conv4_block2_out[0][0]',       \n",
      "                                )                                 'conv4_block3_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block3_out (Activation)  (None, 14, 14, 1024  0           ['conv4_block3_add[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block4_1_conv (Conv2D)   (None, 14, 14, 256)  262400      ['conv4_block3_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block4_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block4_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block4_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block4_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block4_2_conv (Conv2D)   (None, 14, 14, 256)  590080      ['conv4_block4_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block4_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block4_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block4_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block4_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block4_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block4_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block4_3_bn (BatchNormal  (None, 14, 14, 1024  4096       ['conv4_block4_3_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block4_add (Add)         (None, 14, 14, 1024  0           ['conv4_block3_out[0][0]',       \n",
      "                                )                                 'conv4_block4_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block4_out (Activation)  (None, 14, 14, 1024  0           ['conv4_block4_add[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block5_1_conv (Conv2D)   (None, 14, 14, 256)  262400      ['conv4_block4_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block5_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block5_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block5_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block5_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block5_2_conv (Conv2D)   (None, 14, 14, 256)  590080      ['conv4_block5_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block5_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block5_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block5_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block5_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block5_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block5_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block5_3_bn (BatchNormal  (None, 14, 14, 1024  4096       ['conv4_block5_3_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block5_add (Add)         (None, 14, 14, 1024  0           ['conv4_block4_out[0][0]',       \n",
      "                                )                                 'conv4_block5_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block5_out (Activation)  (None, 14, 14, 1024  0           ['conv4_block5_add[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block6_1_conv (Conv2D)   (None, 14, 14, 256)  262400      ['conv4_block5_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block6_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block6_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block6_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block6_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block6_2_conv (Conv2D)   (None, 14, 14, 256)  590080      ['conv4_block6_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block6_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block6_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block6_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block6_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block6_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block6_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block6_3_bn (BatchNormal  (None, 14, 14, 1024  4096       ['conv4_block6_3_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block6_add (Add)         (None, 14, 14, 1024  0           ['conv4_block5_out[0][0]',       \n",
      "                                )                                 'conv4_block6_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block6_out (Activation)  (None, 14, 14, 1024  0           ['conv4_block6_add[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv5_block1_1_conv (Conv2D)   (None, 7, 7, 512)    524800      ['conv4_block6_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv5_block1_1_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block1_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block1_1_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block1_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block1_2_conv (Conv2D)   (None, 7, 7, 512)    2359808     ['conv5_block1_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block1_2_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block1_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block1_2_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block1_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block1_0_conv (Conv2D)   (None, 7, 7, 2048)   2099200     ['conv4_block6_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv5_block1_3_conv (Conv2D)   (None, 7, 7, 2048)   1050624     ['conv5_block1_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block1_0_bn (BatchNormal  (None, 7, 7, 2048)  8192        ['conv5_block1_0_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block1_3_bn (BatchNormal  (None, 7, 7, 2048)  8192        ['conv5_block1_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block1_add (Add)         (None, 7, 7, 2048)   0           ['conv5_block1_0_bn[0][0]',      \n",
      "                                                                  'conv5_block1_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv5_block1_out (Activation)  (None, 7, 7, 2048)   0           ['conv5_block1_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv5_block2_1_conv (Conv2D)   (None, 7, 7, 512)    1049088     ['conv5_block1_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv5_block2_1_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block2_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block2_1_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block2_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block2_2_conv (Conv2D)   (None, 7, 7, 512)    2359808     ['conv5_block2_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block2_2_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block2_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block2_2_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block2_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block2_3_conv (Conv2D)   (None, 7, 7, 2048)   1050624     ['conv5_block2_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block2_3_bn (BatchNormal  (None, 7, 7, 2048)  8192        ['conv5_block2_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block2_add (Add)         (None, 7, 7, 2048)   0           ['conv5_block1_out[0][0]',       \n",
      "                                                                  'conv5_block2_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv5_block2_out (Activation)  (None, 7, 7, 2048)   0           ['conv5_block2_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv5_block3_1_conv (Conv2D)   (None, 7, 7, 512)    1049088     ['conv5_block2_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv5_block3_1_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block3_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block3_1_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block3_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block3_2_conv (Conv2D)   (None, 7, 7, 512)    2359808     ['conv5_block3_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block3_2_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block3_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block3_2_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block3_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block3_3_conv (Conv2D)   (None, 7, 7, 2048)   1050624     ['conv5_block3_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block3_3_bn (BatchNormal  (None, 7, 7, 2048)  8192        ['conv5_block3_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block3_add (Add)         (None, 7, 7, 2048)   0           ['conv5_block2_out[0][0]',       \n",
      "                                                                  'conv5_block3_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv5_block3_out (Activation)  (None, 7, 7, 2048)   0           ['conv5_block3_add[0][0]']       \n",
      "                                                                                                  \n",
      " global_average_pooling2d (Glob  (None, 2048)        0           ['conv5_block3_out[0][0]']       \n",
      " alAveragePooling2D)                                                                              \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 128)          262272      ['global_average_pooling2d[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " lambda (Lambda)                (None, 128)          0           ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 23,849,984\n",
      "Trainable params: 14,712,448\n",
      "Non-trainable params: 9,137,536\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = model3()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4d455007",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 input_1 False\n",
      "1 conv1_pad False\n",
      "2 conv1_conv False\n",
      "3 conv1_bn False\n",
      "4 conv1_relu False\n",
      "5 pool1_pad False\n",
      "6 pool1_pool False\n",
      "7 conv2_block1_1_conv False\n",
      "8 conv2_block1_1_bn False\n",
      "9 conv2_block1_1_relu False\n",
      "10 conv2_block1_2_conv False\n",
      "11 conv2_block1_2_bn False\n",
      "12 conv2_block1_2_relu False\n",
      "13 conv2_block1_0_conv False\n",
      "14 conv2_block1_3_conv False\n",
      "15 conv2_block1_0_bn False\n",
      "16 conv2_block1_3_bn False\n",
      "17 conv2_block1_add False\n",
      "18 conv2_block1_out False\n",
      "19 conv2_block2_1_conv False\n",
      "20 conv2_block2_1_bn False\n",
      "21 conv2_block2_1_relu False\n",
      "22 conv2_block2_2_conv False\n",
      "23 conv2_block2_2_bn False\n",
      "24 conv2_block2_2_relu False\n",
      "25 conv2_block2_3_conv False\n",
      "26 conv2_block2_3_bn False\n",
      "27 conv2_block2_add False\n",
      "28 conv2_block2_out False\n",
      "29 conv2_block3_1_conv False\n",
      "30 conv2_block3_1_bn False\n",
      "31 conv2_block3_1_relu False\n",
      "32 conv2_block3_2_conv False\n",
      "33 conv2_block3_2_bn False\n",
      "34 conv2_block3_2_relu False\n",
      "35 conv2_block3_3_conv False\n",
      "36 conv2_block3_3_bn False\n",
      "37 conv2_block3_add False\n",
      "38 conv2_block3_out False\n",
      "39 conv3_block1_1_conv False\n",
      "40 conv3_block1_1_bn False\n",
      "41 conv3_block1_1_relu False\n",
      "42 conv3_block1_2_conv False\n",
      "43 conv3_block1_2_bn False\n",
      "44 conv3_block1_2_relu False\n",
      "45 conv3_block1_0_conv False\n",
      "46 conv3_block1_3_conv False\n",
      "47 conv3_block1_0_bn False\n",
      "48 conv3_block1_3_bn False\n",
      "49 conv3_block1_add False\n",
      "50 conv3_block1_out False\n",
      "51 conv3_block2_1_conv False\n",
      "52 conv3_block2_1_bn False\n",
      "53 conv3_block2_1_relu False\n",
      "54 conv3_block2_2_conv False\n",
      "55 conv3_block2_2_bn False\n",
      "56 conv3_block2_2_relu False\n",
      "57 conv3_block2_3_conv False\n",
      "58 conv3_block2_3_bn False\n",
      "59 conv3_block2_add False\n",
      "60 conv3_block2_out False\n",
      "61 conv3_block3_1_conv False\n",
      "62 conv3_block3_1_bn False\n",
      "63 conv3_block3_1_relu False\n",
      "64 conv3_block3_2_conv False\n",
      "65 conv3_block3_2_bn False\n",
      "66 conv3_block3_2_relu False\n",
      "67 conv3_block3_3_conv False\n",
      "68 conv3_block3_3_bn False\n",
      "69 conv3_block3_add False\n",
      "70 conv3_block3_out False\n",
      "71 conv3_block4_1_conv False\n",
      "72 conv3_block4_1_bn False\n",
      "73 conv3_block4_1_relu False\n",
      "74 conv3_block4_2_conv False\n",
      "75 conv3_block4_2_bn False\n",
      "76 conv3_block4_2_relu False\n",
      "77 conv3_block4_3_conv False\n",
      "78 conv3_block4_3_bn False\n",
      "79 conv3_block4_add False\n",
      "80 conv3_block4_out False\n",
      "81 conv4_block1_1_conv False\n",
      "82 conv4_block1_1_bn False\n",
      "83 conv4_block1_1_relu False\n",
      "84 conv4_block1_2_conv False\n",
      "85 conv4_block1_2_bn False\n",
      "86 conv4_block1_2_relu False\n",
      "87 conv4_block1_0_conv False\n",
      "88 conv4_block1_3_conv False\n",
      "89 conv4_block1_0_bn False\n",
      "90 conv4_block1_3_bn False\n",
      "91 conv4_block1_add False\n",
      "92 conv4_block1_out False\n",
      "93 conv4_block2_1_conv False\n",
      "94 conv4_block2_1_bn False\n",
      "95 conv4_block2_1_relu False\n",
      "96 conv4_block2_2_conv False\n",
      "97 conv4_block2_2_bn False\n",
      "98 conv4_block2_2_relu False\n",
      "99 conv4_block2_3_conv False\n",
      "100 conv4_block2_3_bn False\n",
      "101 conv4_block2_add False\n",
      "102 conv4_block2_out False\n",
      "103 conv4_block3_1_conv False\n",
      "104 conv4_block3_1_bn False\n",
      "105 conv4_block3_1_relu False\n",
      "106 conv4_block3_2_conv False\n",
      "107 conv4_block3_2_bn False\n",
      "108 conv4_block3_2_relu False\n",
      "109 conv4_block3_3_conv False\n",
      "110 conv4_block3_3_bn False\n",
      "111 conv4_block3_add False\n",
      "112 conv4_block3_out False\n",
      "113 conv4_block4_1_conv False\n",
      "114 conv4_block4_1_bn False\n",
      "115 conv4_block4_1_relu False\n",
      "116 conv4_block4_2_conv False\n",
      "117 conv4_block4_2_bn False\n",
      "118 conv4_block4_2_relu False\n",
      "119 conv4_block4_3_conv False\n",
      "120 conv4_block4_3_bn False\n",
      "121 conv4_block4_add False\n",
      "122 conv4_block4_out False\n",
      "123 conv4_block5_1_conv False\n",
      "124 conv4_block5_1_bn False\n",
      "125 conv4_block5_1_relu False\n",
      "126 conv4_block5_2_conv False\n",
      "127 conv4_block5_2_bn False\n",
      "128 conv4_block5_2_relu False\n",
      "129 conv4_block5_3_conv False\n",
      "130 conv4_block5_3_bn False\n",
      "131 conv4_block5_add False\n",
      "132 conv4_block5_out False\n",
      "133 conv4_block6_1_conv False\n",
      "134 conv4_block6_1_bn False\n",
      "135 conv4_block6_1_relu False\n",
      "136 conv4_block6_2_conv False\n",
      "137 conv4_block6_2_bn False\n",
      "138 conv4_block6_2_relu False\n",
      "139 conv4_block6_3_conv False\n",
      "140 conv4_block6_3_bn False\n",
      "141 conv4_block6_add False\n",
      "142 conv4_block6_out False\n",
      "143 conv5_block1_1_conv False\n",
      "144 conv5_block1_1_bn False\n",
      "145 conv5_block1_1_relu True\n",
      "146 conv5_block1_2_conv True\n",
      "147 conv5_block1_2_bn True\n",
      "148 conv5_block1_2_relu True\n",
      "149 conv5_block1_0_conv True\n",
      "150 conv5_block1_3_conv True\n",
      "151 conv5_block1_0_bn True\n",
      "152 conv5_block1_3_bn True\n",
      "153 conv5_block1_add True\n",
      "154 conv5_block1_out True\n",
      "155 conv5_block2_1_conv True\n",
      "156 conv5_block2_1_bn True\n",
      "157 conv5_block2_1_relu True\n",
      "158 conv5_block2_2_conv True\n",
      "159 conv5_block2_2_bn True\n",
      "160 conv5_block2_2_relu True\n",
      "161 conv5_block2_3_conv True\n",
      "162 conv5_block2_3_bn True\n",
      "163 conv5_block2_add True\n",
      "164 conv5_block2_out True\n",
      "165 conv5_block3_1_conv True\n",
      "166 conv5_block3_1_bn True\n",
      "167 conv5_block3_1_relu True\n",
      "168 conv5_block3_2_conv True\n",
      "169 conv5_block3_2_bn True\n",
      "170 conv5_block3_2_relu True\n",
      "171 conv5_block3_3_conv True\n",
      "172 conv5_block3_3_bn True\n",
      "173 conv5_block3_add True\n",
      "174 conv5_block3_out True\n",
      "175 global_average_pooling2d True\n",
      "176 dense True\n",
      "177 lambda True\n"
     ]
    }
   ],
   "source": [
    "for i, layer in enumerate(model.layers):\n",
    "    print(i, layer.name, layer.trainable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "77ba54b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2f07c9a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def triplet_loss(anchor, positive, negative, alpha=0.2):\n",
    "    epsilon = 1e-8\n",
    "    \n",
    "    # คำนวณระยะห่างแบบ Euclidean squared\n",
    "    pos_dist = tf.reduce_sum(tf.square(anchor - positive), axis=1)\n",
    "    neg_dist = tf.reduce_sum(tf.square(anchor - negative), axis=1)\n",
    "    \n",
    "    # เพิ่ม epsilon และใช้ tf.clip_by_value เพื่อป้องกันค่าผิดปกติ\n",
    "    pos_dist = tf.clip_by_value(pos_dist, epsilon, 10.0)\n",
    "    neg_dist = tf.clip_by_value(neg_dist, epsilon, 10.0)\n",
    "    \n",
    "    # คำนวณ basic loss\n",
    "    basic_loss = pos_dist - neg_dist + alpha\n",
    "    \n",
    "    # ใช้ tf.nn.relu แทน tf.maximum\n",
    "    loss = tf.reduce_mean(tf.nn.relu(basic_loss))\n",
    "    \n",
    "    # ตรวจสอบ NaN\n",
    "    loss = tf.where(tf.math.is_finite(loss), loss, tf.constant(0.0))\n",
    "    \n",
    "    return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c33b7610",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def losshard_mining(anchor, positive, negative, alpha=0.2):\n",
    "    \"\"\"\n",
    "    Computes Triplet Loss with Hard Triplet Mining.\n",
    "    \"\"\"\n",
    "    # 1. Calculate squared Euclidean distances\n",
    "    pos_dist = tf.reduce_sum(tf.square(anchor - positive), axis=1)\n",
    "    neg_dist = tf.reduce_sum(tf.square(anchor - negative), axis=1)\n",
    "\n",
    "    # 2. Find all valid triplets in the batch\n",
    "    all_triplets = pos_dist - neg_dist + alpha\n",
    "    \n",
    "    # 3. Filter out the easy triplets (loss <= 0)\n",
    "    hard_triplets = tf.where(all_triplets > 0, all_triplets, tf.zeros_like(all_triplets))\n",
    "\n",
    "    # 4. Take the mean of the hard triplets\n",
    "    # Add a small value to the denominator to avoid division by zero\n",
    "    num_hard_triplets = tf.reduce_sum(tf.cast(hard_triplets > 0, dtype=tf.float32))\n",
    "    \n",
    "    # Check if there are any hard triplets. If not, the loss is 0\n",
    "    if num_hard_triplets > 0:\n",
    "        loss = tf.reduce_sum(hard_triplets) / num_hard_triplets\n",
    "    else:\n",
    "        loss = tf.constant(0.0)\n",
    "\n",
    "    # Return the loss\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3660810d",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def triplet_loss_val(anchor, positive, negative, alpha=0.2):\n",
    "    epsilon = 1e-8\n",
    "    \n",
    "    # คำนวณระยะห่างแบบ Euclidean squared\n",
    "    pos_dist = tf.reduce_sum(tf.square(anchor - positive), axis=1)\n",
    "    neg_dist = tf.reduce_sum(tf.square(anchor - negative), axis=1)\n",
    "    \n",
    "    # เพิ่ม epsilon และใช้ tf.clip_by_value เพื่อป้องกันค่าผิดปกติ\n",
    "    pos_dist = tf.clip_by_value(pos_dist, epsilon, 10.0)\n",
    "    neg_dist = tf.clip_by_value(neg_dist, epsilon, 10.0)\n",
    "    \n",
    "    # คำนวณ basic loss\n",
    "    basic_loss = pos_dist - neg_dist + alpha\n",
    "    \n",
    "    # ใช้ tf.nn.relu แทน tf.maximum\n",
    "    loss = tf.reduce_mean(tf.nn.relu(basic_loss))\n",
    "    \n",
    "    # ตรวจสอบ NaN\n",
    "    loss = tf.where(tf.math.is_finite(loss), loss, tf.constant(0.0))\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9b1151c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(anchor, positive, negative):\n",
    "    with tf.GradientTape() as tape:\n",
    "        anchor_embedding = model(anchor, training=True)\n",
    "        positive_embedding = model(positive, training=True)\n",
    "        negative_embedding = model(negative, training=True)\n",
    "        loss = triplet_loss(anchor_embedding, positive_embedding, negative_embedding)\n",
    "    \n",
    "    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e8d3434c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- เริ่มการฝึกโมเดล ---\n",
      "\n",
      "--- Epoch 1/50 ---\n",
      "Batch 5000, Training Loss: 0.2036\n",
      "Batch 10000, Training Loss: 0.2428\n",
      "\n",
      "สรุป Epoch 1/50, Training Loss เฉลี่ย: 0.1830\n",
      "\n",
      "--- เริ่ม Validation ---\n",
      "Validation Batch 500, Validation Loss: 0.0334\n",
      "Validation Batch 1000, Validation Loss: 0.2075\n",
      "สรุป Validation Loss เฉลี่ย: 0.1612\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "\n",
      "--- Epoch 2/50 ---\n",
      "Batch 5000, Training Loss: 0.1759\n",
      "Batch 10000, Training Loss: 0.1930\n",
      "\n",
      "สรุป Epoch 2/50, Training Loss เฉลี่ย: 0.1515\n",
      "\n",
      "--- เริ่ม Validation ---\n",
      "Validation Batch 500, Validation Loss: 0.0905\n",
      "Validation Batch 1000, Validation Loss: 0.1803\n",
      "สรุป Validation Loss เฉลี่ย: 0.1340\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "\n",
      "--- Epoch 3/50 ---\n",
      "Batch 5000, Training Loss: 0.0841\n",
      "Batch 10000, Training Loss: 0.0045\n",
      "\n",
      "สรุป Epoch 3/50, Training Loss เฉลี่ย: 0.1230\n",
      "\n",
      "--- เริ่ม Validation ---\n",
      "Validation Batch 500, Validation Loss: 0.0651\n",
      "Validation Batch 1000, Validation Loss: 0.0000\n",
      "สรุป Validation Loss เฉลี่ย: 0.1209\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "\n",
      "--- Epoch 4/50 ---\n",
      "Batch 5000, Training Loss: 0.0743\n",
      "Batch 10000, Training Loss: 0.1211\n",
      "\n",
      "สรุป Epoch 4/50, Training Loss เฉลี่ย: 0.1140\n",
      "\n",
      "--- เริ่ม Validation ---\n",
      "Validation Batch 500, Validation Loss: 0.1270\n",
      "Validation Batch 1000, Validation Loss: 0.0179\n",
      "สรุป Validation Loss เฉลี่ย: 0.1226\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "\n",
      "--- Epoch 5/50 ---\n",
      "Batch 5000, Training Loss: 0.0248\n",
      "Batch 10000, Training Loss: 0.2605\n",
      "\n",
      "สรุป Epoch 5/50, Training Loss เฉลี่ย: 0.1094\n",
      "\n",
      "--- เริ่ม Validation ---\n",
      "Validation Batch 500, Validation Loss: 0.1784\n",
      "Validation Batch 1000, Validation Loss: 0.1939\n",
      "สรุป Validation Loss เฉลี่ย: 0.1033\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "\n",
      "--- Epoch 6/50 ---\n",
      "Batch 5000, Training Loss: 0.1163\n",
      "Batch 10000, Training Loss: 0.0000\n",
      "\n",
      "สรุป Epoch 6/50, Training Loss เฉลี่ย: 0.1046\n",
      "\n",
      "--- เริ่ม Validation ---\n",
      "Validation Batch 500, Validation Loss: 0.0717\n",
      "Validation Batch 1000, Validation Loss: 0.1189\n",
      "สรุป Validation Loss เฉลี่ย: 0.1096\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "\n",
      "--- Epoch 7/50 ---\n",
      "Batch 5000, Training Loss: 0.1548\n",
      "Batch 10000, Training Loss: 0.1586\n",
      "\n",
      "สรุป Epoch 7/50, Training Loss เฉลี่ย: 0.0962\n",
      "\n",
      "--- เริ่ม Validation ---\n",
      "Validation Batch 500, Validation Loss: 0.1593\n",
      "Validation Batch 1000, Validation Loss: 0.0662\n",
      "สรุป Validation Loss เฉลี่ย: 0.1020\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "\n",
      "--- Epoch 8/50 ---\n",
      "Batch 5000, Training Loss: 0.0372\n",
      "Batch 10000, Training Loss: 0.0978\n",
      "\n",
      "สรุป Epoch 8/50, Training Loss เฉลี่ย: 0.0824\n",
      "\n",
      "--- เริ่ม Validation ---\n",
      "Validation Batch 500, Validation Loss: 0.1725\n",
      "Validation Batch 1000, Validation Loss: 0.0526\n",
      "สรุป Validation Loss เฉลี่ย: 0.0974\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "\n",
      "--- Epoch 9/50 ---\n",
      "Batch 5000, Training Loss: 0.0616\n",
      "Batch 10000, Training Loss: 0.0000\n",
      "\n",
      "สรุป Epoch 9/50, Training Loss เฉลี่ย: 0.0723\n",
      "\n",
      "--- เริ่ม Validation ---\n",
      "Validation Batch 500, Validation Loss: 0.0636\n",
      "Validation Batch 1000, Validation Loss: 0.0738\n",
      "สรุป Validation Loss เฉลี่ย: 0.1135\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "\n",
      "--- Epoch 10/50 ---\n",
      "Batch 5000, Training Loss: 0.1618\n",
      "Batch 10000, Training Loss: 0.0000\n",
      "\n",
      "สรุป Epoch 10/50, Training Loss เฉลี่ย: 0.0681\n",
      "\n",
      "--- เริ่ม Validation ---\n",
      "Validation Batch 500, Validation Loss: 0.2646\n",
      "Validation Batch 1000, Validation Loss: 0.0673\n",
      "สรุป Validation Loss เฉลี่ย: 0.1011\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "\n",
      "--- Epoch 11/50 ---\n",
      "Batch 5000, Training Loss: 0.0000\n",
      "Batch 10000, Training Loss: 0.1105\n",
      "\n",
      "สรุป Epoch 11/50, Training Loss เฉลี่ย: 0.0672\n",
      "\n",
      "--- เริ่ม Validation ---\n",
      "Validation Batch 500, Validation Loss: 0.0545\n",
      "Validation Batch 1000, Validation Loss: 0.0405\n",
      "สรุป Validation Loss เฉลี่ย: 0.1154\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "\n",
      "--- Epoch 12/50 ---\n",
      "Batch 5000, Training Loss: 0.0000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 12\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m--- Epoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mEPOCHS\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m ---\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m anchor, positive, negative \u001b[38;5;129;01min\u001b[39;00m train_dataset:\n\u001b[1;32m---> 12\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43manchor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpositive\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnegative\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     13\u001b[0m     total_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\n\u001b[0;32m     14\u001b[0m     num_batches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[1;32md:\\final_facenet\\face\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32md:\\final_facenet\\face\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    912\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    914\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 915\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    917\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    918\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32md:\\final_facenet\\face\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    944\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    945\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    946\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 947\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateless_fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    948\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    949\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    950\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[0;32m    951\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[1;32md:\\final_facenet\\face\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2496\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2493\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m   2494\u001b[0m   (graph_function,\n\u001b[0;32m   2495\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2496\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2497\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\final_facenet\\face\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1862\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1858\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1859\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1860\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1861\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1862\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1863\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   1864\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1865\u001b[0m     args,\n\u001b[0;32m   1866\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1867\u001b[0m     executing_eagerly)\n\u001b[0;32m   1868\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32md:\\final_facenet\\face\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:499\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    497\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    498\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 499\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    503\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    504\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    505\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    506\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    507\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[0;32m    508\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    511\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[0;32m    512\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32md:\\final_facenet\\face\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "EPOCHS = 50\n",
    "print(\"--- เริ่มการฝึกโมเดล ---\")\n",
    "train_loss_history = []\n",
    "val_loss_history = []\n",
    "for epoch in range(EPOCHS):\n",
    "    total_loss = 0.0\n",
    "    num_batches = 0\n",
    "    \n",
    "    # วนลูปใน training dataset\n",
    "    print(f\"\\n--- Epoch {epoch+1}/{EPOCHS} ---\")\n",
    "    for anchor, positive, negative in train_dataset:\n",
    "        loss = train_step(anchor, positive, negative)\n",
    "        total_loss += loss\n",
    "        num_batches += 1\n",
    "        \n",
    "        # ปริ้นท์\n",
    "        if num_batches % 5000 == 0:\n",
    "            print(f\"Batch {num_batches}, Training Loss: {loss.numpy():.4f}\")\n",
    "    \n",
    "    avg_loss = total_loss / num_batches if num_batches > 0 else 0\n",
    "    print(f\"\\nสรุป Epoch {epoch+1}/{EPOCHS}, Training Loss เฉลี่ย: {avg_loss.numpy():.4f}\")\n",
    "    train_loss_history.append(avg_loss)\n",
    "    # Optional: ตรวจสอบ Validation Loss ในแต่ละ Epoch\n",
    "    val_total_loss = 0.0\n",
    "    val_num_batches = 0\n",
    "    \n",
    "    # วนลูปใน validation dataset\n",
    "    print(\"\\n--- เริ่ม Validation ---\")\n",
    "    for anchor, positive, negative in val_dataset:\n",
    "        anchor_embedding = model(anchor, training=False)\n",
    "        positive_embedding = model(positive, training=False)\n",
    "        negative_embedding = model(negative, training=False)\n",
    "        val_loss = triplet_loss(anchor_embedding, positive_embedding, negative_embedding)\n",
    "        val_total_loss += val_loss\n",
    "        val_num_batches += 1\n",
    "        \n",
    "        # ปริ้นท์ Val\n",
    "        if val_num_batches % 500 == 0:\n",
    "             print(f\"Validation Batch {val_num_batches}, Validation Loss: {val_loss.numpy():.4f}\")\n",
    "             \n",
    "    val_avg_loss = val_total_loss / val_num_batches if val_num_batches > 0 else 0\n",
    "    print(f\"สรุป Validation Loss เฉลี่ย: {val_avg_loss.numpy():.4f}\")\n",
    "    val_loss_history.append(val_avg_loss)\n",
    "    nameModel = f\"modelR{epoch+1}.h5\"\n",
    "    model.save(nameModel)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(range(1, EPOCHS + 1), train_loss_history, 'o-', label='Training Loss',color='red')\n",
    "plt.plot(range(1, EPOCHS + 1), val_loss_history, 'x-', label='Validation Loss',color=\"#00FF2A\")\n",
    "plt.title('Training vs. Validation Loss Over Epochs')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n--- การฝึกโมเดลเสร็จสิ้น ---\")\n",
    "model.save(\"2M.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca062932",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def hard_mining(anchor, positive, negative, alpha=0.2):\n",
    "    pos_dist = tf.reduce_sum(tf.square(anchor - positive), axis=1)\n",
    "    neg_dist = tf.reduce_sum(tf.square(anchor - negative), axis=1)\n",
    "    hardest_pos_dist = tf.reduce_max(pos_dist)\n",
    "    hardest_neg_dist = tf.reduce_min(neg_dist)\n",
    "    basic_loss = hardest_pos_dist - hardest_neg_dist + alpha\n",
    "    loss = tf.nn.relu(basic_loss)\n",
    "    return loss"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "face",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
